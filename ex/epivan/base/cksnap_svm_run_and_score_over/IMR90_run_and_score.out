nohup: ignoring input
Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)
experiment: IMR90 cksnap_svm
trainSet len:[X=45080,y=45080]
testSet len:[X=2625,y=2625]
Fitting, totalling 850 fits
==get_scoring_result==
base_score: total=2625, TP=89, TN=828, FP=1672, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.349) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 828, 'FP': 1672, 'FN': 36, 'precision': 0.05053946621237933, 'recall': 0.712, 'accuracy': 0.34933333333333333, 'average_precision': 0.04619555504572405, 'balanced_accuracy': 0.5216, 'f1': 0.09437963944856839, 'roc_auc': 0.5067408}
==getted_scoring_result==
[fit 1/850] END C=0.0009765625, gamma=0.0009765625, kernel=rbf; total=2625, TP=89, TN=828, FP=1672, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.349) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.507) 10.98s
==get_scoring_result==
base_score: total=2625, TP=86, TN=868, FP=1632, FN=39; precision=0.050, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.363) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 868, 'FP': 1632, 'FN': 39, 'precision': 0.050058207217694994, 'recall': 0.688, 'accuracy': 0.36342857142857143, 'average_precision': 0.0461995550860568, 'balanced_accuracy': 0.5176, 'f1': 0.09332609875203472, 'roc_auc': 0.5067392}
==getted_scoring_result==
[fit 2/850] END C=0.0009765625, gamma=0.001953125, kernel=rbf; total=2625, TP=86, TN=868, FP=1632, FN=39; precision=0.050, recall=0.688
accuracy: (test=0.363) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 10.35s
==get_scoring_result==
base_score: total=2625, TP=88, TN=845, FP=1655, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.355) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 845, 'FP': 1655, 'FN': 37, 'precision': 0.05048766494549627, 'recall': 0.704, 'accuracy': 0.3554285714285714, 'average_precision': 0.046206654935190036, 'balanced_accuracy': 0.521, 'f1': 0.09421841541755888, 'roc_auc': 0.5067296}
==getted_scoring_result==
[fit 3/850] END C=0.0009765625, gamma=0.00390625, kernel=rbf; total=2625, TP=88, TN=845, FP=1655, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.355) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 10.56s
==get_scoring_result==
base_score: total=2625, TP=88, TN=856, FP=1644, FN=37; precision=0.051, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.523) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 856, 'FP': 1644, 'FN': 37, 'precision': 0.050808314087759814, 'recall': 0.704, 'accuracy': 0.3596190476190476, 'average_precision': 0.04625403133372868, 'balanced_accuracy': 0.5232, 'f1': 0.09477652127086698, 'roc_auc': 0.506816}
==getted_scoring_result==
[fit 4/850] END C=0.0009765625, gamma=0.0078125, kernel=rbf; total=2625, TP=88, TN=856, FP=1644, FN=37; precision=0.051, recall=0.704
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.523) f1: (test=0.095) roc_auc: (test=0.507) 9.94s
==get_scoring_result==
base_score: total=2625, TP=88, TN=837, FP=1663, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.352) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 837, 'FP': 1663, 'FN': 37, 'precision': 0.05025699600228441, 'recall': 0.704, 'accuracy': 0.3523809523809524, 'average_precision': 0.04617281694877945, 'balanced_accuracy': 0.5194, 'f1': 0.09381663113006397, 'roc_auc': 0.5065424}
==getted_scoring_result==
[fit 5/850] END C=0.0009765625, gamma=0.015625, kernel=rbf; total=2625, TP=88, TN=837, FP=1663, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.352) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.78s
==get_scoring_result==
base_score: total=2625, TP=89, TN=831, FP=1669, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.350) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 831, 'FP': 1669, 'FN': 36, 'precision': 0.05062571103526735, 'recall': 0.712, 'accuracy': 0.3504761904761905, 'average_precision': 0.04620795310389612, 'balanced_accuracy': 0.5222, 'f1': 0.09453000531067446, 'roc_auc': 0.5068048}
==getted_scoring_result==
[fit 6/850] END C=0.0009765625, gamma=0.03125, kernel=rbf; total=2625, TP=89, TN=831, FP=1669, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.350) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.095) roc_auc: (test=0.507) 9.80s
==get_scoring_result==
base_score: total=2625, TP=87, TN=849, FP=1651, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 849, 'FP': 1651, 'FN': 38, 'precision': 0.05005753739930955, 'recall': 0.696, 'accuracy': 0.3565714285714286, 'average_precision': 0.04619465309966033, 'balanced_accuracy': 0.5178, 'f1': 0.09339774557165861, 'roc_auc': 0.5066976}
==getted_scoring_result==
[fit 7/850] END C=0.0009765625, gamma=0.0625, kernel=rbf; total=2625, TP=87, TN=849, FP=1651, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.72s
==get_scoring_result==
base_score: total=2625, TP=87, TN=853, FP=1647, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 853, 'FP': 1647, 'FN': 38, 'precision': 0.050173010380622836, 'recall': 0.696, 'accuracy': 0.3580952380952381, 'average_precision': 0.04624048738464204, 'balanced_accuracy': 0.5186, 'f1': 0.09359870898332437, 'roc_auc': 0.506752}
==getted_scoring_result==
[fit 8/850] END C=0.0009765625, gamma=0.125, kernel=rbf; total=2625, TP=87, TN=853, FP=1647, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.42s
==get_scoring_result==
base_score: total=2625, TP=87, TN=850, FP=1650, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 850, 'FP': 1650, 'FN': 38, 'precision': 0.05008635578583765, 'recall': 0.696, 'accuracy': 0.35695238095238097, 'average_precision': 0.04625099109005469, 'balanced_accuracy': 0.518, 'f1': 0.09344790547798067, 'roc_auc': 0.5068384}
==getted_scoring_result==
[fit 9/850] END C=0.0009765625, gamma=0.25, kernel=rbf; total=2625, TP=87, TN=850, FP=1650, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.27s
==get_scoring_result==
base_score: total=2625, TP=87, TN=851, FP=1649, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 851, 'FP': 1649, 'FN': 38, 'precision': 0.05011520737327189, 'recall': 0.696, 'accuracy': 0.35733333333333334, 'average_precision': 0.046254883329281266, 'balanced_accuracy': 0.5182, 'f1': 0.09349811929070391, 'roc_auc': 0.5071792}
==getted_scoring_result==
[fit 10/850] END C=0.0009765625, gamma=0.5, kernel=rbf; total=2625, TP=87, TN=851, FP=1649, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.34s
==get_scoring_result==
base_score: total=2625, TP=86, TN=858, FP=1642, FN=39; precision=0.050, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.516) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.508) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 858, 'FP': 1642, 'FN': 39, 'precision': 0.04976851851851852, 'recall': 0.688, 'accuracy': 0.3596190476190476, 'average_precision': 0.04635114027945615, 'balanced_accuracy': 0.5156, 'f1': 0.09282245008094982, 'roc_auc': 0.5081616}
==getted_scoring_result==
[fit 11/850] END C=0.0009765625, gamma=1.0, kernel=rbf; total=2625, TP=86, TN=858, FP=1642, FN=39; precision=0.050, recall=0.688
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.516) f1: (test=0.093) roc_auc: (test=0.508) 9.30s
==get_scoring_result==
base_score: total=2625, TP=84, TN=885, FP=1615, FN=41; precision=0.049, recall=0.672

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.369) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.513) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.510) ===
score_result_dict: {'Total': 2625, 'TP': 84, 'TN': 885, 'FP': 1615, 'FN': 41, 'precision': 0.049440847557386695, 'recall': 0.672, 'accuracy': 0.36914285714285716, 'average_precision': 0.04663364527562597, 'balanced_accuracy': 0.513, 'f1': 0.09210526315789473, 'roc_auc': 0.5095216}
==getted_scoring_result==
[fit 12/850] END C=0.0009765625, gamma=2.0, kernel=rbf; total=2625, TP=84, TN=885, FP=1615, FN=41; precision=0.049, recall=0.672
accuracy: (test=0.369) average_precision: (test=0.047) balanced_accuracy: (test=0.513) f1: (test=0.092) roc_auc: (test=0.510) 9.44s
==get_scoring_result==
base_score: total=2625, TP=80, TN=916, FP=1584, FN=45; precision=0.048, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.379) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.503) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.089) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.512) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 916, 'FP': 1584, 'FN': 45, 'precision': 0.04807692307692308, 'recall': 0.64, 'accuracy': 0.37942857142857145, 'average_precision': 0.047605568338596915, 'balanced_accuracy': 0.5032, 'f1': 0.08943543879262157, 'roc_auc': 0.5116032}
==getted_scoring_result==
[fit 13/850] END C=0.0009765625, gamma=4.0, kernel=rbf; total=2625, TP=80, TN=916, FP=1584, FN=45; precision=0.048, recall=0.640
accuracy: (test=0.379) average_precision: (test=0.048) balanced_accuracy: (test=0.503) f1: (test=0.089) roc_auc: (test=0.512) 9.30s
==get_scoring_result==
base_score: total=2625, TP=78, TN=914, FP=1586, FN=47; precision=0.047, recall=0.624

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.378) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.055) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.495) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.087) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.517) ===
score_result_dict: {'Total': 2625, 'TP': 78, 'TN': 914, 'FP': 1586, 'FN': 47, 'precision': 0.046875, 'recall': 0.624, 'accuracy': 0.3779047619047619, 'average_precision': 0.05468277357961167, 'balanced_accuracy': 0.4948, 'f1': 0.08719955282280603, 'roc_auc': 0.5170688}
==getted_scoring_result==
[fit 14/850] END C=0.0009765625, gamma=8.0, kernel=rbf; total=2625, TP=78, TN=914, FP=1586, FN=47; precision=0.047, recall=0.624
accuracy: (test=0.378) average_precision: (test=0.055) balanced_accuracy: (test=0.495) f1: (test=0.087) roc_auc: (test=0.517) 9.26s
==get_scoring_result==
base_score: total=2625, TP=82, TN=924, FP=1576, FN=43; precision=0.049, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.383) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.056) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.513) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.527) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 924, 'FP': 1576, 'FN': 43, 'precision': 0.04945717732207479, 'recall': 0.656, 'accuracy': 0.3832380952380952, 'average_precision': 0.05575640015447816, 'balanced_accuracy': 0.5128, 'f1': 0.09197980931015143, 'roc_auc': 0.5265696}
==getted_scoring_result==
[fit 15/850] END C=0.0009765625, gamma=16.0, kernel=rbf; total=2625, TP=82, TN=924, FP=1576, FN=43; precision=0.049, recall=0.656
accuracy: (test=0.383) average_precision: (test=0.056) balanced_accuracy: (test=0.513) f1: (test=0.092) roc_auc: (test=0.527) 9.32s
==get_scoring_result==
base_score: total=2625, TP=85, TN=918, FP=1582, FN=40; precision=0.051, recall=0.680

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.382) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.060) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.540) ===
score_result_dict: {'Total': 2625, 'TP': 85, 'TN': 918, 'FP': 1582, 'FN': 40, 'precision': 0.05098980203959208, 'recall': 0.68, 'accuracy': 0.3820952380952381, 'average_precision': 0.05991909134596738, 'balanced_accuracy': 0.5236000000000001, 'f1': 0.09486607142857141, 'roc_auc': 0.5396208}
==getted_scoring_result==
[fit 16/850] END C=0.0009765625, gamma=32.0, kernel=rbf; total=2625, TP=85, TN=918, FP=1582, FN=40; precision=0.051, recall=0.680
accuracy: (test=0.382) average_precision: (test=0.060) balanced_accuracy: (test=0.524) f1: (test=0.095) roc_auc: (test=0.540) 9.36s
==get_scoring_result==
base_score: total=2625, TP=47, TN=1743, FP=757, FN=78; precision=0.058, recall=0.376

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.682) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.056) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.537) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.101) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.558) ===
score_result_dict: {'Total': 2625, 'TP': 47, 'TN': 1743, 'FP': 757, 'FN': 78, 'precision': 0.05845771144278607, 'recall': 0.376, 'accuracy': 0.6819047619047619, 'average_precision': 0.05593535418068587, 'balanced_accuracy': 0.5366, 'f1': 0.10118406889128095, 'roc_auc': 0.5583152}
==getted_scoring_result==
[fit 17/850] END C=0.0009765625, gamma=64.0, kernel=rbf; total=2625, TP=47, TN=1743, FP=757, FN=78; precision=0.058, recall=0.376
accuracy: (test=0.682) average_precision: (test=0.056) balanced_accuracy: (test=0.537) f1: (test=0.101) roc_auc: (test=0.558) 9.21s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.110) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.624) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.11038423831105955, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.6236928}
==getted_scoring_result==
[fit 18/850] END C=0.0009765625, gamma=128.0, kernel=rbf; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.110) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.624) 9.36s
==get_scoring_result==
base_score: total=2625, TP=33, TN=2458, FP=42, FN=92; precision=0.440, recall=0.264

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.949) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.338) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.330) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.770) ===
score_result_dict: {'Total': 2625, 'TP': 33, 'TN': 2458, 'FP': 42, 'FN': 92, 'precision': 0.44, 'recall': 0.264, 'accuracy': 0.948952380952381, 'average_precision': 0.3375451652215907, 'balanced_accuracy': 0.6235999999999999, 'f1': 0.33, 'roc_auc': 0.7701904}
==getted_scoring_result==
[fit 19/850] END C=0.0009765625, gamma=256.0, kernel=rbf; total=2625, TP=33, TN=2458, FP=42, FN=92; precision=0.440, recall=0.264
accuracy: (test=0.949) average_precision: (test=0.338) balanced_accuracy: (test=0.624) f1: (test=0.330) roc_auc: (test=0.770) 9.86s
==get_scoring_result==
base_score: total=2625, TP=33, TN=2500, FP=0, FN=92; precision=1.000, recall=0.264

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.965) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.617) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.632) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.418) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.845) ===
score_result_dict: {'Total': 2625, 'TP': 33, 'TN': 2500, 'FP': 0, 'FN': 92, 'precision': 1.0, 'recall': 0.264, 'accuracy': 0.964952380952381, 'average_precision': 0.6168395359690413, 'balanced_accuracy': 0.632, 'f1': 0.4177215189873418, 'roc_auc': 0.8448352}
==getted_scoring_result==
[fit 20/850] END C=0.0009765625, gamma=512.0, kernel=rbf; total=2625, TP=33, TN=2500, FP=0, FN=92; precision=1.000, recall=0.264
accuracy: (test=0.965) average_precision: (test=0.617) balanced_accuracy: (test=0.632) f1: (test=0.418) roc_auc: (test=0.845) 10.09s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.849) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.654680642481418, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.8494992}
==getted_scoring_result==
[fit 21/850] END C=0.0009765625, gamma=1024.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.655) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.849) 9.69s
==get_scoring_result==
base_score: total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.962) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.646) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.596) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.322) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 24, 'TN': 2500, 'FP': 0, 'FN': 101, 'precision': 1.0, 'recall': 0.192, 'accuracy': 0.9615238095238096, 'average_precision': 0.645883173791148, 'balanced_accuracy': 0.596, 'f1': 0.32214765100671144, 'roc_auc': 0.8348672}
==getted_scoring_result==
[fit 22/850] END C=0.0009765625, gamma=2048.0, kernel=rbf; total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192
accuracy: (test=0.962) average_precision: (test=0.646) balanced_accuracy: (test=0.596) f1: (test=0.322) roc_auc: (test=0.835) 9.97s
==get_scoring_result==
base_score: total=2625, TP=22, TN=2500, FP=0, FN=103; precision=1.000, recall=0.176

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.961) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.602) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.588) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.299) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.807) ===
score_result_dict: {'Total': 2625, 'TP': 22, 'TN': 2500, 'FP': 0, 'FN': 103, 'precision': 1.0, 'recall': 0.176, 'accuracy': 0.9607619047619048, 'average_precision': 0.6019410042542589, 'balanced_accuracy': 0.588, 'f1': 0.29931972789115646, 'roc_auc': 0.8071152}
==getted_scoring_result==
[fit 23/850] END C=0.0009765625, gamma=4096.0, kernel=rbf; total=2625, TP=22, TN=2500, FP=0, FN=103; precision=1.000, recall=0.176
accuracy: (test=0.961) average_precision: (test=0.602) balanced_accuracy: (test=0.588) f1: (test=0.299) roc_auc: (test=0.807) 9.50s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.962) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.453) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.596) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.322) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.720) ===
score_result_dict: {'Total': 2625, 'TP': 24, 'TN': 2500, 'FP': 0, 'FN': 101, 'precision': 1.0, 'recall': 0.192, 'accuracy': 0.9615238095238096, 'average_precision': 0.4526520452806387, 'balanced_accuracy': 0.596, 'f1': 0.32214765100671144, 'roc_auc': 0.7199984}
==getted_scoring_result==
[fit 24/850] END C=0.0009765625, gamma=8192.0, kernel=rbf; total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192
accuracy: (test=0.962) average_precision: (test=0.453) balanced_accuracy: (test=0.596) f1: (test=0.322) roc_auc: (test=0.720) 8.89s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.353) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.671) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.35341194968553463, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.671016}
==getted_scoring_result==
[fit 25/850] END C=0.0009765625, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.353) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.671) 9.25s
==get_scoring_result==
base_score: total=2625, TP=89, TN=828, FP=1672, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.349) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 828, 'FP': 1672, 'FN': 36, 'precision': 0.05053946621237933, 'recall': 0.712, 'accuracy': 0.34933333333333333, 'average_precision': 0.04619555504572405, 'balanced_accuracy': 0.5216, 'f1': 0.09437963944856839, 'roc_auc': 0.5067408}
==getted_scoring_result==
[fit 26/850] END C=0.001953125, gamma=0.0009765625, kernel=rbf; total=2625, TP=89, TN=828, FP=1672, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.349) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.507) 9.46s
==get_scoring_result==
base_score: total=2625, TP=86, TN=868, FP=1632, FN=39; precision=0.050, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.363) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 868, 'FP': 1632, 'FN': 39, 'precision': 0.050058207217694994, 'recall': 0.688, 'accuracy': 0.36342857142857143, 'average_precision': 0.0461995550860568, 'balanced_accuracy': 0.5176, 'f1': 0.09332609875203472, 'roc_auc': 0.5067392}
==getted_scoring_result==
[fit 27/850] END C=0.001953125, gamma=0.001953125, kernel=rbf; total=2625, TP=86, TN=868, FP=1632, FN=39; precision=0.050, recall=0.688
accuracy: (test=0.363) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.53s
==get_scoring_result==
base_score: total=2625, TP=89, TN=826, FP=1674, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.349) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 826, 'FP': 1674, 'FN': 36, 'precision': 0.05048213272830403, 'recall': 0.712, 'accuracy': 0.3485714285714286, 'average_precision': 0.04618273705618006, 'balanced_accuracy': 0.5212, 'f1': 0.09427966101694915, 'roc_auc': 0.5065968}
==getted_scoring_result==
[fit 28/850] END C=0.001953125, gamma=0.00390625, kernel=rbf; total=2625, TP=89, TN=826, FP=1674, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.349) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 9.63s
==get_scoring_result==
base_score: total=2625, TP=88, TN=843, FP=1657, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.355) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 843, 'FP': 1657, 'FN': 37, 'precision': 0.0504297994269341, 'recall': 0.704, 'accuracy': 0.3546666666666667, 'average_precision': 0.04619575209871411, 'balanced_accuracy': 0.5206, 'f1': 0.09411764705882353, 'roc_auc': 0.5068048}
==getted_scoring_result==
[fit 29/850] END C=0.001953125, gamma=0.0078125, kernel=rbf; total=2625, TP=88, TN=843, FP=1657, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.355) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 9.36s
==get_scoring_result==
base_score: total=2625, TP=88, TN=843, FP=1657, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.355) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 843, 'FP': 1657, 'FN': 37, 'precision': 0.0504297994269341, 'recall': 0.704, 'accuracy': 0.3546666666666667, 'average_precision': 0.04619444105848304, 'balanced_accuracy': 0.5206, 'f1': 0.09411764705882353, 'roc_auc': 0.5068}
==getted_scoring_result==
[fit 30/850] END C=0.001953125, gamma=0.015625, kernel=rbf; total=2625, TP=88, TN=843, FP=1657, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.355) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 8.99s
==get_scoring_result==
base_score: total=2625, TP=88, TN=840, FP=1660, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.354) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 840, 'FP': 1660, 'FN': 37, 'precision': 0.05034324942791762, 'recall': 0.704, 'accuracy': 0.3535238095238095, 'average_precision': 0.04620954712994005, 'balanced_accuracy': 0.52, 'f1': 0.09396689802455954, 'roc_auc': 0.5067984}
==getted_scoring_result==
[fit 31/850] END C=0.001953125, gamma=0.03125, kernel=rbf; total=2625, TP=88, TN=840, FP=1660, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.354) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.00s
==get_scoring_result==
base_score: total=2625, TP=87, TN=854, FP=1646, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 854, 'FP': 1646, 'FN': 38, 'precision': 0.05020196191575303, 'recall': 0.696, 'accuracy': 0.3584761904761905, 'average_precision': 0.046217735458567, 'balanced_accuracy': 0.5187999999999999, 'f1': 0.09364908503767493, 'roc_auc': 0.5067264}
==getted_scoring_result==
[fit 32/850] END C=0.001953125, gamma=0.0625, kernel=rbf; total=2625, TP=87, TN=854, FP=1646, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.08s
==get_scoring_result==
base_score: total=2625, TP=87, TN=849, FP=1651, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 849, 'FP': 1651, 'FN': 38, 'precision': 0.05005753739930955, 'recall': 0.696, 'accuracy': 0.3565714285714286, 'average_precision': 0.046223330359016185, 'balanced_accuracy': 0.5178, 'f1': 0.09339774557165861, 'roc_auc': 0.5068464}
==getted_scoring_result==
[fit 33/850] END C=0.001953125, gamma=0.125, kernel=rbf; total=2625, TP=87, TN=849, FP=1651, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 8.95s
==get_scoring_result==
base_score: total=2625, TP=87, TN=852, FP=1648, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 852, 'FP': 1648, 'FN': 38, 'precision': 0.05014409221902017, 'recall': 0.696, 'accuracy': 0.3577142857142857, 'average_precision': 0.046263553201079145, 'balanced_accuracy': 0.5184, 'f1': 0.09354838709677418, 'roc_auc': 0.5069344}
==getted_scoring_result==
[fit 34/850] END C=0.001953125, gamma=0.25, kernel=rbf; total=2625, TP=87, TN=852, FP=1648, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.094) roc_auc: (test=0.507) 9.63s
==get_scoring_result==
base_score: total=2625, TP=87, TN=852, FP=1648, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 852, 'FP': 1648, 'FN': 38, 'precision': 0.05014409221902017, 'recall': 0.696, 'accuracy': 0.3577142857142857, 'average_precision': 0.04625809929212136, 'balanced_accuracy': 0.5184, 'f1': 0.09354838709677418, 'roc_auc': 0.507224}
==getted_scoring_result==
[fit 35/850] END C=0.001953125, gamma=0.5, kernel=rbf; total=2625, TP=87, TN=852, FP=1648, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.094) roc_auc: (test=0.507) 10.04s
==get_scoring_result==
base_score: total=2625, TP=86, TN=858, FP=1642, FN=39; precision=0.050, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.516) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.508) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 858, 'FP': 1642, 'FN': 39, 'precision': 0.04976851851851852, 'recall': 0.688, 'accuracy': 0.3596190476190476, 'average_precision': 0.04635129025014786, 'balanced_accuracy': 0.5156, 'f1': 0.09282245008094982, 'roc_auc': 0.5081648}
==getted_scoring_result==
[fit 36/850] END C=0.001953125, gamma=1.0, kernel=rbf; total=2625, TP=86, TN=858, FP=1642, FN=39; precision=0.050, recall=0.688
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.516) f1: (test=0.093) roc_auc: (test=0.508) 10.06s
==get_scoring_result==
base_score: total=2625, TP=83, TN=897, FP=1603, FN=42; precision=0.049, recall=0.664

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.373) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.511) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 83, 'TN': 897, 'FP': 1603, 'FN': 42, 'precision': 0.04922894424673784, 'recall': 0.664, 'accuracy': 0.37333333333333335, 'average_precision': 0.04662318250920455, 'balanced_accuracy': 0.5114000000000001, 'f1': 0.09166206515737162, 'roc_auc': 0.5094912}
==getted_scoring_result==
[fit 37/850] END C=0.001953125, gamma=2.0, kernel=rbf; total=2625, TP=83, TN=897, FP=1603, FN=42; precision=0.049, recall=0.664
accuracy: (test=0.373) average_precision: (test=0.047) balanced_accuracy: (test=0.511) f1: (test=0.092) roc_auc: (test=0.509) 9.84s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1168, FP=1332, FN=52; precision=0.052, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.473) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.526) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.513) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1168, 'FP': 1332, 'FN': 52, 'precision': 0.05195729537366548, 'recall': 0.584, 'accuracy': 0.47276190476190477, 'average_precision': 0.04771015367494027, 'balanced_accuracy': 0.5256, 'f1': 0.0954248366013072, 'roc_auc': 0.513312}
==getted_scoring_result==
[fit 38/850] END C=0.001953125, gamma=4.0, kernel=rbf; total=2625, TP=73, TN=1168, FP=1332, FN=52; precision=0.052, recall=0.584
accuracy: (test=0.473) average_precision: (test=0.048) balanced_accuracy: (test=0.526) f1: (test=0.095) roc_auc: (test=0.513) 9.40s
==get_scoring_result==
base_score: total=2625, TP=63, TN=1350, FP=1150, FN=62; precision=0.052, recall=0.504

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.538) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.055) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.519) ===
score_result_dict: {'Total': 2625, 'TP': 63, 'TN': 1350, 'FP': 1150, 'FN': 62, 'precision': 0.05193734542456719, 'recall': 0.504, 'accuracy': 0.5382857142857143, 'average_precision': 0.05458791755899425, 'balanced_accuracy': 0.522, 'f1': 0.09417040358744395, 'roc_auc': 0.5186624}
==getted_scoring_result==
[fit 39/850] END C=0.001953125, gamma=8.0, kernel=rbf; total=2625, TP=63, TN=1350, FP=1150, FN=62; precision=0.052, recall=0.504
accuracy: (test=0.538) average_precision: (test=0.055) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.519) 9.74s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1233, FP=1267, FN=55; precision=0.052, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.496) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.055) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.527) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.530) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1233, 'FP': 1267, 'FN': 55, 'precision': 0.05235602094240838, 'recall': 0.56, 'accuracy': 0.49638095238095237, 'average_precision': 0.05494529766929651, 'balanced_accuracy': 0.5266000000000001, 'f1': 0.0957592339261286, 'roc_auc': 0.5299392}
==getted_scoring_result==
[fit 40/850] END C=0.001953125, gamma=16.0, kernel=rbf; total=2625, TP=70, TN=1233, FP=1267, FN=55; precision=0.052, recall=0.560
accuracy: (test=0.496) average_precision: (test=0.055) balanced_accuracy: (test=0.527) f1: (test=0.096) roc_auc: (test=0.530) 9.71s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1261, FP=1239, FN=55; precision=0.053, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.507) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.060) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.532) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.541) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1261, 'FP': 1239, 'FN': 55, 'precision': 0.053475935828877004, 'recall': 0.56, 'accuracy': 0.5070476190476191, 'average_precision': 0.059968955366575705, 'balanced_accuracy': 0.5322, 'f1': 0.09762900976290098, 'roc_auc': 0.5414832}
==getted_scoring_result==
[fit 41/850] END C=0.001953125, gamma=32.0, kernel=rbf; total=2625, TP=70, TN=1261, FP=1239, FN=55; precision=0.053, recall=0.560
accuracy: (test=0.507) average_precision: (test=0.060) balanced_accuracy: (test=0.532) f1: (test=0.098) roc_auc: (test=0.541) 9.75s
==get_scoring_result==
base_score: total=2625, TP=77, TN=1218, FP=1282, FN=48; precision=0.057, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.493) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.066) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.552) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.104) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.563) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 1218, 'FP': 1282, 'FN': 48, 'precision': 0.05665930831493746, 'recall': 0.616, 'accuracy': 0.49333333333333335, 'average_precision': 0.06583998397577431, 'balanced_accuracy': 0.5516, 'f1': 0.10377358490566037, 'roc_auc': 0.5628576}
==getted_scoring_result==
[fit 42/850] END C=0.001953125, gamma=64.0, kernel=rbf; total=2625, TP=77, TN=1218, FP=1282, FN=48; precision=0.057, recall=0.616
accuracy: (test=0.493) average_precision: (test=0.066) balanced_accuracy: (test=0.552) f1: (test=0.104) roc_auc: (test=0.563) 9.89s
==get_scoring_result==
base_score: total=2625, TP=36, TN=2087, FP=413, FN=89; precision=0.080, recall=0.288

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.809) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.110) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.561) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.125) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.624) ===
score_result_dict: {'Total': 2625, 'TP': 36, 'TN': 2087, 'FP': 413, 'FN': 89, 'precision': 0.0801781737193764, 'recall': 0.288, 'accuracy': 0.8087619047619048, 'average_precision': 0.11038674445680494, 'balanced_accuracy': 0.5614, 'f1': 0.1254355400696864, 'roc_auc': 0.6237024}
==getted_scoring_result==
[fit 43/850] END C=0.001953125, gamma=128.0, kernel=rbf; total=2625, TP=36, TN=2087, FP=413, FN=89; precision=0.080, recall=0.288
accuracy: (test=0.809) average_precision: (test=0.110) balanced_accuracy: (test=0.561) f1: (test=0.125) roc_auc: (test=0.624) 9.74s
==get_scoring_result==
base_score: total=2625, TP=32, TN=2459, FP=41, FN=93; precision=0.438, recall=0.256

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.949) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.337) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.620) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.323) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.770) ===
score_result_dict: {'Total': 2625, 'TP': 32, 'TN': 2459, 'FP': 41, 'FN': 93, 'precision': 0.4383561643835616, 'recall': 0.256, 'accuracy': 0.948952380952381, 'average_precision': 0.3372943726458886, 'balanced_accuracy': 0.6198, 'f1': 0.3232323232323232, 'roc_auc': 0.7701792}
==getted_scoring_result==
[fit 44/850] END C=0.001953125, gamma=256.0, kernel=rbf; total=2625, TP=32, TN=2459, FP=41, FN=93; precision=0.438, recall=0.256
accuracy: (test=0.949) average_precision: (test=0.337) balanced_accuracy: (test=0.620) f1: (test=0.323) roc_auc: (test=0.770) 9.80s
==get_scoring_result==
base_score: total=2625, TP=32, TN=2500, FP=0, FN=93; precision=1.000, recall=0.256

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.965) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.617) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.628) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.408) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.845) ===
score_result_dict: {'Total': 2625, 'TP': 32, 'TN': 2500, 'FP': 0, 'FN': 93, 'precision': 1.0, 'recall': 0.256, 'accuracy': 0.9645714285714285, 'average_precision': 0.6168426580435187, 'balanced_accuracy': 0.628, 'f1': 0.40764331210191085, 'roc_auc': 0.8448416}
==getted_scoring_result==
[fit 45/850] END C=0.001953125, gamma=512.0, kernel=rbf; total=2625, TP=32, TN=2500, FP=0, FN=93; precision=1.000, recall=0.256
accuracy: (test=0.965) average_precision: (test=0.617) balanced_accuracy: (test=0.628) f1: (test=0.408) roc_auc: (test=0.845) 10.62s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.850) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6547419176972473, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.8495088}
==getted_scoring_result==
[fit 46/850] END C=0.001953125, gamma=1024.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.655) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.850) 10.77s
==get_scoring_result==
base_score: total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.962) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.644) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.596) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.322) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.831) ===
score_result_dict: {'Total': 2625, 'TP': 24, 'TN': 2500, 'FP': 0, 'FN': 101, 'precision': 1.0, 'recall': 0.192, 'accuracy': 0.9615238095238096, 'average_precision': 0.6436962767367099, 'balanced_accuracy': 0.596, 'f1': 0.32214765100671144, 'roc_auc': 0.831392}
==getted_scoring_result==
[fit 47/850] END C=0.001953125, gamma=2048.0, kernel=rbf; total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192
accuracy: (test=0.962) average_precision: (test=0.644) balanced_accuracy: (test=0.596) f1: (test=0.322) roc_auc: (test=0.831) 10.68s
==get_scoring_result==
base_score: total=2625, TP=19, TN=2500, FP=0, FN=106; precision=1.000, recall=0.152

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.960) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.592) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.576) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.264) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.803) ===
score_result_dict: {'Total': 2625, 'TP': 19, 'TN': 2500, 'FP': 0, 'FN': 106, 'precision': 1.0, 'recall': 0.152, 'accuracy': 0.9596190476190476, 'average_precision': 0.5922769566155159, 'balanced_accuracy': 0.576, 'f1': 0.2638888888888889, 'roc_auc': 0.803448}
==getted_scoring_result==
[fit 48/850] END C=0.001953125, gamma=4096.0, kernel=rbf; total=2625, TP=19, TN=2500, FP=0, FN=106; precision=1.000, recall=0.152
accuracy: (test=0.960) average_precision: (test=0.592) balanced_accuracy: (test=0.576) f1: (test=0.264) roc_auc: (test=0.803) 10.51s
==get_scoring_result==
base_score: total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.957) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.453) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.552) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.188) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.721) ===
score_result_dict: {'Total': 2625, 'TP': 13, 'TN': 2500, 'FP': 0, 'FN': 112, 'precision': 1.0, 'recall': 0.104, 'accuracy': 0.9573333333333334, 'average_precision': 0.4527537931744686, 'balanced_accuracy': 0.552, 'f1': 0.18840579710144925, 'roc_auc': 0.7210272}
==getted_scoring_result==
[fit 49/850] END C=0.001953125, gamma=8192.0, kernel=rbf; total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104
accuracy: (test=0.957) average_precision: (test=0.453) balanced_accuracy: (test=0.552) f1: (test=0.188) roc_auc: (test=0.721) 10.71s
==get_scoring_result==
base_score: total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.955) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 6, 'TN': 2500, 'FP': 0, 'FN': 119, 'precision': 1.0, 'recall': 0.048, 'accuracy': 0.9546666666666667, 'average_precision': 0.36870291568163915, 'balanced_accuracy': 0.524, 'f1': 0.0916030534351145, 'roc_auc': 0.6795536}
==getted_scoring_result==
[fit 50/850] END C=0.001953125, gamma=16384.0, kernel=rbf; total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048
accuracy: (test=0.955) average_precision: (test=0.369) balanced_accuracy: (test=0.524) f1: (test=0.092) roc_auc: (test=0.680) 10.37s
==get_scoring_result==
base_score: total=2625, TP=89, TN=828, FP=1672, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.349) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 828, 'FP': 1672, 'FN': 36, 'precision': 0.05053946621237933, 'recall': 0.712, 'accuracy': 0.34933333333333333, 'average_precision': 0.04619555504572405, 'balanced_accuracy': 0.5216, 'f1': 0.09437963944856839, 'roc_auc': 0.5067408}
==getted_scoring_result==
[fit 51/850] END C=0.00390625, gamma=0.0009765625, kernel=rbf; total=2625, TP=89, TN=828, FP=1672, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.349) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.507) 10.72s
==get_scoring_result==
base_score: total=2625, TP=88, TN=851, FP=1649, FN=37; precision=0.051, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 851, 'FP': 1649, 'FN': 37, 'precision': 0.050662061024755324, 'recall': 0.704, 'accuracy': 0.3577142857142857, 'average_precision': 0.046223361746920204, 'balanced_accuracy': 0.5222, 'f1': 0.09452201933404941, 'roc_auc': 0.506824}
==getted_scoring_result==
[fit 52/850] END C=0.00390625, gamma=0.001953125, kernel=rbf; total=2625, TP=88, TN=851, FP=1649, FN=37; precision=0.051, recall=0.704
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.095) roc_auc: (test=0.507) 10.00s
==get_scoring_result==
base_score: total=2625, TP=88, TN=849, FP=1651, FN=37; precision=0.051, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 849, 'FP': 1651, 'FN': 37, 'precision': 0.05060379528464635, 'recall': 0.704, 'accuracy': 0.35695238095238097, 'average_precision': 0.04619925414957336, 'balanced_accuracy': 0.5218, 'f1': 0.09442060085836909, 'roc_auc': 0.5067712}
==getted_scoring_result==
[fit 53/850] END C=0.00390625, gamma=0.00390625, kernel=rbf; total=2625, TP=88, TN=849, FP=1651, FN=37; precision=0.051, recall=0.704
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.507) 8.58s
==get_scoring_result==
base_score: total=2625, TP=89, TN=832, FP=1668, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.351) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 832, 'FP': 1668, 'FN': 36, 'precision': 0.050654524758110414, 'recall': 0.712, 'accuracy': 0.35085714285714287, 'average_precision': 0.04619194437794863, 'balanced_accuracy': 0.5224, 'f1': 0.09458023379383634, 'roc_auc': 0.506792}
==getted_scoring_result==
[fit 54/850] END C=0.00390625, gamma=0.0078125, kernel=rbf; total=2625, TP=89, TN=832, FP=1668, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.351) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.095) roc_auc: (test=0.507) 9.16s
==get_scoring_result==
base_score: total=2625, TP=87, TN=847, FP=1653, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.517) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 847, 'FP': 1653, 'FN': 38, 'precision': 0.05, 'recall': 0.696, 'accuracy': 0.3558095238095238, 'average_precision': 0.046190521526364506, 'balanced_accuracy': 0.5174, 'f1': 0.09329758713136728, 'roc_auc': 0.506648}
==getted_scoring_result==
[fit 55/850] END C=0.00390625, gamma=0.015625, kernel=rbf; total=2625, TP=87, TN=847, FP=1653, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.517) f1: (test=0.093) roc_auc: (test=0.507) 9.16s
==get_scoring_result==
base_score: total=2625, TP=87, TN=854, FP=1646, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 854, 'FP': 1646, 'FN': 38, 'precision': 0.05020196191575303, 'recall': 0.696, 'accuracy': 0.3584761904761905, 'average_precision': 0.04623074858369107, 'balanced_accuracy': 0.5187999999999999, 'f1': 0.09364908503767493, 'roc_auc': 0.5065376}
==getted_scoring_result==
[fit 56/850] END C=0.00390625, gamma=0.03125, kernel=rbf; total=2625, TP=87, TN=854, FP=1646, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.15s
==get_scoring_result==
base_score: total=2625, TP=87, TN=854, FP=1646, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 854, 'FP': 1646, 'FN': 38, 'precision': 0.05020196191575303, 'recall': 0.696, 'accuracy': 0.3584761904761905, 'average_precision': 0.0462252041147454, 'balanced_accuracy': 0.5187999999999999, 'f1': 0.09364908503767493, 'roc_auc': 0.5067296}
==getted_scoring_result==
[fit 57/850] END C=0.00390625, gamma=0.0625, kernel=rbf; total=2625, TP=87, TN=854, FP=1646, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.24s
==get_scoring_result==
base_score: total=2625, TP=87, TN=849, FP=1651, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 849, 'FP': 1651, 'FN': 38, 'precision': 0.05005753739930955, 'recall': 0.696, 'accuracy': 0.3565714285714286, 'average_precision': 0.046229486330412704, 'balanced_accuracy': 0.5178, 'f1': 0.09339774557165861, 'roc_auc': 0.5068736}
==getted_scoring_result==
[fit 58/850] END C=0.00390625, gamma=0.125, kernel=rbf; total=2625, TP=87, TN=849, FP=1651, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.65s
==get_scoring_result==
base_score: total=2625, TP=87, TN=850, FP=1650, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 850, 'FP': 1650, 'FN': 38, 'precision': 0.05008635578583765, 'recall': 0.696, 'accuracy': 0.35695238095238097, 'average_precision': 0.04625341841436505, 'balanced_accuracy': 0.518, 'f1': 0.09344790547798067, 'roc_auc': 0.5068704}
==getted_scoring_result==
[fit 59/850] END C=0.00390625, gamma=0.25, kernel=rbf; total=2625, TP=87, TN=850, FP=1650, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.42s
==get_scoring_result==
base_score: total=2625, TP=87, TN=851, FP=1649, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 851, 'FP': 1649, 'FN': 38, 'precision': 0.05011520737327189, 'recall': 0.696, 'accuracy': 0.35733333333333334, 'average_precision': 0.0462598568214499, 'balanced_accuracy': 0.5182, 'f1': 0.09349811929070391, 'roc_auc': 0.5072096}
==getted_scoring_result==
[fit 60/850] END C=0.00390625, gamma=0.5, kernel=rbf; total=2625, TP=87, TN=851, FP=1649, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.19s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1201, FP=1299, FN=59; precision=0.048, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.483) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.504) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.089) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1201, 'FP': 1299, 'FN': 59, 'precision': 0.04835164835164835, 'recall': 0.528, 'accuracy': 0.4826666666666667, 'average_precision': 0.046426625208889113, 'balanced_accuracy': 0.5042, 'f1': 0.08859060402684563, 'roc_auc': 0.5090544}
==getted_scoring_result==
[fit 61/850] END C=0.00390625, gamma=1.0, kernel=rbf; total=2625, TP=66, TN=1201, FP=1299, FN=59; precision=0.048, recall=0.528
accuracy: (test=0.483) average_precision: (test=0.046) balanced_accuracy: (test=0.504) f1: (test=0.089) roc_auc: (test=0.509) 9.06s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1213, FP=1287, FN=56; precision=0.051, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.488) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.514) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1213, 'FP': 1287, 'FN': 56, 'precision': 0.05088495575221239, 'recall': 0.552, 'accuracy': 0.48838095238095236, 'average_precision': 0.04711714867101413, 'balanced_accuracy': 0.5186000000000001, 'f1': 0.09318028359216746, 'roc_auc': 0.5140288}
==getted_scoring_result==
[fit 62/850] END C=0.00390625, gamma=2.0, kernel=rbf; total=2625, TP=69, TN=1213, FP=1287, FN=56; precision=0.051, recall=0.552
accuracy: (test=0.488) average_precision: (test=0.047) balanced_accuracy: (test=0.519) f1: (test=0.093) roc_auc: (test=0.514) 9.28s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1229, FP=1271, FN=58; precision=0.050, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.494) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.049) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.514) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.519) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1229, 'FP': 1271, 'FN': 58, 'precision': 0.05007473841554559, 'recall': 0.536, 'accuracy': 0.4937142857142857, 'average_precision': 0.048984049738987984, 'balanced_accuracy': 0.5138, 'f1': 0.09159261790840739, 'roc_auc': 0.5194304}
==getted_scoring_result==
[fit 63/850] END C=0.00390625, gamma=4.0, kernel=rbf; total=2625, TP=67, TN=1229, FP=1271, FN=58; precision=0.050, recall=0.536
accuracy: (test=0.494) average_precision: (test=0.049) balanced_accuracy: (test=0.514) f1: (test=0.092) roc_auc: (test=0.519) 9.09s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1239, FP=1261, FN=59; precision=0.050, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.497) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.052) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.512) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.530) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1239, 'FP': 1261, 'FN': 59, 'precision': 0.04973624717407687, 'recall': 0.528, 'accuracy': 0.49714285714285716, 'average_precision': 0.052262854453941264, 'balanced_accuracy': 0.5118, 'f1': 0.09090909090909093, 'roc_auc': 0.5298352}
==getted_scoring_result==
[fit 64/850] END C=0.00390625, gamma=8.0, kernel=rbf; total=2625, TP=66, TN=1239, FP=1261, FN=59; precision=0.050, recall=0.528
accuracy: (test=0.497) average_precision: (test=0.052) balanced_accuracy: (test=0.512) f1: (test=0.091) roc_auc: (test=0.530) 8.90s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1294, FP=1206, FN=58; precision=0.053, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.518) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.056) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.527) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.542) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1294, 'FP': 1206, 'FN': 58, 'precision': 0.05263157894736842, 'recall': 0.536, 'accuracy': 0.5184761904761904, 'average_precision': 0.056168972959729814, 'balanced_accuracy': 0.5267999999999999, 'f1': 0.09585121602288985, 'roc_auc': 0.5419616}
==getted_scoring_result==
[fit 65/850] END C=0.00390625, gamma=16.0, kernel=rbf; total=2625, TP=67, TN=1294, FP=1206, FN=58; precision=0.053, recall=0.536
accuracy: (test=0.518) average_precision: (test=0.056) balanced_accuracy: (test=0.527) f1: (test=0.096) roc_auc: (test=0.542) 9.39s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1336, FP=1164, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.534) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.066) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.535) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.099) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.552) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1336, 'FP': 1164, 'FN': 58, 'precision': 0.054427294882209584, 'recall': 0.536, 'accuracy': 0.5344761904761904, 'average_precision': 0.06632085683087473, 'balanced_accuracy': 0.5352, 'f1': 0.09882005899705015, 'roc_auc': 0.5521824}
==getted_scoring_result==
[fit 66/850] END C=0.00390625, gamma=32.0, kernel=rbf; total=2625, TP=67, TN=1336, FP=1164, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.534) average_precision: (test=0.066) balanced_accuracy: (test=0.535) f1: (test=0.099) roc_auc: (test=0.552) 9.58s
==get_scoring_result==
base_score: total=2625, TP=65, TN=1454, FP=1046, FN=60; precision=0.059, recall=0.520

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.579) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.069) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.551) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.105) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.566) ===
score_result_dict: {'Total': 2625, 'TP': 65, 'TN': 1454, 'FP': 1046, 'FN': 60, 'precision': 0.05850585058505851, 'recall': 0.52, 'accuracy': 0.5786666666666667, 'average_precision': 0.06921252500138103, 'balanced_accuracy': 0.5508, 'f1': 0.10517799352750808, 'roc_auc': 0.5662848}
==getted_scoring_result==
[fit 67/850] END C=0.00390625, gamma=64.0, kernel=rbf; total=2625, TP=65, TN=1454, FP=1046, FN=60; precision=0.059, recall=0.520
accuracy: (test=0.579) average_precision: (test=0.069) balanced_accuracy: (test=0.551) f1: (test=0.105) roc_auc: (test=0.566) 8.43s
==get_scoring_result==
base_score: total=2625, TP=36, TN=2087, FP=413, FN=89; precision=0.080, recall=0.288

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.809) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.110) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.561) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.125) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.624) ===
score_result_dict: {'Total': 2625, 'TP': 36, 'TN': 2087, 'FP': 413, 'FN': 89, 'precision': 0.0801781737193764, 'recall': 0.288, 'accuracy': 0.8087619047619048, 'average_precision': 0.11038740938668859, 'balanced_accuracy': 0.5614, 'f1': 0.1254355400696864, 'roc_auc': 0.6237056}
==getted_scoring_result==
[fit 68/850] END C=0.00390625, gamma=128.0, kernel=rbf; total=2625, TP=36, TN=2087, FP=413, FN=89; precision=0.080, recall=0.288
accuracy: (test=0.809) average_precision: (test=0.110) balanced_accuracy: (test=0.561) f1: (test=0.125) roc_auc: (test=0.624) 8.90s
==get_scoring_result==
base_score: total=2625, TP=32, TN=2459, FP=41, FN=93; precision=0.438, recall=0.256

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.949) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.337) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.620) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.323) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.770) ===
score_result_dict: {'Total': 2625, 'TP': 32, 'TN': 2459, 'FP': 41, 'FN': 93, 'precision': 0.4383561643835616, 'recall': 0.256, 'accuracy': 0.948952380952381, 'average_precision': 0.3373321441439144, 'balanced_accuracy': 0.6198, 'f1': 0.3232323232323232, 'roc_auc': 0.770176}
==getted_scoring_result==
[fit 69/850] END C=0.00390625, gamma=256.0, kernel=rbf; total=2625, TP=32, TN=2459, FP=41, FN=93; precision=0.438, recall=0.256
accuracy: (test=0.949) average_precision: (test=0.337) balanced_accuracy: (test=0.620) f1: (test=0.323) roc_auc: (test=0.770) 8.80s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.617) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.845) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6168401755004987, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.844832}
==getted_scoring_result==
[fit 70/850] END C=0.00390625, gamma=512.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.617) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.845) 9.24s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.850) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6547367858871069, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.8495008}
==getted_scoring_result==
[fit 71/850] END C=0.00390625, gamma=1024.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.655) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.850) 9.22s
==get_scoring_result==
base_score: total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.962) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.646) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.596) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.322) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.834) ===
score_result_dict: {'Total': 2625, 'TP': 24, 'TN': 2500, 'FP': 0, 'FN': 101, 'precision': 1.0, 'recall': 0.192, 'accuracy': 0.9615238095238096, 'average_precision': 0.6456260426071049, 'balanced_accuracy': 0.596, 'f1': 0.32214765100671144, 'roc_auc': 0.834336}
==getted_scoring_result==
[fit 72/850] END C=0.00390625, gamma=2048.0, kernel=rbf; total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192
accuracy: (test=0.962) average_precision: (test=0.646) balanced_accuracy: (test=0.596) f1: (test=0.322) roc_auc: (test=0.834) 9.33s
==get_scoring_result==
base_score: total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.960) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.588) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.584) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.288) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.808) ===
score_result_dict: {'Total': 2625, 'TP': 21, 'TN': 2500, 'FP': 0, 'FN': 104, 'precision': 1.0, 'recall': 0.168, 'accuracy': 0.9603809523809523, 'average_precision': 0.5881094919752591, 'balanced_accuracy': 0.584, 'f1': 0.28767123287671237, 'roc_auc': 0.808472}
==getted_scoring_result==
[fit 73/850] END C=0.00390625, gamma=4096.0, kernel=rbf; total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168
accuracy: (test=0.960) average_precision: (test=0.588) balanced_accuracy: (test=0.584) f1: (test=0.288) roc_auc: (test=0.808) 9.56s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=12, TN=2500, FP=0, FN=113; precision=1.000, recall=0.096

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.957) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.505) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.548) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.175) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.752) ===
score_result_dict: {'Total': 2625, 'TP': 12, 'TN': 2500, 'FP': 0, 'FN': 113, 'precision': 1.0, 'recall': 0.096, 'accuracy': 0.956952380952381, 'average_precision': 0.5051917476435988, 'balanced_accuracy': 0.548, 'f1': 0.1751824817518248, 'roc_auc': 0.752072}
==getted_scoring_result==
[fit 74/850] END C=0.00390625, gamma=8192.0, kernel=rbf; total=2625, TP=12, TN=2500, FP=0, FN=113; precision=1.000, recall=0.096
accuracy: (test=0.957) average_precision: (test=0.505) balanced_accuracy: (test=0.548) f1: (test=0.175) roc_auc: (test=0.752) 9.42s
==get_scoring_result==
base_score: total=2625, TP=4, TN=2500, FP=0, FN=121; precision=1.000, recall=0.032

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.954) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.353) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.516) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.062) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.672) ===
score_result_dict: {'Total': 2625, 'TP': 4, 'TN': 2500, 'FP': 0, 'FN': 121, 'precision': 1.0, 'recall': 0.032, 'accuracy': 0.9539047619047619, 'average_precision': 0.35349093774625695, 'balanced_accuracy': 0.516, 'f1': 0.06201550387596899, 'roc_auc': 0.671832}
==getted_scoring_result==
[fit 75/850] END C=0.00390625, gamma=16384.0, kernel=rbf; total=2625, TP=4, TN=2500, FP=0, FN=121; precision=1.000, recall=0.032
accuracy: (test=0.954) average_precision: (test=0.353) balanced_accuracy: (test=0.516) f1: (test=0.062) roc_auc: (test=0.672) 9.34s
==get_scoring_result==
base_score: total=2625, TP=90, TN=804, FP=1696, FN=35; precision=0.050, recall=0.720

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.341) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 90, 'TN': 804, 'FP': 1696, 'FN': 35, 'precision': 0.05039193729003359, 'recall': 0.72, 'accuracy': 0.3405714285714286, 'average_precision': 0.046173288372010166, 'balanced_accuracy': 0.5207999999999999, 'f1': 0.09419152276295134, 'roc_auc': 0.506728}
==getted_scoring_result==
[fit 76/850] END C=0.0078125, gamma=0.0009765625, kernel=rbf; total=2625, TP=90, TN=804, FP=1696, FN=35; precision=0.050, recall=0.720
accuracy: (test=0.341) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 9.24s
==get_scoring_result==
base_score: total=2625, TP=91, TN=764, FP=1736, FN=34; precision=0.050, recall=0.728

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.326) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.517) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 91, 'TN': 764, 'FP': 1736, 'FN': 34, 'precision': 0.04980842911877394, 'recall': 0.728, 'accuracy': 0.32571428571428573, 'average_precision': 0.04615656422237014, 'balanced_accuracy': 0.5167999999999999, 'f1': 0.09323770491803278, 'roc_auc': 0.5066848}
==getted_scoring_result==
[fit 77/850] END C=0.0078125, gamma=0.001953125, kernel=rbf; total=2625, TP=91, TN=764, FP=1736, FN=34; precision=0.050, recall=0.728
accuracy: (test=0.326) average_precision: (test=0.046) balanced_accuracy: (test=0.517) f1: (test=0.093) roc_auc: (test=0.507) 9.96s
==get_scoring_result==
base_score: total=2625, TP=88, TN=843, FP=1657, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.355) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 843, 'FP': 1657, 'FN': 37, 'precision': 0.0504297994269341, 'recall': 0.704, 'accuracy': 0.3546666666666667, 'average_precision': 0.0461928742443273, 'balanced_accuracy': 0.5206, 'f1': 0.09411764705882353, 'roc_auc': 0.5067552}
==getted_scoring_result==
[fit 78/850] END C=0.0078125, gamma=0.00390625, kernel=rbf; total=2625, TP=88, TN=843, FP=1657, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.355) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 9.75s
==get_scoring_result==
base_score: total=2625, TP=87, TN=846, FP=1654, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.355) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.517) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 846, 'FP': 1654, 'FN': 38, 'precision': 0.049971280873061456, 'recall': 0.696, 'accuracy': 0.3554285714285714, 'average_precision': 0.04618617229443661, 'balanced_accuracy': 0.5172, 'f1': 0.0932475884244373, 'roc_auc': 0.5065904}
==getted_scoring_result==
[fit 79/850] END C=0.0078125, gamma=0.0078125, kernel=rbf; total=2625, TP=87, TN=846, FP=1654, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.355) average_precision: (test=0.046) balanced_accuracy: (test=0.517) f1: (test=0.093) roc_auc: (test=0.507) 9.85s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.04622486475330709, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.506544}
==getted_scoring_result==
[fit 80/850] END C=0.0078125, gamma=0.015625, kernel=rbf; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.72s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.04623233891259225, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.5065648}
==getted_scoring_result==
[fit 81/850] END C=0.0078125, gamma=0.03125, kernel=rbf; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.93s
==get_scoring_result==
base_score: total=2625, TP=87, TN=853, FP=1647, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 853, 'FP': 1647, 'FN': 38, 'precision': 0.050173010380622836, 'recall': 0.696, 'accuracy': 0.3580952380952381, 'average_precision': 0.04622820409809193, 'balanced_accuracy': 0.5186, 'f1': 0.09359870898332437, 'roc_auc': 0.5067072}
==getted_scoring_result==
[fit 82/850] END C=0.0078125, gamma=0.0625, kernel=rbf; total=2625, TP=87, TN=853, FP=1647, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.87s
==get_scoring_result==
base_score: total=2625, TP=87, TN=850, FP=1650, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 850, 'FP': 1650, 'FN': 38, 'precision': 0.05008635578583765, 'recall': 0.696, 'accuracy': 0.35695238095238097, 'average_precision': 0.04624378968190511, 'balanced_accuracy': 0.518, 'f1': 0.09344790547798067, 'roc_auc': 0.5067744}
==getted_scoring_result==
[fit 83/850] END C=0.0078125, gamma=0.125, kernel=rbf; total=2625, TP=87, TN=850, FP=1650, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.89s
==get_scoring_result==
base_score: total=2625, TP=87, TN=849, FP=1651, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 849, 'FP': 1651, 'FN': 38, 'precision': 0.05005753739930955, 'recall': 0.696, 'accuracy': 0.3565714285714286, 'average_precision': 0.04626028674728298, 'balanced_accuracy': 0.5178, 'f1': 0.09339774557165861, 'roc_auc': 0.5068864}
==getted_scoring_result==
[fit 84/850] END C=0.0078125, gamma=0.25, kernel=rbf; total=2625, TP=87, TN=849, FP=1651, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.61s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1198, FP=1302, FN=59; precision=0.048, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.482) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.504) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.088) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1198, 'FP': 1302, 'FN': 59, 'precision': 0.04824561403508772, 'recall': 0.528, 'accuracy': 0.4815238095238095, 'average_precision': 0.046416400105905885, 'balanced_accuracy': 0.5036, 'f1': 0.08841259209645008, 'roc_auc': 0.5089552}
==getted_scoring_result==
[fit 85/850] END C=0.0078125, gamma=0.5, kernel=rbf; total=2625, TP=66, TN=1198, FP=1302, FN=59; precision=0.048, recall=0.528
accuracy: (test=0.482) average_precision: (test=0.046) balanced_accuracy: (test=0.504) f1: (test=0.088) roc_auc: (test=0.509) 9.47s
==get_scoring_result==
base_score: total=2625, TP=52, TN=1486, FP=1014, FN=73; precision=0.049, recall=0.416

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.586) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.505) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.087) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.514) ===
score_result_dict: {'Total': 2625, 'TP': 52, 'TN': 1486, 'FP': 1014, 'FN': 73, 'precision': 0.04878048780487805, 'recall': 0.416, 'accuracy': 0.5859047619047619, 'average_precision': 0.04709431545664075, 'balanced_accuracy': 0.5052, 'f1': 0.0873215785054576, 'roc_auc': 0.5144352}
==getted_scoring_result==
[fit 86/850] END C=0.0078125, gamma=1.0, kernel=rbf; total=2625, TP=52, TN=1486, FP=1014, FN=73; precision=0.049, recall=0.416
accuracy: (test=0.586) average_precision: (test=0.047) balanced_accuracy: (test=0.505) f1: (test=0.087) roc_auc: (test=0.514) 9.36s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1237, FP=1263, FN=57; precision=0.051, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.497) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.521) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1237, 'FP': 1263, 'FN': 57, 'precision': 0.05108940646130729, 'recall': 0.544, 'accuracy': 0.49714285714285716, 'average_precision': 0.04802752556116573, 'balanced_accuracy': 0.5194000000000001, 'f1': 0.0934065934065934, 'roc_auc': 0.5208032}
==getted_scoring_result==
[fit 87/850] END C=0.0078125, gamma=2.0, kernel=rbf; total=2625, TP=68, TN=1237, FP=1263, FN=57; precision=0.051, recall=0.544
accuracy: (test=0.497) average_precision: (test=0.048) balanced_accuracy: (test=0.519) f1: (test=0.093) roc_auc: (test=0.521) 9.28s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1247, FP=1253, FN=58; precision=0.051, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.501) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.517) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.531) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1247, 'FP': 1253, 'FN': 58, 'precision': 0.05075757575757576, 'recall': 0.536, 'accuracy': 0.5005714285714286, 'average_precision': 0.05048768409430712, 'balanced_accuracy': 0.5174000000000001, 'f1': 0.09273356401384084, 'roc_auc': 0.5313152}
==getted_scoring_result==
[fit 88/850] END C=0.0078125, gamma=4.0, kernel=rbf; total=2625, TP=67, TN=1247, FP=1253, FN=58; precision=0.051, recall=0.536
accuracy: (test=0.501) average_precision: (test=0.050) balanced_accuracy: (test=0.517) f1: (test=0.093) roc_auc: (test=0.531) 9.15s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1287, FP=1213, FN=57; precision=0.053, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.516) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.054) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.529) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.097) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.545) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1287, 'FP': 1213, 'FN': 57, 'precision': 0.05308352849336456, 'recall': 0.544, 'accuracy': 0.5161904761904762, 'average_precision': 0.05425222902938169, 'balanced_accuracy': 0.5294000000000001, 'f1': 0.09672830725462304, 'roc_auc': 0.544992}
==getted_scoring_result==
[fit 89/850] END C=0.0078125, gamma=8.0, kernel=rbf; total=2625, TP=68, TN=1287, FP=1213, FN=57; precision=0.053, recall=0.544
accuracy: (test=0.516) average_precision: (test=0.054) balanced_accuracy: (test=0.529) f1: (test=0.097) roc_auc: (test=0.545) 9.64s
==get_scoring_result==
base_score: total=2625, TP=65, TN=1357, FP=1143, FN=60; precision=0.054, recall=0.520

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.542) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.059) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.531) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.560) ===
score_result_dict: {'Total': 2625, 'TP': 65, 'TN': 1357, 'FP': 1143, 'FN': 60, 'precision': 0.05380794701986755, 'recall': 0.52, 'accuracy': 0.5417142857142857, 'average_precision': 0.059226423449343944, 'balanced_accuracy': 0.5314, 'f1': 0.09752438109527381, 'roc_auc': 0.5599712}
==getted_scoring_result==
[fit 90/850] END C=0.0078125, gamma=16.0, kernel=rbf; total=2625, TP=65, TN=1357, FP=1143, FN=60; precision=0.054, recall=0.520
accuracy: (test=0.542) average_precision: (test=0.059) balanced_accuracy: (test=0.531) f1: (test=0.098) roc_auc: (test=0.560) 9.66s
==get_scoring_result==
base_score: total=2625, TP=62, TN=1447, FP=1053, FN=63; precision=0.056, recall=0.496

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.575) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.066) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.537) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.100) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.574) ===
score_result_dict: {'Total': 2625, 'TP': 62, 'TN': 1447, 'FP': 1053, 'FN': 63, 'precision': 0.05560538116591928, 'recall': 0.496, 'accuracy': 0.5748571428571428, 'average_precision': 0.06607328855695409, 'balanced_accuracy': 0.5374, 'f1': 0.09999999999999999, 'roc_auc': 0.5744752}
==getted_scoring_result==
[fit 91/850] END C=0.0078125, gamma=32.0, kernel=rbf; total=2625, TP=62, TN=1447, FP=1053, FN=63; precision=0.056, recall=0.496
accuracy: (test=0.575) average_precision: (test=0.066) balanced_accuracy: (test=0.537) f1: (test=0.100) roc_auc: (test=0.574) 9.55s
==get_scoring_result==
base_score: total=2625, TP=60, TN=1523, FP=977, FN=65; precision=0.058, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.603) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.074) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.545) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.587) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 1523, 'FP': 977, 'FN': 65, 'precision': 0.05785920925747348, 'recall': 0.48, 'accuracy': 0.603047619047619, 'average_precision': 0.07400747171261088, 'balanced_accuracy': 0.5446, 'f1': 0.10327022375215147, 'roc_auc': 0.5873296}
==getted_scoring_result==
[fit 92/850] END C=0.0078125, gamma=64.0, kernel=rbf; total=2625, TP=60, TN=1523, FP=977, FN=65; precision=0.058, recall=0.480
accuracy: (test=0.603) average_precision: (test=0.074) balanced_accuracy: (test=0.545) f1: (test=0.103) roc_auc: (test=0.587) 9.27s
==get_scoring_result==
base_score: total=2625, TP=36, TN=2087, FP=413, FN=89; precision=0.080, recall=0.288

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.809) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.110) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.561) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.125) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.624) ===
score_result_dict: {'Total': 2625, 'TP': 36, 'TN': 2087, 'FP': 413, 'FN': 89, 'precision': 0.0801781737193764, 'recall': 0.288, 'accuracy': 0.8087619047619048, 'average_precision': 0.11038933854849181, 'balanced_accuracy': 0.5614, 'f1': 0.1254355400696864, 'roc_auc': 0.6237056}
==getted_scoring_result==
[fit 93/850] END C=0.0078125, gamma=128.0, kernel=rbf; total=2625, TP=36, TN=2087, FP=413, FN=89; precision=0.080, recall=0.288
accuracy: (test=0.809) average_precision: (test=0.110) balanced_accuracy: (test=0.561) f1: (test=0.125) roc_auc: (test=0.624) 9.19s
==get_scoring_result==
base_score: total=2625, TP=32, TN=2459, FP=41, FN=93; precision=0.438, recall=0.256

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.949) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.337) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.620) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.323) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.770) ===
score_result_dict: {'Total': 2625, 'TP': 32, 'TN': 2459, 'FP': 41, 'FN': 93, 'precision': 0.4383561643835616, 'recall': 0.256, 'accuracy': 0.948952380952381, 'average_precision': 0.3373293147304559, 'balanced_accuracy': 0.6198, 'f1': 0.3232323232323232, 'roc_auc': 0.7701728}
==getted_scoring_result==
[fit 94/850] END C=0.0078125, gamma=256.0, kernel=rbf; total=2625, TP=32, TN=2459, FP=41, FN=93; precision=0.438, recall=0.256
accuracy: (test=0.949) average_precision: (test=0.337) balanced_accuracy: (test=0.620) f1: (test=0.323) roc_auc: (test=0.770) 9.38s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.617) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.845) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6168475653372076, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.8448416}
==getted_scoring_result==
[fit 95/850] END C=0.0078125, gamma=512.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.617) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.845) 9.17s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.850) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6547373550963167, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.8495024}
==getted_scoring_result==
[fit 96/850] END C=0.0078125, gamma=1024.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.655) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.850) 9.45s
==get_scoring_result==
base_score: total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.962) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.646) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.596) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.322) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.834) ===
score_result_dict: {'Total': 2625, 'TP': 24, 'TN': 2500, 'FP': 0, 'FN': 101, 'precision': 1.0, 'recall': 0.192, 'accuracy': 0.9615238095238096, 'average_precision': 0.6461135559250566, 'balanced_accuracy': 0.596, 'f1': 0.32214765100671144, 'roc_auc': 0.8338832}
==getted_scoring_result==
[fit 97/850] END C=0.0078125, gamma=2048.0, kernel=rbf; total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192
accuracy: (test=0.962) average_precision: (test=0.646) balanced_accuracy: (test=0.596) f1: (test=0.322) roc_auc: (test=0.834) 9.92s
==get_scoring_result==
base_score: total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.960) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.588) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.584) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.288) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.808) ===
score_result_dict: {'Total': 2625, 'TP': 21, 'TN': 2500, 'FP': 0, 'FN': 104, 'precision': 1.0, 'recall': 0.168, 'accuracy': 0.9603809523809523, 'average_precision': 0.588344110798175, 'balanced_accuracy': 0.584, 'f1': 0.28767123287671237, 'roc_auc': 0.8078288}
==getted_scoring_result==
[fit 98/850] END C=0.0078125, gamma=4096.0, kernel=rbf; total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168
accuracy: (test=0.960) average_precision: (test=0.588) balanced_accuracy: (test=0.584) f1: (test=0.288) roc_auc: (test=0.808) 9.79s
==get_scoring_result==
base_score: total=2625, TP=12, TN=2500, FP=0, FN=113; precision=1.000, recall=0.096

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.957) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.505) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.548) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.175) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.752) ===
score_result_dict: {'Total': 2625, 'TP': 12, 'TN': 2500, 'FP': 0, 'FN': 113, 'precision': 1.0, 'recall': 0.096, 'accuracy': 0.956952380952381, 'average_precision': 0.5051917476435988, 'balanced_accuracy': 0.548, 'f1': 0.1751824817518248, 'roc_auc': 0.752072}
==getted_scoring_result==
[fit 99/850] END C=0.0078125, gamma=8192.0, kernel=rbf; total=2625, TP=12, TN=2500, FP=0, FN=113; precision=1.000, recall=0.096
accuracy: (test=0.957) average_precision: (test=0.505) balanced_accuracy: (test=0.548) f1: (test=0.175) roc_auc: (test=0.752) 10.39s
==get_scoring_result==
base_score: total=2625, TP=125, TN=15, FP=2485, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.053) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.353) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.503) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.672) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 15, 'FP': 2485, 'FN': 0, 'precision': 0.04789272030651341, 'recall': 1.0, 'accuracy': 0.05333333333333334, 'average_precision': 0.35349093774625695, 'balanced_accuracy': 0.503, 'f1': 0.09140767824497259, 'roc_auc': 0.671832}
==getted_scoring_result==
[fit 100/850] END C=0.0078125, gamma=16384.0, kernel=rbf; total=2625, TP=125, TN=15, FP=2485, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.053) average_precision: (test=0.353) balanced_accuracy: (test=0.503) f1: (test=0.091) roc_auc: (test=0.672) 10.93s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.04620544001950866, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.5065872}
==getted_scoring_result==
[fit 101/850] END C=0.015625, gamma=0.0009765625, kernel=rbf; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.43s
==get_scoring_result==
base_score: total=2625, TP=89, TN=827, FP=1673, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.349) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 827, 'FP': 1673, 'FN': 36, 'precision': 0.05051078320090806, 'recall': 0.712, 'accuracy': 0.34895238095238096, 'average_precision': 0.046201489600223994, 'balanced_accuracy': 0.5214, 'f1': 0.09432962374138845, 'roc_auc': 0.5067328}
==getted_scoring_result==
[fit 102/850] END C=0.015625, gamma=0.001953125, kernel=rbf; total=2625, TP=89, TN=827, FP=1673, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.349) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 9.63s
==get_scoring_result==
base_score: total=2625, TP=88, TN=847, FP=1653, FN=37; precision=0.051, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 847, 'FP': 1653, 'FN': 37, 'precision': 0.05054566341183228, 'recall': 0.704, 'accuracy': 0.35619047619047617, 'average_precision': 0.046209970284832556, 'balanced_accuracy': 0.5214, 'f1': 0.09431939978563772, 'roc_auc': 0.506768}
==getted_scoring_result==
[fit 103/850] END C=0.015625, gamma=0.00390625, kernel=rbf; total=2625, TP=88, TN=847, FP=1653, FN=37; precision=0.051, recall=0.704
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 9.85s
==get_scoring_result==
base_score: total=2625, TP=87, TN=859, FP=1641, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 859, 'FP': 1641, 'FN': 38, 'precision': 0.050347222222222224, 'recall': 0.696, 'accuracy': 0.36038095238095236, 'average_precision': 0.04623629996407145, 'balanced_accuracy': 0.5198, 'f1': 0.09390178089584458, 'roc_auc': 0.5065952}
==getted_scoring_result==
[fit 104/850] END C=0.015625, gamma=0.0078125, kernel=rbf; total=2625, TP=87, TN=859, FP=1641, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.73s
==get_scoring_result==
base_score: total=2625, TP=87, TN=854, FP=1646, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 854, 'FP': 1646, 'FN': 38, 'precision': 0.05020196191575303, 'recall': 0.696, 'accuracy': 0.3584761904761905, 'average_precision': 0.04621677645776366, 'balanced_accuracy': 0.5187999999999999, 'f1': 0.09364908503767493, 'roc_auc': 0.5066784}
==getted_scoring_result==
[fit 105/850] END C=0.015625, gamma=0.015625, kernel=rbf; total=2625, TP=87, TN=854, FP=1646, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.65s
==get_scoring_result==
base_score: total=2625, TP=87, TN=854, FP=1646, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 854, 'FP': 1646, 'FN': 38, 'precision': 0.05020196191575303, 'recall': 0.696, 'accuracy': 0.3584761904761905, 'average_precision': 0.04621802275549457, 'balanced_accuracy': 0.5187999999999999, 'f1': 0.09364908503767493, 'roc_auc': 0.5067168}
==getted_scoring_result==
[fit 106/850] END C=0.015625, gamma=0.03125, kernel=rbf; total=2625, TP=87, TN=854, FP=1646, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.71s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.04623903377297349, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.5068176}
==getted_scoring_result==
[fit 107/850] END C=0.015625, gamma=0.0625, kernel=rbf; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 10.49s
==get_scoring_result==
base_score: total=2625, TP=87, TN=850, FP=1650, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.357) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 850, 'FP': 1650, 'FN': 38, 'precision': 0.05008635578583765, 'recall': 0.696, 'accuracy': 0.35695238095238097, 'average_precision': 0.046247134512819546, 'balanced_accuracy': 0.518, 'f1': 0.09344790547798067, 'roc_auc': 0.5067808}
==getted_scoring_result==
[fit 108/850] END C=0.015625, gamma=0.125, kernel=rbf; total=2625, TP=87, TN=850, FP=1650, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.357) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 10.52s
==get_scoring_result==
base_score: total=2625, TP=77, TN=1018, FP=1482, FN=48; precision=0.049, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.417) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.512) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 1018, 'FP': 1482, 'FN': 48, 'precision': 0.04939063502245029, 'recall': 0.616, 'accuracy': 0.41714285714285715, 'average_precision': 0.046384068669961656, 'balanced_accuracy': 0.5116, 'f1': 0.09144893111638953, 'roc_auc': 0.5087616}
==getted_scoring_result==
[fit 109/850] END C=0.015625, gamma=0.25, kernel=rbf; total=2625, TP=77, TN=1018, FP=1482, FN=48; precision=0.049, recall=0.616
accuracy: (test=0.417) average_precision: (test=0.046) balanced_accuracy: (test=0.512) f1: (test=0.091) roc_auc: (test=0.509) 10.60s
==get_scoring_result==
base_score: total=2625, TP=51, TN=1495, FP=1005, FN=74; precision=0.048, recall=0.408

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.589) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.503) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.086) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.515) ===
score_result_dict: {'Total': 2625, 'TP': 51, 'TN': 1495, 'FP': 1005, 'FN': 74, 'precision': 0.048295454545454544, 'recall': 0.408, 'accuracy': 0.588952380952381, 'average_precision': 0.04710478199980084, 'balanced_accuracy': 0.503, 'f1': 0.08636748518204912, 'roc_auc': 0.5149568}
==getted_scoring_result==
[fit 110/850] END C=0.015625, gamma=0.5, kernel=rbf; total=2625, TP=51, TN=1495, FP=1005, FN=74; precision=0.048, recall=0.408
accuracy: (test=0.589) average_precision: (test=0.047) balanced_accuracy: (test=0.503) f1: (test=0.086) roc_auc: (test=0.515) 11.73s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1280, FP=1220, FN=57; precision=0.053, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.514) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.528) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.522) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1280, 'FP': 1220, 'FN': 57, 'precision': 0.052795031055900624, 'recall': 0.544, 'accuracy': 0.5135238095238095, 'average_precision': 0.047999804140031486, 'balanced_accuracy': 0.528, 'f1': 0.09624911535739561, 'roc_auc': 0.5221312}
==getted_scoring_result==
[fit 111/850] END C=0.015625, gamma=1.0, kernel=rbf; total=2625, TP=68, TN=1280, FP=1220, FN=57; precision=0.053, recall=0.544
accuracy: (test=0.514) average_precision: (test=0.048) balanced_accuracy: (test=0.528) f1: (test=0.096) roc_auc: (test=0.522) 11.28s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1270, FP=1230, FN=58; precision=0.052, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.509) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.533) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1270, 'FP': 1230, 'FN': 58, 'precision': 0.051657671549730146, 'recall': 0.536, 'accuracy': 0.5093333333333333, 'average_precision': 0.050027625661092034, 'balanced_accuracy': 0.522, 'f1': 0.09423347398030943, 'roc_auc': 0.5333584}
==getted_scoring_result==
[fit 112/850] END C=0.015625, gamma=2.0, kernel=rbf; total=2625, TP=67, TN=1270, FP=1230, FN=58; precision=0.052, recall=0.536
accuracy: (test=0.509) average_precision: (test=0.050) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.533) 11.39s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1291, FP=1209, FN=56; precision=0.054, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.518) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.534) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.548) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1291, 'FP': 1209, 'FN': 56, 'precision': 0.0539906103286385, 'recall': 0.552, 'accuracy': 0.518095238095238, 'average_precision': 0.053087531918396616, 'balanced_accuracy': 0.5342, 'f1': 0.09836065573770492, 'roc_auc': 0.547976}
==getted_scoring_result==
[fit 113/850] END C=0.015625, gamma=4.0, kernel=rbf; total=2625, TP=69, TN=1291, FP=1209, FN=56; precision=0.054, recall=0.552
accuracy: (test=0.518) average_precision: (test=0.053) balanced_accuracy: (test=0.534) f1: (test=0.098) roc_auc: (test=0.548) 10.42s
==get_scoring_result==
base_score: total=2625, TP=65, TN=1377, FP=1123, FN=60; precision=0.055, recall=0.520

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.549) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.059) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.535) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.099) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.566) ===
score_result_dict: {'Total': 2625, 'TP': 65, 'TN': 1377, 'FP': 1123, 'FN': 60, 'precision': 0.054713804713804715, 'recall': 0.52, 'accuracy': 0.5493333333333333, 'average_precision': 0.05891114326235944, 'balanced_accuracy': 0.5354, 'f1': 0.09900990099009901, 'roc_auc': 0.5661872}
==getted_scoring_result==
[fit 114/850] END C=0.015625, gamma=8.0, kernel=rbf; total=2625, TP=65, TN=1377, FP=1123, FN=60; precision=0.055, recall=0.520
accuracy: (test=0.549) average_precision: (test=0.059) balanced_accuracy: (test=0.535) f1: (test=0.099) roc_auc: (test=0.566) 9.53s
==get_scoring_result==
base_score: total=2625, TP=65, TN=1452, FP=1048, FN=60; precision=0.058, recall=0.520

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.578) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.066) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.550) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.105) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.587) ===
score_result_dict: {'Total': 2625, 'TP': 65, 'TN': 1452, 'FP': 1048, 'FN': 60, 'precision': 0.05840071877807727, 'recall': 0.52, 'accuracy': 0.5779047619047619, 'average_precision': 0.0663426072842147, 'balanced_accuracy': 0.5504, 'f1': 0.10500807754442648, 'roc_auc': 0.5865184}
==getted_scoring_result==
[fit 115/850] END C=0.015625, gamma=16.0, kernel=rbf; total=2625, TP=65, TN=1452, FP=1048, FN=60; precision=0.058, recall=0.520
accuracy: (test=0.578) average_precision: (test=0.066) balanced_accuracy: (test=0.550) f1: (test=0.105) roc_auc: (test=0.587) 9.38s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=61, TN=1525, FP=975, FN=64; precision=0.059, recall=0.488

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.604) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.549) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.105) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.610) ===
score_result_dict: {'Total': 2625, 'TP': 61, 'TN': 1525, 'FP': 975, 'FN': 64, 'precision': 0.05888030888030888, 'recall': 0.488, 'accuracy': 0.6041904761904762, 'average_precision': 0.07504334490014912, 'balanced_accuracy': 0.5489999999999999, 'f1': 0.10508182601205857, 'roc_auc': 0.6095008}
==getted_scoring_result==
[fit 116/850] END C=0.015625, gamma=32.0, kernel=rbf; total=2625, TP=61, TN=1525, FP=975, FN=64; precision=0.059, recall=0.488
accuracy: (test=0.604) average_precision: (test=0.075) balanced_accuracy: (test=0.549) f1: (test=0.105) roc_auc: (test=0.610) 9.45s
==get_scoring_result==
base_score: total=2625, TP=60, TN=1641, FP=859, FN=65; precision=0.065, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.648) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.089) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.115) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.628) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 1641, 'FP': 859, 'FN': 65, 'precision': 0.06528835690968444, 'recall': 0.48, 'accuracy': 0.648, 'average_precision': 0.0894027602382231, 'balanced_accuracy': 0.5682, 'f1': 0.11494252873563218, 'roc_auc': 0.6282944}
==getted_scoring_result==
[fit 117/850] END C=0.015625, gamma=64.0, kernel=rbf; total=2625, TP=60, TN=1641, FP=859, FN=65; precision=0.065, recall=0.480
accuracy: (test=0.648) average_precision: (test=0.089) balanced_accuracy: (test=0.568) f1: (test=0.115) roc_auc: (test=0.628) 9.39s
==get_scoring_result==
base_score: total=2625, TP=60, TN=1805, FP=695, FN=65; precision=0.079, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.710) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.139) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.601) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.136) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.646) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 1805, 'FP': 695, 'FN': 65, 'precision': 0.07947019867549669, 'recall': 0.48, 'accuracy': 0.7104761904761905, 'average_precision': 0.13898617049888348, 'balanced_accuracy': 0.601, 'f1': 0.13636363636363638, 'roc_auc': 0.6458576}
==getted_scoring_result==
[fit 118/850] END C=0.015625, gamma=128.0, kernel=rbf; total=2625, TP=60, TN=1805, FP=695, FN=65; precision=0.079, recall=0.480
accuracy: (test=0.710) average_precision: (test=0.139) balanced_accuracy: (test=0.601) f1: (test=0.136) roc_auc: (test=0.646) 9.58s
==get_scoring_result==
base_score: total=2625, TP=32, TN=2459, FP=41, FN=93; precision=0.438, recall=0.256

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.949) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.337) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.620) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.323) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.770) ===
score_result_dict: {'Total': 2625, 'TP': 32, 'TN': 2459, 'FP': 41, 'FN': 93, 'precision': 0.4383561643835616, 'recall': 0.256, 'accuracy': 0.948952380952381, 'average_precision': 0.3373293147304559, 'balanced_accuracy': 0.6198, 'f1': 0.3232323232323232, 'roc_auc': 0.7701728}
==getted_scoring_result==
[fit 119/850] END C=0.015625, gamma=256.0, kernel=rbf; total=2625, TP=32, TN=2459, FP=41, FN=93; precision=0.438, recall=0.256
accuracy: (test=0.949) average_precision: (test=0.337) balanced_accuracy: (test=0.620) f1: (test=0.323) roc_auc: (test=0.770) 9.64s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.617) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.845) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6168475653372076, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.8448416}
==getted_scoring_result==
[fit 120/850] END C=0.015625, gamma=512.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.617) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.845) 9.71s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.850) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.654736372778631, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.8495024}
==getted_scoring_result==
[fit 121/850] END C=0.015625, gamma=1024.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.655) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.850) 10.70s
==get_scoring_result==
base_score: total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.962) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.646) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.596) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.322) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.833) ===
score_result_dict: {'Total': 2625, 'TP': 24, 'TN': 2500, 'FP': 0, 'FN': 101, 'precision': 1.0, 'recall': 0.192, 'accuracy': 0.9615238095238096, 'average_precision': 0.6461371829684166, 'balanced_accuracy': 0.596, 'f1': 0.32214765100671144, 'roc_auc': 0.832528}
==getted_scoring_result==
[fit 122/850] END C=0.015625, gamma=2048.0, kernel=rbf; total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192
accuracy: (test=0.962) average_precision: (test=0.646) balanced_accuracy: (test=0.596) f1: (test=0.322) roc_auc: (test=0.833) 11.25s
==get_scoring_result==
base_score: total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.960) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.608) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.584) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.288) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.812) ===
score_result_dict: {'Total': 2625, 'TP': 21, 'TN': 2500, 'FP': 0, 'FN': 104, 'precision': 1.0, 'recall': 0.168, 'accuracy': 0.9603809523809523, 'average_precision': 0.6077955126223025, 'balanced_accuracy': 0.584, 'f1': 0.28767123287671237, 'roc_auc': 0.8124784}
==getted_scoring_result==
[fit 123/850] END C=0.015625, gamma=4096.0, kernel=rbf; total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168
accuracy: (test=0.960) average_precision: (test=0.608) balanced_accuracy: (test=0.584) f1: (test=0.288) roc_auc: (test=0.812) 11.42s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.957) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.453) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.552) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.188) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.721) ===
score_result_dict: {'Total': 2625, 'TP': 13, 'TN': 2500, 'FP': 0, 'FN': 112, 'precision': 1.0, 'recall': 0.104, 'accuracy': 0.9573333333333334, 'average_precision': 0.45272001120289046, 'balanced_accuracy': 0.552, 'f1': 0.18840579710144925, 'roc_auc': 0.7206864}
==getted_scoring_result==
[fit 124/850] END C=0.015625, gamma=8192.0, kernel=rbf; total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104
accuracy: (test=0.957) average_precision: (test=0.453) balanced_accuracy: (test=0.552) f1: (test=0.188) roc_auc: (test=0.721) 11.53s
==get_scoring_result==
base_score: total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.955) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.353) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.670) ===
score_result_dict: {'Total': 2625, 'TP': 6, 'TN': 2500, 'FP': 0, 'FN': 119, 'precision': 1.0, 'recall': 0.048, 'accuracy': 0.9546666666666667, 'average_precision': 0.35342089424285944, 'balanced_accuracy': 0.524, 'f1': 0.0916030534351145, 'roc_auc': 0.6698704}
==getted_scoring_result==
[fit 125/850] END C=0.015625, gamma=16384.0, kernel=rbf; total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048
accuracy: (test=0.955) average_precision: (test=0.353) balanced_accuracy: (test=0.524) f1: (test=0.092) roc_auc: (test=0.670) 10.75s
==get_scoring_result==
base_score: total=2625, TP=88, TN=842, FP=1658, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.354) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 842, 'FP': 1658, 'FN': 37, 'precision': 0.050400916380297825, 'recall': 0.704, 'accuracy': 0.35428571428571426, 'average_precision': 0.04618967965287904, 'balanced_accuracy': 0.5204, 'f1': 0.0940673436664885, 'roc_auc': 0.5067152}
==getted_scoring_result==
[fit 126/850] END C=0.03125, gamma=0.0009765625, kernel=rbf; total=2625, TP=88, TN=842, FP=1658, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.354) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.14s
==get_scoring_result==
base_score: total=2625, TP=88, TN=840, FP=1660, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.354) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 840, 'FP': 1660, 'FN': 37, 'precision': 0.05034324942791762, 'recall': 0.704, 'accuracy': 0.3535238095238095, 'average_precision': 0.04619426573298584, 'balanced_accuracy': 0.52, 'f1': 0.09396689802455954, 'roc_auc': 0.5067136}
==getted_scoring_result==
[fit 127/850] END C=0.03125, gamma=0.001953125, kernel=rbf; total=2625, TP=88, TN=840, FP=1660, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.354) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.27s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.046221209833089784, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.5065088}
==getted_scoring_result==
[fit 128/850] END C=0.03125, gamma=0.00390625, kernel=rbf; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.44s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.04623243050329637, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.5065744}
==getted_scoring_result==
[fit 129/850] END C=0.03125, gamma=0.0078125, kernel=rbf; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.42s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.046236545932222144, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.5066112}
==getted_scoring_result==
[fit 130/850] END C=0.03125, gamma=0.015625, kernel=rbf; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.46s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.046236101413417455, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.5066368}
==getted_scoring_result==
[fit 131/850] END C=0.03125, gamma=0.03125, kernel=rbf; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.44s
==get_scoring_result==
base_score: total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 856, 'FP': 1644, 'FN': 38, 'precision': 0.05025996533795494, 'recall': 0.696, 'accuracy': 0.35923809523809525, 'average_precision': 0.04625248251855619, 'balanced_accuracy': 0.5192, 'f1': 0.09374999999999999, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 132/850] END C=0.03125, gamma=0.0625, kernel=rbf; total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.24s
==get_scoring_result==
base_score: total=2625, TP=80, TN=964, FP=1536, FN=45; precision=0.050, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.398) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.513) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 964, 'FP': 1536, 'FN': 45, 'precision': 0.04950495049504951, 'recall': 0.64, 'accuracy': 0.3977142857142857, 'average_precision': 0.04642926117363739, 'balanced_accuracy': 0.5128, 'f1': 0.0919012062033314, 'roc_auc': 0.5092384}
==getted_scoring_result==
[fit 133/850] END C=0.03125, gamma=0.125, kernel=rbf; total=2625, TP=80, TN=964, FP=1536, FN=45; precision=0.050, recall=0.640
accuracy: (test=0.398) average_precision: (test=0.046) balanced_accuracy: (test=0.513) f1: (test=0.092) roc_auc: (test=0.509) 9.30s
==get_scoring_result==
base_score: total=2625, TP=44, TN=1582, FP=918, FN=81; precision=0.046, recall=0.352

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.619) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.492) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.081) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.514) ===
score_result_dict: {'Total': 2625, 'TP': 44, 'TN': 1582, 'FP': 918, 'FN': 81, 'precision': 0.04573804573804574, 'recall': 0.352, 'accuracy': 0.6194285714285714, 'average_precision': 0.046992826108101085, 'balanced_accuracy': 0.4924, 'f1': 0.08095676172953083, 'roc_auc': 0.5144832}
==getted_scoring_result==
[fit 134/850] END C=0.03125, gamma=0.25, kernel=rbf; total=2625, TP=44, TN=1582, FP=918, FN=81; precision=0.046, recall=0.352
accuracy: (test=0.619) average_precision: (test=0.047) balanced_accuracy: (test=0.492) f1: (test=0.081) roc_auc: (test=0.514) 9.41s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1289, FP=1211, FN=58; precision=0.052, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.517) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.526) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1289, 'FP': 1211, 'FN': 58, 'precision': 0.05242566510172144, 'recall': 0.536, 'accuracy': 0.5165714285714286, 'average_precision': 0.04807253131899179, 'balanced_accuracy': 0.5258, 'f1': 0.09550962223806131, 'roc_auc': 0.5229264}
==getted_scoring_result==
[fit 135/850] END C=0.03125, gamma=0.5, kernel=rbf; total=2625, TP=67, TN=1289, FP=1211, FN=58; precision=0.052, recall=0.536
accuracy: (test=0.517) average_precision: (test=0.048) balanced_accuracy: (test=0.526) f1: (test=0.096) roc_auc: (test=0.523) 9.38s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1292, FP=1208, FN=58; precision=0.053, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.518) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.526) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.535) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1292, 'FP': 1208, 'FN': 58, 'precision': 0.05254901960784314, 'recall': 0.536, 'accuracy': 0.5177142857142857, 'average_precision': 0.04991679080719895, 'balanced_accuracy': 0.5264, 'f1': 0.09571428571428572, 'roc_auc': 0.5346176}
==getted_scoring_result==
[fit 136/850] END C=0.03125, gamma=1.0, kernel=rbf; total=2625, TP=67, TN=1292, FP=1208, FN=58; precision=0.053, recall=0.536
accuracy: (test=0.518) average_precision: (test=0.050) balanced_accuracy: (test=0.526) f1: (test=0.096) roc_auc: (test=0.535) 10.82s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1309, FP=1191, FN=55; precision=0.056, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.525) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.542) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.101) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.552) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1309, 'FP': 1191, 'FN': 55, 'precision': 0.05551149881046788, 'recall': 0.56, 'accuracy': 0.5253333333333333, 'average_precision': 0.05314329599295333, 'balanced_accuracy': 0.5418000000000001, 'f1': 0.101010101010101, 'roc_auc': 0.5515456}
==getted_scoring_result==
[fit 137/850] END C=0.03125, gamma=2.0, kernel=rbf; total=2625, TP=70, TN=1309, FP=1191, FN=55; precision=0.056, recall=0.560
accuracy: (test=0.525) average_precision: (test=0.053) balanced_accuracy: (test=0.542) f1: (test=0.101) roc_auc: (test=0.552) 11.03s
==get_scoring_result==
base_score: total=2625, TP=65, TN=1379, FP=1121, FN=60; precision=0.055, recall=0.520

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.550) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.536) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.099) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.572) ===
score_result_dict: {'Total': 2625, 'TP': 65, 'TN': 1379, 'FP': 1121, 'FN': 60, 'precision': 0.05480607082630692, 'recall': 0.52, 'accuracy': 0.5500952380952381, 'average_precision': 0.058237360898951505, 'balanced_accuracy': 0.5358, 'f1': 0.09916094584286804, 'roc_auc': 0.571808}
==getted_scoring_result==
[fit 138/850] END C=0.03125, gamma=4.0, kernel=rbf; total=2625, TP=65, TN=1379, FP=1121, FN=60; precision=0.055, recall=0.520
accuracy: (test=0.550) average_precision: (test=0.058) balanced_accuracy: (test=0.536) f1: (test=0.099) roc_auc: (test=0.572) 10.84s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1479, FP=1021, FN=59; precision=0.061, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.589) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.067) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.560) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.109) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.595) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1479, 'FP': 1021, 'FN': 59, 'precision': 0.06071757129714812, 'recall': 0.528, 'accuracy': 0.5885714285714285, 'average_precision': 0.06651110103701907, 'balanced_accuracy': 0.5598000000000001, 'f1': 0.10891089108910891, 'roc_auc': 0.5947072}
==getted_scoring_result==
[fit 139/850] END C=0.03125, gamma=8.0, kernel=rbf; total=2625, TP=66, TN=1479, FP=1021, FN=59; precision=0.061, recall=0.528
accuracy: (test=0.589) average_precision: (test=0.067) balanced_accuracy: (test=0.560) f1: (test=0.109) roc_auc: (test=0.595) 10.68s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=66, TN=1542, FP=958, FN=59; precision=0.064, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.613) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.077) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.572) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.115) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.625) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1542, 'FP': 958, 'FN': 59, 'precision': 0.064453125, 'recall': 0.528, 'accuracy': 0.6125714285714285, 'average_precision': 0.07742096279820834, 'balanced_accuracy': 0.5724, 'f1': 0.11488250652741513, 'roc_auc': 0.6248384}
==getted_scoring_result==
[fit 140/850] END C=0.03125, gamma=16.0, kernel=rbf; total=2625, TP=66, TN=1542, FP=958, FN=59; precision=0.064, recall=0.528
accuracy: (test=0.613) average_precision: (test=0.077) balanced_accuracy: (test=0.572) f1: (test=0.115) roc_auc: (test=0.625) 9.85s
==get_scoring_result==
base_score: total=2625, TP=65, TN=1666, FP=834, FN=60; precision=0.072, recall=0.520

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.659) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.097) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.593) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.127) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.662) ===
score_result_dict: {'Total': 2625, 'TP': 65, 'TN': 1666, 'FP': 834, 'FN': 60, 'precision': 0.07230255839822025, 'recall': 0.52, 'accuracy': 0.6594285714285715, 'average_precision': 0.09670650609534828, 'balanced_accuracy': 0.5932, 'f1': 0.126953125, 'roc_auc': 0.6619296}
==getted_scoring_result==
[fit 141/850] END C=0.03125, gamma=32.0, kernel=rbf; total=2625, TP=65, TN=1666, FP=834, FN=60; precision=0.072, recall=0.520
accuracy: (test=0.659) average_precision: (test=0.097) balanced_accuracy: (test=0.593) f1: (test=0.127) roc_auc: (test=0.662) 9.72s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1808, FP=692, FN=56; precision=0.091, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.715) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.130) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.638) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.156) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.695) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1808, 'FP': 692, 'FN': 56, 'precision': 0.09067017082785808, 'recall': 0.552, 'accuracy': 0.715047619047619, 'average_precision': 0.12966278333145925, 'balanced_accuracy': 0.6376, 'f1': 0.15575620767494355, 'roc_auc': 0.69464}
==getted_scoring_result==
[fit 142/850] END C=0.03125, gamma=64.0, kernel=rbf; total=2625, TP=69, TN=1808, FP=692, FN=56; precision=0.091, recall=0.552
accuracy: (test=0.715) average_precision: (test=0.130) balanced_accuracy: (test=0.638) f1: (test=0.156) roc_auc: (test=0.695) 9.85s
==get_scoring_result==
base_score: total=2625, TP=63, TN=1952, FP=548, FN=62; precision=0.103, recall=0.504

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.768) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.210) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.642) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.171) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.712) ===
score_result_dict: {'Total': 2625, 'TP': 63, 'TN': 1952, 'FP': 548, 'FN': 62, 'precision': 0.10310965630114566, 'recall': 0.504, 'accuracy': 0.7676190476190476, 'average_precision': 0.21008528064805432, 'balanced_accuracy': 0.6424000000000001, 'f1': 0.17119565217391303, 'roc_auc': 0.7124}
==getted_scoring_result==
[fit 143/850] END C=0.03125, gamma=128.0, kernel=rbf; total=2625, TP=63, TN=1952, FP=548, FN=62; precision=0.103, recall=0.504
accuracy: (test=0.768) average_precision: (test=0.210) balanced_accuracy: (test=0.642) f1: (test=0.171) roc_auc: (test=0.712) 9.91s
==get_scoring_result==
base_score: total=2625, TP=36, TN=2444, FP=56, FN=89; precision=0.391, recall=0.288

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.945) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.339) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.633) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.332) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.772) ===
score_result_dict: {'Total': 2625, 'TP': 36, 'TN': 2444, 'FP': 56, 'FN': 89, 'precision': 0.391304347826087, 'recall': 0.288, 'accuracy': 0.9447619047619048, 'average_precision': 0.3394605618904181, 'balanced_accuracy': 0.6328, 'f1': 0.3317972350230415, 'roc_auc': 0.7717024}
==getted_scoring_result==
[fit 144/850] END C=0.03125, gamma=256.0, kernel=rbf; total=2625, TP=36, TN=2444, FP=56, FN=89; precision=0.391, recall=0.288
accuracy: (test=0.945) average_precision: (test=0.339) balanced_accuracy: (test=0.633) f1: (test=0.332) roc_auc: (test=0.772) 9.46s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.617) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.845) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6168475653372076, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.8448416}
==getted_scoring_result==
[fit 145/850] END C=0.03125, gamma=512.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.617) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.845) 9.52s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.850) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6547386420722515, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.849504}
==getted_scoring_result==
[fit 146/850] END C=0.03125, gamma=1024.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.655) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.850) 9.47s
==get_scoring_result==
base_score: total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.962) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.646) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.596) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.322) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.834) ===
score_result_dict: {'Total': 2625, 'TP': 24, 'TN': 2500, 'FP': 0, 'FN': 101, 'precision': 1.0, 'recall': 0.192, 'accuracy': 0.9615238095238096, 'average_precision': 0.6464154163518238, 'balanced_accuracy': 0.596, 'f1': 0.32214765100671144, 'roc_auc': 0.8335472}
==getted_scoring_result==
[fit 147/850] END C=0.03125, gamma=2048.0, kernel=rbf; total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192
accuracy: (test=0.962) average_precision: (test=0.646) balanced_accuracy: (test=0.596) f1: (test=0.322) roc_auc: (test=0.834) 9.45s
==get_scoring_result==
base_score: total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.960) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.588) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.584) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.288) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.808) ===
score_result_dict: {'Total': 2625, 'TP': 21, 'TN': 2500, 'FP': 0, 'FN': 104, 'precision': 1.0, 'recall': 0.168, 'accuracy': 0.9603809523809523, 'average_precision': 0.5883432013564972, 'balanced_accuracy': 0.584, 'f1': 0.28767123287671237, 'roc_auc': 0.8078944}
==getted_scoring_result==
[fit 148/850] END C=0.03125, gamma=4096.0, kernel=rbf; total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168
accuracy: (test=0.960) average_precision: (test=0.588) balanced_accuracy: (test=0.584) f1: (test=0.288) roc_auc: (test=0.808) 9.44s
==get_scoring_result==
base_score: total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.957) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.499) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.552) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.188) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 13, 'TN': 2500, 'FP': 0, 'FN': 112, 'precision': 1.0, 'recall': 0.104, 'accuracy': 0.9573333333333334, 'average_precision': 0.49851156252849943, 'balanced_accuracy': 0.552, 'f1': 0.18840579710144925, 'roc_auc': 0.7484336}
==getted_scoring_result==
[fit 149/850] END C=0.03125, gamma=8192.0, kernel=rbf; total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104
accuracy: (test=0.957) average_precision: (test=0.499) balanced_accuracy: (test=0.552) f1: (test=0.188) roc_auc: (test=0.748) 9.43s
==get_scoring_result==
base_score: total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.955) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.679) ===
score_result_dict: {'Total': 2625, 'TP': 6, 'TN': 2500, 'FP': 0, 'FN': 119, 'precision': 1.0, 'recall': 0.048, 'accuracy': 0.9546666666666667, 'average_precision': 0.3686900354470264, 'balanced_accuracy': 0.524, 'f1': 0.0916030534351145, 'roc_auc': 0.6794208}
==getted_scoring_result==
[fit 150/850] END C=0.03125, gamma=16384.0, kernel=rbf; total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048
accuracy: (test=0.955) average_precision: (test=0.369) balanced_accuracy: (test=0.524) f1: (test=0.092) roc_auc: (test=0.679) 9.51s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.0461778974765596, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5066064}
==getted_scoring_result==
[fit 151/850] END C=0.0625, gamma=0.0009765625, kernel=rbf; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.59s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.04622399458377145, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.5065168}
==getted_scoring_result==
[fit 152/850] END C=0.0625, gamma=0.001953125, kernel=rbf; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.91s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.046229051995021045, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.5065344}
==getted_scoring_result==
[fit 153/850] END C=0.0625, gamma=0.00390625, kernel=rbf; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.89s
==get_scoring_result==
base_score: total=2625, TP=87, TN=857, FP=1643, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 857, 'FP': 1643, 'FN': 38, 'precision': 0.050289017341040465, 'recall': 0.696, 'accuracy': 0.3596190476190476, 'average_precision': 0.046230414338316525, 'balanced_accuracy': 0.5194, 'f1': 0.09380053908355795, 'roc_auc': 0.50656}
==getted_scoring_result==
[fit 154/850] END C=0.0625, gamma=0.0078125, kernel=rbf; total=2625, TP=87, TN=857, FP=1643, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 10.17s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.046236545932222144, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.5066112}
==getted_scoring_result==
[fit 155/850] END C=0.0625, gamma=0.015625, kernel=rbf; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.81s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.046236101413417455, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.5066512}
==getted_scoring_result==
[fit 156/850] END C=0.0625, gamma=0.03125, kernel=rbf; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.40s
==get_scoring_result==
base_score: total=2625, TP=55, TN=1416, FP=1084, FN=70; precision=0.048, recall=0.440

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.560) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.503) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.087) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 55, 'TN': 1416, 'FP': 1084, 'FN': 70, 'precision': 0.048287971905179985, 'recall': 0.44, 'accuracy': 0.5603809523809524, 'average_precision': 0.04648606067690151, 'balanced_accuracy': 0.5032, 'f1': 0.08702531645569621, 'roc_auc': 0.5089552}
==getted_scoring_result==
[fit 157/850] END C=0.0625, gamma=0.0625, kernel=rbf; total=2625, TP=55, TN=1416, FP=1084, FN=70; precision=0.048, recall=0.440
accuracy: (test=0.560) average_precision: (test=0.046) balanced_accuracy: (test=0.503) f1: (test=0.087) roc_auc: (test=0.509) 9.33s
==get_scoring_result==
base_score: total=2625, TP=44, TN=1630, FP=870, FN=81; precision=0.048, recall=0.352

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.638) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.502) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.085) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.514) ===
score_result_dict: {'Total': 2625, 'TP': 44, 'TN': 1630, 'FP': 870, 'FN': 81, 'precision': 0.04814004376367615, 'recall': 0.352, 'accuracy': 0.6377142857142857, 'average_precision': 0.04699835664754812, 'balanced_accuracy': 0.502, 'f1': 0.08469682386910492, 'roc_auc': 0.5142368}
==getted_scoring_result==
[fit 158/850] END C=0.0625, gamma=0.125, kernel=rbf; total=2625, TP=44, TN=1630, FP=870, FN=81; precision=0.048, recall=0.352
accuracy: (test=0.638) average_precision: (test=0.047) balanced_accuracy: (test=0.502) f1: (test=0.085) roc_auc: (test=0.514) 9.00s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1296, FP=1204, FN=58; precision=0.053, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.519) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.527) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1296, 'FP': 1204, 'FN': 58, 'precision': 0.05271439811172305, 'recall': 0.536, 'accuracy': 0.5192380952380953, 'average_precision': 0.04812628850807253, 'balanced_accuracy': 0.5272, 'f1': 0.09598853868194841, 'roc_auc': 0.5233184}
==getted_scoring_result==
[fit 159/850] END C=0.0625, gamma=0.25, kernel=rbf; total=2625, TP=67, TN=1296, FP=1204, FN=58; precision=0.053, recall=0.536
accuracy: (test=0.519) average_precision: (test=0.048) balanced_accuracy: (test=0.527) f1: (test=0.096) roc_auc: (test=0.523) 9.06s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1313, FP=1187, FN=58; precision=0.053, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.526) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.531) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.097) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.536) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1313, 'FP': 1187, 'FN': 58, 'precision': 0.05342902711323764, 'recall': 0.536, 'accuracy': 0.5257142857142857, 'average_precision': 0.050008426321017076, 'balanced_accuracy': 0.5306, 'f1': 0.0971718636693256, 'roc_auc': 0.5361088}
==getted_scoring_result==
[fit 160/850] END C=0.0625, gamma=0.5, kernel=rbf; total=2625, TP=67, TN=1313, FP=1187, FN=58; precision=0.053, recall=0.536
accuracy: (test=0.526) average_precision: (test=0.050) balanced_accuracy: (test=0.531) f1: (test=0.097) roc_auc: (test=0.536) 9.23s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1328, FP=1172, FN=56; precision=0.056, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.532) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.542) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.101) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.553) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1328, 'FP': 1172, 'FN': 56, 'precision': 0.055600322320709106, 'recall': 0.552, 'accuracy': 0.5321904761904762, 'average_precision': 0.0529340875746087, 'balanced_accuracy': 0.5416000000000001, 'f1': 0.10102489019033675, 'roc_auc': 0.5533872}
==getted_scoring_result==
[fit 161/850] END C=0.0625, gamma=1.0, kernel=rbf; total=2625, TP=69, TN=1328, FP=1172, FN=56; precision=0.056, recall=0.552
accuracy: (test=0.532) average_precision: (test=0.053) balanced_accuracy: (test=0.542) f1: (test=0.101) roc_auc: (test=0.553) 9.37s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=66, TN=1380, FP=1120, FN=59; precision=0.056, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.551) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.101) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.575) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1380, 'FP': 1120, 'FN': 59, 'precision': 0.05564924114671164, 'recall': 0.528, 'accuracy': 0.5508571428571428, 'average_precision': 0.058044951049112004, 'balanced_accuracy': 0.54, 'f1': 0.10068649885583525, 'roc_auc': 0.5753824}
==getted_scoring_result==
[fit 162/850] END C=0.0625, gamma=2.0, kernel=rbf; total=2625, TP=66, TN=1380, FP=1120, FN=59; precision=0.056, recall=0.528
accuracy: (test=0.551) average_precision: (test=0.058) balanced_accuracy: (test=0.540) f1: (test=0.101) roc_auc: (test=0.575) 9.44s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=65, TN=1463, FP=1037, FN=60; precision=0.059, recall=0.520

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.582) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.066) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.553) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.106) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.601) ===
score_result_dict: {'Total': 2625, 'TP': 65, 'TN': 1463, 'FP': 1037, 'FN': 60, 'precision': 0.05898366606170599, 'recall': 0.52, 'accuracy': 0.5820952380952381, 'average_precision': 0.06644209895307496, 'balanced_accuracy': 0.5526, 'f1': 0.10594947025264874, 'roc_auc': 0.6006384}
==getted_scoring_result==
[fit 163/850] END C=0.0625, gamma=4.0, kernel=rbf; total=2625, TP=65, TN=1463, FP=1037, FN=60; precision=0.059, recall=0.520
accuracy: (test=0.582) average_precision: (test=0.066) balanced_accuracy: (test=0.553) f1: (test=0.106) roc_auc: (test=0.601) 9.31s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1551, FP=949, FN=56; precision=0.068, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.617) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.079) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.586) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.121) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.631) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1551, 'FP': 949, 'FN': 56, 'precision': 0.06777996070726916, 'recall': 0.552, 'accuracy': 0.6171428571428571, 'average_precision': 0.07864705561162445, 'balanced_accuracy': 0.5862, 'f1': 0.12073490813648297, 'roc_auc': 0.6310608}
==getted_scoring_result==
[fit 164/850] END C=0.0625, gamma=8.0, kernel=rbf; total=2625, TP=69, TN=1551, FP=949, FN=56; precision=0.068, recall=0.552
accuracy: (test=0.617) average_precision: (test=0.079) balanced_accuracy: (test=0.586) f1: (test=0.121) roc_auc: (test=0.631) 9.78s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1675, FP=825, FN=56; precision=0.077, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.664) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.101) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.611) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.135) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.677) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1675, 'FP': 825, 'FN': 56, 'precision': 0.07718120805369127, 'recall': 0.552, 'accuracy': 0.6643809523809524, 'average_precision': 0.10149444846000448, 'balanced_accuracy': 0.611, 'f1': 0.1354268891069676, 'roc_auc': 0.6765216}
==getted_scoring_result==
[fit 165/850] END C=0.0625, gamma=16.0, kernel=rbf; total=2625, TP=69, TN=1675, FP=825, FN=56; precision=0.077, recall=0.552
accuracy: (test=0.664) average_precision: (test=0.101) balanced_accuracy: (test=0.611) f1: (test=0.135) roc_auc: (test=0.677) 9.51s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=72, TN=1854, FP=646, FN=53; precision=0.100, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.734) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.140) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.659) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.171) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.730) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1854, 'FP': 646, 'FN': 53, 'precision': 0.10027855153203342, 'recall': 0.576, 'accuracy': 0.7337142857142858, 'average_precision': 0.14008971610556034, 'balanced_accuracy': 0.6588, 'f1': 0.17081850533807827, 'roc_auc': 0.7296192}
==getted_scoring_result==
[fit 166/850] END C=0.0625, gamma=32.0, kernel=rbf; total=2625, TP=72, TN=1854, FP=646, FN=53; precision=0.100, recall=0.576
accuracy: (test=0.734) average_precision: (test=0.140) balanced_accuracy: (test=0.659) f1: (test=0.171) roc_auc: (test=0.730) 9.63s
==get_scoring_result==
base_score: total=2625, TP=72, TN=2026, FP=474, FN=53; precision=0.132, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.799) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.224) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.693) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.215) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.782) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 2026, 'FP': 474, 'FN': 53, 'precision': 0.13186813186813187, 'recall': 0.576, 'accuracy': 0.7992380952380952, 'average_precision': 0.22417882427137253, 'balanced_accuracy': 0.6932, 'f1': 0.21460506706408347, 'roc_auc': 0.781632}
==getted_scoring_result==
[fit 167/850] END C=0.0625, gamma=64.0, kernel=rbf; total=2625, TP=72, TN=2026, FP=474, FN=53; precision=0.132, recall=0.576
accuracy: (test=0.799) average_precision: (test=0.224) balanced_accuracy: (test=0.693) f1: (test=0.215) roc_auc: (test=0.782) 9.73s
==get_scoring_result==
base_score: total=2625, TP=67, TN=2151, FP=349, FN=58; precision=0.161, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.845) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.356) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.698) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.248) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.807) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 2151, 'FP': 349, 'FN': 58, 'precision': 0.16105769230769232, 'recall': 0.536, 'accuracy': 0.8449523809523809, 'average_precision': 0.35590489312143525, 'balanced_accuracy': 0.6982, 'f1': 0.24768946395563773, 'roc_auc': 0.8072224}
==getted_scoring_result==
[fit 168/850] END C=0.0625, gamma=128.0, kernel=rbf; total=2625, TP=67, TN=2151, FP=349, FN=58; precision=0.161, recall=0.536
accuracy: (test=0.845) average_precision: (test=0.356) balanced_accuracy: (test=0.698) f1: (test=0.248) roc_auc: (test=0.807) 11.62s
==get_scoring_result==
base_score: total=2625, TP=69, TN=2280, FP=220, FN=56; precision=0.239, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.895) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.431) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.732) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.333) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.815) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 2280, 'FP': 220, 'FN': 56, 'precision': 0.23875432525951557, 'recall': 0.552, 'accuracy': 0.8948571428571429, 'average_precision': 0.43076967089329454, 'balanced_accuracy': 0.732, 'f1': 0.3333333333333333, 'roc_auc': 0.8153728}
==getted_scoring_result==
[fit 169/850] END C=0.0625, gamma=256.0, kernel=rbf; total=2625, TP=69, TN=2280, FP=220, FN=56; precision=0.239, recall=0.552
accuracy: (test=0.895) average_precision: (test=0.431) balanced_accuracy: (test=0.732) f1: (test=0.333) roc_auc: (test=0.815) 11.86s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.617) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.845) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6168475653372076, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.8448416}
==getted_scoring_result==
[fit 170/850] END C=0.0625, gamma=512.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.617) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.845) 11.86s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.850) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6547409193563427, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.8495056}
==getted_scoring_result==
[fit 171/850] END C=0.0625, gamma=1024.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.655) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.850) 11.66s
==get_scoring_result==
base_score: total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.962) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.645) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.596) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.322) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.834) ===
score_result_dict: {'Total': 2625, 'TP': 24, 'TN': 2500, 'FP': 0, 'FN': 101, 'precision': 1.0, 'recall': 0.192, 'accuracy': 0.9615238095238096, 'average_precision': 0.6449230593203522, 'balanced_accuracy': 0.596, 'f1': 0.32214765100671144, 'roc_auc': 0.8344048}
==getted_scoring_result==
[fit 172/850] END C=0.0625, gamma=2048.0, kernel=rbf; total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192
accuracy: (test=0.962) average_precision: (test=0.645) balanced_accuracy: (test=0.596) f1: (test=0.322) roc_auc: (test=0.834) 11.65s
==get_scoring_result==
base_score: total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.960) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.592) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.584) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.288) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.804) ===
score_result_dict: {'Total': 2625, 'TP': 21, 'TN': 2500, 'FP': 0, 'FN': 104, 'precision': 1.0, 'recall': 0.168, 'accuracy': 0.9603809523809523, 'average_precision': 0.5924118869299606, 'balanced_accuracy': 0.584, 'f1': 0.28767123287671237, 'roc_auc': 0.8044736}
==getted_scoring_result==
[fit 173/850] END C=0.0625, gamma=4096.0, kernel=rbf; total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168
accuracy: (test=0.960) average_precision: (test=0.592) balanced_accuracy: (test=0.584) f1: (test=0.288) roc_auc: (test=0.804) 10.90s
==get_scoring_result==
base_score: total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.957) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.468) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.552) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.188) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.727) ===
score_result_dict: {'Total': 2625, 'TP': 13, 'TN': 2500, 'FP': 0, 'FN': 112, 'precision': 1.0, 'recall': 0.104, 'accuracy': 0.9573333333333334, 'average_precision': 0.4678457467220462, 'balanced_accuracy': 0.552, 'f1': 0.18840579710144925, 'roc_auc': 0.7273504}
==getted_scoring_result==
[fit 174/850] END C=0.0625, gamma=8192.0, kernel=rbf; total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104
accuracy: (test=0.957) average_precision: (test=0.468) balanced_accuracy: (test=0.552) f1: (test=0.188) roc_auc: (test=0.727) 10.95s
==get_scoring_result==
base_score: total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.955) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 6, 'TN': 2500, 'FP': 0, 'FN': 119, 'precision': 1.0, 'recall': 0.048, 'accuracy': 0.9546666666666667, 'average_precision': 0.36870291568163915, 'balanced_accuracy': 0.524, 'f1': 0.0916030534351145, 'roc_auc': 0.6795536}
==getted_scoring_result==
[fit 175/850] END C=0.0625, gamma=16384.0, kernel=rbf; total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048
accuracy: (test=0.955) average_precision: (test=0.369) balanced_accuracy: (test=0.524) f1: (test=0.092) roc_auc: (test=0.680) 11.14s
==get_scoring_result==
base_score: total=2625, TP=87, TN=857, FP=1643, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 857, 'FP': 1643, 'FN': 38, 'precision': 0.050289017341040465, 'recall': 0.696, 'accuracy': 0.3596190476190476, 'average_precision': 0.046223613257047894, 'balanced_accuracy': 0.5194, 'f1': 0.09380053908355795, 'roc_auc': 0.5065552}
==getted_scoring_result==
[fit 176/850] END C=0.125, gamma=0.0009765625, kernel=rbf; total=2625, TP=87, TN=857, FP=1643, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 10.58s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.04623133395366551, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.5065152}
==getted_scoring_result==
[fit 177/850] END C=0.125, gamma=0.001953125, kernel=rbf; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.32s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.046232081123308406, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.5065696}
==getted_scoring_result==
[fit 178/850] END C=0.125, gamma=0.00390625, kernel=rbf; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 8.73s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.046236408306163684, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.506608}
==getted_scoring_result==
[fit 179/850] END C=0.125, gamma=0.0078125, kernel=rbf; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.18s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.046236545932222144, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.50664}
==getted_scoring_result==
[fit 180/850] END C=0.125, gamma=0.015625, kernel=rbf; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.30s
==get_scoring_result==
base_score: total=2625, TP=60, TN=1375, FP=1125, FN=65; precision=0.051, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.547) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.515) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 1375, 'FP': 1125, 'FN': 65, 'precision': 0.05063291139240506, 'recall': 0.48, 'accuracy': 0.5466666666666666, 'average_precision': 0.046555037750844554, 'balanced_accuracy': 0.515, 'f1': 0.0916030534351145, 'roc_auc': 0.5091072}
==getted_scoring_result==
[fit 181/850] END C=0.125, gamma=0.03125, kernel=rbf; total=2625, TP=60, TN=1375, FP=1125, FN=65; precision=0.051, recall=0.480
accuracy: (test=0.547) average_precision: (test=0.047) balanced_accuracy: (test=0.515) f1: (test=0.092) roc_auc: (test=0.509) 9.41s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1227, FP=1273, FN=58; precision=0.050, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.493) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.513) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.515) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1227, 'FP': 1273, 'FN': 58, 'precision': 0.05, 'recall': 0.536, 'accuracy': 0.492952380952381, 'average_precision': 0.047029494823319064, 'balanced_accuracy': 0.5134000000000001, 'f1': 0.09146757679180888, 'roc_auc': 0.514808}
==getted_scoring_result==
[fit 182/850] END C=0.125, gamma=0.0625, kernel=rbf; total=2625, TP=67, TN=1227, FP=1273, FN=58; precision=0.050, recall=0.536
accuracy: (test=0.493) average_precision: (test=0.047) balanced_accuracy: (test=0.513) f1: (test=0.091) roc_auc: (test=0.515) 9.42s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1169, FP=1331, FN=55; precision=0.050, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.472) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.514) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1169, 'FP': 1331, 'FN': 55, 'precision': 0.049964311206281226, 'recall': 0.56, 'accuracy': 0.472, 'average_precision': 0.04813858843888833, 'balanced_accuracy': 0.5138, 'f1': 0.09174311926605505, 'roc_auc': 0.52324}
==getted_scoring_result==
[fit 183/850] END C=0.125, gamma=0.125, kernel=rbf; total=2625, TP=70, TN=1169, FP=1331, FN=55; precision=0.050, recall=0.560
accuracy: (test=0.472) average_precision: (test=0.048) balanced_accuracy: (test=0.514) f1: (test=0.092) roc_auc: (test=0.523) 9.37s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1317, FP=1183, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.527) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.531) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.097) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.537) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1317, 'FP': 1183, 'FN': 58, 'precision': 0.0536, 'recall': 0.536, 'accuracy': 0.5272380952380953, 'average_precision': 0.04995438431679533, 'balanced_accuracy': 0.5314000000000001, 'f1': 0.09745454545454546, 'roc_auc': 0.5368144}
==getted_scoring_result==
[fit 184/850] END C=0.125, gamma=0.25, kernel=rbf; total=2625, TP=67, TN=1317, FP=1183, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.527) average_precision: (test=0.050) balanced_accuracy: (test=0.531) f1: (test=0.097) roc_auc: (test=0.537) 9.62s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1343, FP=1157, FN=55; precision=0.057, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.538) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.549) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.104) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.555) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1343, 'FP': 1157, 'FN': 55, 'precision': 0.05704971475142624, 'recall': 0.56, 'accuracy': 0.5382857142857143, 'average_precision': 0.05302510444197893, 'balanced_accuracy': 0.5486, 'f1': 0.10355029585798817, 'roc_auc': 0.5546}
==getted_scoring_result==
[fit 185/850] END C=0.125, gamma=0.5, kernel=rbf; total=2625, TP=70, TN=1343, FP=1157, FN=55; precision=0.057, recall=0.560
accuracy: (test=0.538) average_precision: (test=0.053) balanced_accuracy: (test=0.549) f1: (test=0.104) roc_auc: (test=0.555) 10.04s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=67, TN=1385, FP=1115, FN=58; precision=0.057, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.553) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.545) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.577) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1385, 'FP': 1115, 'FN': 58, 'precision': 0.05668358714043993, 'recall': 0.536, 'accuracy': 0.5531428571428572, 'average_precision': 0.05796894452150221, 'balanced_accuracy': 0.545, 'f1': 0.1025248661055853, 'roc_auc': 0.5772608}
==getted_scoring_result==
[fit 186/850] END C=0.125, gamma=1.0, kernel=rbf; total=2625, TP=67, TN=1385, FP=1115, FN=58; precision=0.057, recall=0.536
accuracy: (test=0.553) average_precision: (test=0.058) balanced_accuracy: (test=0.545) f1: (test=0.103) roc_auc: (test=0.577) 10.30s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1455, FP=1045, FN=57; precision=0.061, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.580) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.066) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.563) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.110) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.604) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1455, 'FP': 1045, 'FN': 57, 'precision': 0.061096136567834684, 'recall': 0.544, 'accuracy': 0.5801904761904761, 'average_precision': 0.06626952075153575, 'balanced_accuracy': 0.563, 'f1': 0.10985460420032311, 'roc_auc': 0.604416}
==getted_scoring_result==
[fit 187/850] END C=0.125, gamma=2.0, kernel=rbf; total=2625, TP=68, TN=1455, FP=1045, FN=57; precision=0.061, recall=0.544
accuracy: (test=0.580) average_precision: (test=0.066) balanced_accuracy: (test=0.563) f1: (test=0.110) roc_auc: (test=0.604) 10.27s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1556, FP=944, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.620) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.079) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.599) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.126) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.633) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1556, 'FP': 944, 'FN': 53, 'precision': 0.07086614173228346, 'recall': 0.576, 'accuracy': 0.6201904761904762, 'average_precision': 0.07916064321481957, 'balanced_accuracy': 0.5992, 'f1': 0.126205083260298, 'roc_auc': 0.6326208}
==getted_scoring_result==
[fit 188/850] END C=0.125, gamma=4.0, kernel=rbf; total=2625, TP=72, TN=1556, FP=944, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.620) average_precision: (test=0.079) balanced_accuracy: (test=0.599) f1: (test=0.126) roc_auc: (test=0.633) 9.89s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1664, FP=836, FN=54; precision=0.078, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.661) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.096) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.617) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.138) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.673) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1664, 'FP': 836, 'FN': 54, 'precision': 0.0782800441014333, 'recall': 0.568, 'accuracy': 0.660952380952381, 'average_precision': 0.09631028214127386, 'balanced_accuracy': 0.6168, 'f1': 0.1375968992248062, 'roc_auc': 0.6730112}
==getted_scoring_result==
[fit 189/850] END C=0.125, gamma=8.0, kernel=rbf; total=2625, TP=71, TN=1664, FP=836, FN=54; precision=0.078, recall=0.568
accuracy: (test=0.661) average_precision: (test=0.096) balanced_accuracy: (test=0.617) f1: (test=0.138) roc_auc: (test=0.673) 8.83s
==get_scoring_result==
base_score: total=2625, TP=75, TN=1796, FP=704, FN=50; precision=0.096, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.713) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.134) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.659) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.166) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.730) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1796, 'FP': 704, 'FN': 50, 'precision': 0.0962772785622593, 'recall': 0.6, 'accuracy': 0.7127619047619047, 'average_precision': 0.13434676582941488, 'balanced_accuracy': 0.6592, 'f1': 0.165929203539823, 'roc_auc': 0.7298784}
==getted_scoring_result==
[fit 190/850] END C=0.125, gamma=16.0, kernel=rbf; total=2625, TP=75, TN=1796, FP=704, FN=50; precision=0.096, recall=0.600
accuracy: (test=0.713) average_precision: (test=0.134) balanced_accuracy: (test=0.659) f1: (test=0.166) roc_auc: (test=0.730) 8.41s
==get_scoring_result==
base_score: total=2625, TP=78, TN=1985, FP=515, FN=47; precision=0.132, recall=0.624

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.786) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.210) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.709) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.217) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.801) ===
score_result_dict: {'Total': 2625, 'TP': 78, 'TN': 1985, 'FP': 515, 'FN': 47, 'precision': 0.1315345699831366, 'recall': 0.624, 'accuracy': 0.7859047619047619, 'average_precision': 0.2098227267544896, 'balanced_accuracy': 0.7090000000000001, 'f1': 0.2172701949860724, 'roc_auc': 0.8011584}
==getted_scoring_result==
[fit 191/850] END C=0.125, gamma=32.0, kernel=rbf; total=2625, TP=78, TN=1985, FP=515, FN=47; precision=0.132, recall=0.624
accuracy: (test=0.786) average_precision: (test=0.210) balanced_accuracy: (test=0.709) f1: (test=0.217) roc_auc: (test=0.801) 8.86s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2215, FP=285, FN=51; precision=0.206, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.872) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.385) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.739) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.306) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.856) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2215, 'FP': 285, 'FN': 51, 'precision': 0.20612813370473537, 'recall': 0.592, 'accuracy': 0.872, 'average_precision': 0.38481138798521874, 'balanced_accuracy': 0.739, 'f1': 0.30578512396694213, 'roc_auc': 0.8563264}
==getted_scoring_result==
[fit 192/850] END C=0.125, gamma=64.0, kernel=rbf; total=2625, TP=74, TN=2215, FP=285, FN=51; precision=0.206, recall=0.592
accuracy: (test=0.872) average_precision: (test=0.385) balanced_accuracy: (test=0.739) f1: (test=0.306) roc_auc: (test=0.856) 8.87s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2330, FP=170, FN=49; precision=0.309, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.917) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.544) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.770) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.410) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.872) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2330, 'FP': 170, 'FN': 49, 'precision': 0.3089430894308943, 'recall': 0.608, 'accuracy': 0.9165714285714286, 'average_precision': 0.5444973329675971, 'balanced_accuracy': 0.77, 'f1': 0.4097035040431267, 'roc_auc': 0.8716832}
==getted_scoring_result==
[fit 193/850] END C=0.125, gamma=128.0, kernel=rbf; total=2625, TP=76, TN=2330, FP=170, FN=49; precision=0.309, recall=0.608
accuracy: (test=0.917) average_precision: (test=0.544) balanced_accuracy: (test=0.770) f1: (test=0.410) roc_auc: (test=0.872) 9.44s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2386, FP=114, FN=51; precision=0.394, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.937) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.582) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.773) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.473) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.859) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2386, 'FP': 114, 'FN': 51, 'precision': 0.39361702127659576, 'recall': 0.592, 'accuracy': 0.9371428571428572, 'average_precision': 0.5818493880694005, 'balanced_accuracy': 0.7732, 'f1': 0.4728434504792332, 'roc_auc': 0.8585984}
==getted_scoring_result==
[fit 194/850] END C=0.125, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2386, FP=114, FN=51; precision=0.394, recall=0.592
accuracy: (test=0.937) average_precision: (test=0.582) balanced_accuracy: (test=0.773) f1: (test=0.473) roc_auc: (test=0.859) 10.63s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2459, FP=41, FN=51; precision=0.643, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.965) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.626) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.788) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.617) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.851) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2459, 'FP': 41, 'FN': 51, 'precision': 0.6434782608695652, 'recall': 0.592, 'accuracy': 0.964952380952381, 'average_precision': 0.625532050282028, 'balanced_accuracy': 0.7878000000000001, 'f1': 0.6166666666666666, 'roc_auc': 0.8505296}
==getted_scoring_result==
[fit 195/850] END C=0.125, gamma=512.0, kernel=rbf; total=2625, TP=74, TN=2459, FP=41, FN=51; precision=0.643, recall=0.592
accuracy: (test=0.965) average_precision: (test=0.626) balanced_accuracy: (test=0.788) f1: (test=0.617) roc_auc: (test=0.851) 10.72s
==get_scoring_result==
base_score: total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.964) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.624) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.849) ===
score_result_dict: {'Total': 2625, 'TP': 31, 'TN': 2500, 'FP': 0, 'FN': 94, 'precision': 1.0, 'recall': 0.248, 'accuracy': 0.9641904761904762, 'average_precision': 0.6546732275581939, 'balanced_accuracy': 0.624, 'f1': 0.3974358974358974, 'roc_auc': 0.84948}
==getted_scoring_result==
[fit 196/850] END C=0.125, gamma=1024.0, kernel=rbf; total=2625, TP=31, TN=2500, FP=0, FN=94; precision=1.000, recall=0.248
accuracy: (test=0.964) average_precision: (test=0.655) balanced_accuracy: (test=0.624) f1: (test=0.397) roc_auc: (test=0.849) 9.87s
==get_scoring_result==
base_score: total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.962) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.644) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.596) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.322) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.833) ===
score_result_dict: {'Total': 2625, 'TP': 24, 'TN': 2500, 'FP': 0, 'FN': 101, 'precision': 1.0, 'recall': 0.192, 'accuracy': 0.9615238095238096, 'average_precision': 0.6442817092207631, 'balanced_accuracy': 0.596, 'f1': 0.32214765100671144, 'roc_auc': 0.8327328}
==getted_scoring_result==
[fit 197/850] END C=0.125, gamma=2048.0, kernel=rbf; total=2625, TP=24, TN=2500, FP=0, FN=101; precision=1.000, recall=0.192
accuracy: (test=0.962) average_precision: (test=0.644) balanced_accuracy: (test=0.596) f1: (test=0.322) roc_auc: (test=0.833) 9.44s
==get_scoring_result==
base_score: total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.960) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.592) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.584) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.288) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.804) ===
score_result_dict: {'Total': 2625, 'TP': 21, 'TN': 2500, 'FP': 0, 'FN': 104, 'precision': 1.0, 'recall': 0.168, 'accuracy': 0.9603809523809523, 'average_precision': 0.5923923900410971, 'balanced_accuracy': 0.584, 'f1': 0.28767123287671237, 'roc_auc': 0.8043264}
==getted_scoring_result==
[fit 198/850] END C=0.125, gamma=4096.0, kernel=rbf; total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168
accuracy: (test=0.960) average_precision: (test=0.592) balanced_accuracy: (test=0.584) f1: (test=0.288) roc_auc: (test=0.804) 9.29s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.957) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.468) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.552) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.188) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.735) ===
score_result_dict: {'Total': 2625, 'TP': 13, 'TN': 2500, 'FP': 0, 'FN': 112, 'precision': 1.0, 'recall': 0.104, 'accuracy': 0.9573333333333334, 'average_precision': 0.4682314317288695, 'balanced_accuracy': 0.552, 'f1': 0.18840579710144925, 'roc_auc': 0.7345296}
==getted_scoring_result==
[fit 199/850] END C=0.125, gamma=8192.0, kernel=rbf; total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104
accuracy: (test=0.957) average_precision: (test=0.468) balanced_accuracy: (test=0.552) f1: (test=0.188) roc_auc: (test=0.735) 9.54s
==get_scoring_result==
base_score: total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.955) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.354) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.672) ===
score_result_dict: {'Total': 2625, 'TP': 6, 'TN': 2500, 'FP': 0, 'FN': 119, 'precision': 1.0, 'recall': 0.048, 'accuracy': 0.9546666666666667, 'average_precision': 0.35353057199211047, 'balanced_accuracy': 0.524, 'f1': 0.0916030534351145, 'roc_auc': 0.67224}
==getted_scoring_result==
[fit 200/850] END C=0.125, gamma=16384.0, kernel=rbf; total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048
accuracy: (test=0.955) average_precision: (test=0.354) balanced_accuracy: (test=0.524) f1: (test=0.092) roc_auc: (test=0.672) 9.63s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.04622472434067766, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.5065184}
==getted_scoring_result==
[fit 201/850] END C=0.25, gamma=0.0009765625, kernel=rbf; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.28s
==get_scoring_result==
base_score: total=2625, TP=87, TN=857, FP=1643, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 857, 'FP': 1643, 'FN': 38, 'precision': 0.050289017341040465, 'recall': 0.696, 'accuracy': 0.3596190476190476, 'average_precision': 0.04623400364106981, 'balanced_accuracy': 0.5194, 'f1': 0.09380053908355795, 'roc_auc': 0.5065696}
==getted_scoring_result==
[fit 202/850] END C=0.25, gamma=0.001953125, kernel=rbf; total=2625, TP=87, TN=857, FP=1643, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.19s
==get_scoring_result==
base_score: total=2625, TP=87, TN=859, FP=1641, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 859, 'FP': 1641, 'FN': 38, 'precision': 0.050347222222222224, 'recall': 0.696, 'accuracy': 0.36038095238095236, 'average_precision': 0.04623646217641444, 'balanced_accuracy': 0.5198, 'f1': 0.09390178089584458, 'roc_auc': 0.5066528}
==getted_scoring_result==
[fit 203/850] END C=0.25, gamma=0.00390625, kernel=rbf; total=2625, TP=87, TN=859, FP=1641, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.13s
==get_scoring_result==
base_score: total=2625, TP=87, TN=860, FP=1640, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.361) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 860, 'FP': 1640, 'FN': 38, 'precision': 0.05037637521713955, 'recall': 0.696, 'accuracy': 0.3607619047619048, 'average_precision': 0.046240985090435324, 'balanced_accuracy': 0.52, 'f1': 0.09395248380129591, 'roc_auc': 0.5066736}
==getted_scoring_result==
[fit 204/850] END C=0.25, gamma=0.0078125, kernel=rbf; total=2625, TP=87, TN=860, FP=1640, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.361) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.16s
==get_scoring_result==
base_score: total=2625, TP=55, TN=1424, FP=1076, FN=70; precision=0.049, recall=0.440

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.563) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.505) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.088) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 55, 'TN': 1424, 'FP': 1076, 'FN': 70, 'precision': 0.04862953138815208, 'recall': 0.44, 'accuracy': 0.5634285714285714, 'average_precision': 0.04651532037685988, 'balanced_accuracy': 0.5048, 'f1': 0.0875796178343949, 'roc_auc': 0.5094848}
==getted_scoring_result==
[fit 205/850] END C=0.25, gamma=0.015625, kernel=rbf; total=2625, TP=55, TN=1424, FP=1076, FN=70; precision=0.049, recall=0.440
accuracy: (test=0.563) average_precision: (test=0.047) balanced_accuracy: (test=0.505) f1: (test=0.088) roc_auc: (test=0.509) 9.15s
==get_scoring_result==
base_score: total=2625, TP=42, TN=1670, FP=830, FN=83; precision=0.048, recall=0.336

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.652) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.502) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.084) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.515) ===
score_result_dict: {'Total': 2625, 'TP': 42, 'TN': 1670, 'FP': 830, 'FN': 83, 'precision': 0.0481651376146789, 'recall': 0.336, 'accuracy': 0.6521904761904762, 'average_precision': 0.04700572493652603, 'balanced_accuracy': 0.502, 'f1': 0.08425275827482448, 'roc_auc': 0.514664}
==getted_scoring_result==
[fit 206/850] END C=0.25, gamma=0.03125, kernel=rbf; total=2625, TP=42, TN=1670, FP=830, FN=83; precision=0.048, recall=0.336
accuracy: (test=0.652) average_precision: (test=0.047) balanced_accuracy: (test=0.502) f1: (test=0.084) roc_auc: (test=0.515) 9.34s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.520) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1298, 'FP': 1202, 'FN': 59, 'precision': 0.052050473186119876, 'recall': 0.528, 'accuracy': 0.5196190476190476, 'average_precision': 0.0481507227761432, 'balanced_accuracy': 0.5236000000000001, 'f1': 0.09475951184493898, 'roc_auc': 0.5230592}
==getted_scoring_result==
[fit 207/850] END C=0.25, gamma=0.0625, kernel=rbf; total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528
accuracy: (test=0.520) average_precision: (test=0.048) balanced_accuracy: (test=0.524) f1: (test=0.095) roc_auc: (test=0.523) 9.27s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1317, FP=1183, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.527) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.531) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.097) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.537) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1317, 'FP': 1183, 'FN': 58, 'precision': 0.0536, 'recall': 0.536, 'accuracy': 0.5272380952380953, 'average_precision': 0.0500436271556272, 'balanced_accuracy': 0.5314000000000001, 'f1': 0.09745454545454546, 'roc_auc': 0.537104}
==getted_scoring_result==
[fit 208/850] END C=0.25, gamma=0.125, kernel=rbf; total=2625, TP=67, TN=1317, FP=1183, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.527) average_precision: (test=0.050) balanced_accuracy: (test=0.531) f1: (test=0.097) roc_auc: (test=0.537) 9.29s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1348, FP=1152, FN=55; precision=0.057, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.540) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.550) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.104) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.555) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1348, 'FP': 1152, 'FN': 55, 'precision': 0.057283142389525366, 'recall': 0.56, 'accuracy': 0.5401904761904762, 'average_precision': 0.053119031849301564, 'balanced_accuracy': 0.5496000000000001, 'f1': 0.10393466963622865, 'roc_auc': 0.5553056}
==getted_scoring_result==
[fit 209/850] END C=0.25, gamma=0.25, kernel=rbf; total=2625, TP=70, TN=1348, FP=1152, FN=55; precision=0.057, recall=0.560
accuracy: (test=0.540) average_precision: (test=0.053) balanced_accuracy: (test=0.550) f1: (test=0.104) roc_auc: (test=0.555) 9.20s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1386, FP=1114, FN=58; precision=0.057, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.554) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.545) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.579) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1386, 'FP': 1114, 'FN': 58, 'precision': 0.056731583403895, 'recall': 0.536, 'accuracy': 0.5535238095238095, 'average_precision': 0.05794282747256882, 'balanced_accuracy': 0.5452, 'f1': 0.10260336906584992, 'roc_auc': 0.5785248}
==getted_scoring_result==
[fit 210/850] END C=0.25, gamma=0.5, kernel=rbf; total=2625, TP=67, TN=1386, FP=1114, FN=58; precision=0.057, recall=0.536
accuracy: (test=0.554) average_precision: (test=0.058) balanced_accuracy: (test=0.545) f1: (test=0.103) roc_auc: (test=0.579) 9.33s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=70, TN=1457, FP=1043, FN=55; precision=0.063, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.582) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.066) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.571) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.113) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.606) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1457, 'FP': 1043, 'FN': 55, 'precision': 0.06289308176100629, 'recall': 0.56, 'accuracy': 0.5817142857142857, 'average_precision': 0.06618996189887408, 'balanced_accuracy': 0.5714, 'f1': 0.11308562197092085, 'roc_auc': 0.606}
==getted_scoring_result==
[fit 211/850] END C=0.25, gamma=1.0, kernel=rbf; total=2625, TP=70, TN=1457, FP=1043, FN=55; precision=0.063, recall=0.560
accuracy: (test=0.582) average_precision: (test=0.066) balanced_accuracy: (test=0.571) f1: (test=0.113) roc_auc: (test=0.606) 9.74s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1538, FP=962, FN=55; precision=0.068, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.613) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.079) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.588) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.121) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.632) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1538, 'FP': 962, 'FN': 55, 'precision': 0.06782945736434108, 'recall': 0.56, 'accuracy': 0.6125714285714285, 'average_precision': 0.07853305259063437, 'balanced_accuracy': 0.5876, 'f1': 0.12100259291270526, 'roc_auc': 0.6324128}
==getted_scoring_result==
[fit 212/850] END C=0.25, gamma=2.0, kernel=rbf; total=2625, TP=70, TN=1538, FP=962, FN=55; precision=0.068, recall=0.560
accuracy: (test=0.613) average_precision: (test=0.079) balanced_accuracy: (test=0.588) f1: (test=0.121) roc_auc: (test=0.632) 9.76s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1631, FP=869, FN=53; precision=0.077, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.649) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.091) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.614) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.135) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.665) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1631, 'FP': 869, 'FN': 53, 'precision': 0.0765143464399575, 'recall': 0.576, 'accuracy': 0.6487619047619048, 'average_precision': 0.0910725022590081, 'balanced_accuracy': 0.6142, 'f1': 0.1350844277673546, 'roc_auc': 0.6645216}
==getted_scoring_result==
[fit 213/850] END C=0.25, gamma=4.0, kernel=rbf; total=2625, TP=72, TN=1631, FP=869, FN=53; precision=0.077, recall=0.576
accuracy: (test=0.649) average_precision: (test=0.091) balanced_accuracy: (test=0.614) f1: (test=0.135) roc_auc: (test=0.665) 9.80s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1741, FP=759, FN=51; precision=0.089, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.691) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.118) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.644) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.154) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.715) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1741, 'FP': 759, 'FN': 51, 'precision': 0.08883553421368548, 'recall': 0.592, 'accuracy': 0.6914285714285714, 'average_precision': 0.11826340998483656, 'balanced_accuracy': 0.6442, 'f1': 0.15448851774530273, 'roc_auc': 0.7150656}
==getted_scoring_result==
[fit 214/850] END C=0.25, gamma=8.0, kernel=rbf; total=2625, TP=74, TN=1741, FP=759, FN=51; precision=0.089, recall=0.592
accuracy: (test=0.691) average_precision: (test=0.118) balanced_accuracy: (test=0.644) f1: (test=0.154) roc_auc: (test=0.715) 10.06s
==get_scoring_result==
base_score: total=2625, TP=78, TN=1913, FP=587, FN=47; precision=0.117, recall=0.624

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.758) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.176) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.695) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.197) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.780) ===
score_result_dict: {'Total': 2625, 'TP': 78, 'TN': 1913, 'FP': 587, 'FN': 47, 'precision': 0.11729323308270677, 'recall': 0.624, 'accuracy': 0.7584761904761905, 'average_precision': 0.1757137578350494, 'balanced_accuracy': 0.6946, 'f1': 0.19746835443037977, 'roc_auc': 0.7795872}
==getted_scoring_result==
[fit 215/850] END C=0.25, gamma=16.0, kernel=rbf; total=2625, TP=78, TN=1913, FP=587, FN=47; precision=0.117, recall=0.624
accuracy: (test=0.758) average_precision: (test=0.176) balanced_accuracy: (test=0.695) f1: (test=0.197) roc_auc: (test=0.780) 10.10s
==get_scoring_result==
base_score: total=2625, TP=83, TN=2145, FP=355, FN=42; precision=0.189, recall=0.664

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.849) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.311) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.761) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.295) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.853) ===
score_result_dict: {'Total': 2625, 'TP': 83, 'TN': 2145, 'FP': 355, 'FN': 42, 'precision': 0.18949771689497716, 'recall': 0.664, 'accuracy': 0.8487619047619047, 'average_precision': 0.31091472337676246, 'balanced_accuracy': 0.761, 'f1': 0.29484902309058614, 'roc_auc': 0.8525504}
==getted_scoring_result==
[fit 216/850] END C=0.25, gamma=32.0, kernel=rbf; total=2625, TP=83, TN=2145, FP=355, FN=42; precision=0.189, recall=0.664
accuracy: (test=0.849) average_precision: (test=0.311) balanced_accuracy: (test=0.761) f1: (test=0.295) roc_auc: (test=0.853) 9.80s
==get_scoring_result==
base_score: total=2625, TP=80, TN=2334, FP=166, FN=45; precision=0.325, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.920) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.549) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.787) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.431) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.891) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2334, 'FP': 166, 'FN': 45, 'precision': 0.3252032520325203, 'recall': 0.64, 'accuracy': 0.9196190476190477, 'average_precision': 0.5486286352135821, 'balanced_accuracy': 0.7867999999999999, 'f1': 0.431266846361186, 'roc_auc': 0.8908496}
==getted_scoring_result==
[fit 217/850] END C=0.25, gamma=64.0, kernel=rbf; total=2625, TP=80, TN=2334, FP=166, FN=45; precision=0.325, recall=0.640
accuracy: (test=0.920) average_precision: (test=0.549) balanced_accuracy: (test=0.787) f1: (test=0.431) roc_auc: (test=0.891) 10.42s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2420, FP=80, FN=49; precision=0.487, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.951) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.652) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.788) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.541) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.898) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2420, 'FP': 80, 'FN': 49, 'precision': 0.48717948717948717, 'recall': 0.608, 'accuracy': 0.9508571428571428, 'average_precision': 0.6519412267120059, 'balanced_accuracy': 0.788, 'f1': 0.5409252669039146, 'roc_auc': 0.8976416}
==getted_scoring_result==
[fit 218/850] END C=0.25, gamma=128.0, kernel=rbf; total=2625, TP=76, TN=2420, FP=80, FN=49; precision=0.487, recall=0.608
accuracy: (test=0.951) average_precision: (test=0.652) balanced_accuracy: (test=0.788) f1: (test=0.541) roc_auc: (test=0.898) 11.53s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2453, FP=47, FN=51; precision=0.612, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.652) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.787) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.602) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.882) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2453, 'FP': 47, 'FN': 51, 'precision': 0.6115702479338843, 'recall': 0.592, 'accuracy': 0.9626666666666667, 'average_precision': 0.6521323623074937, 'balanced_accuracy': 0.7866, 'f1': 0.6016260162601625, 'roc_auc': 0.8822528}
==getted_scoring_result==
[fit 219/850] END C=0.25, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2453, FP=47, FN=51; precision=0.612, recall=0.592
accuracy: (test=0.963) average_precision: (test=0.652) balanced_accuracy: (test=0.787) f1: (test=0.602) roc_auc: (test=0.882) 13.72s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2474, FP=26, FN=51; precision=0.740, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.791) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.658) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.863) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2474, 'FP': 26, 'FN': 51, 'precision': 0.74, 'recall': 0.592, 'accuracy': 0.9706666666666667, 'average_precision': 0.6489662521951013, 'balanced_accuracy': 0.7908, 'f1': 0.6577777777777778, 'roc_auc': 0.8632928}
==getted_scoring_result==
[fit 220/850] END C=0.25, gamma=512.0, kernel=rbf; total=2625, TP=74, TN=2474, FP=26, FN=51; precision=0.740, recall=0.592
accuracy: (test=0.971) average_precision: (test=0.649) balanced_accuracy: (test=0.791) f1: (test=0.658) roc_auc: (test=0.863) 15.71s
==get_scoring_result==
base_score: total=2625, TP=69, TN=2489, FP=11, FN=56; precision=0.863, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.654) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.774) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 2489, 'FP': 11, 'FN': 56, 'precision': 0.8625, 'recall': 0.552, 'accuracy': 0.9744761904761905, 'average_precision': 0.6541691840752644, 'balanced_accuracy': 0.7738, 'f1': 0.6731707317073171, 'roc_auc': 0.8471584}
==getted_scoring_result==
[fit 221/850] END C=0.25, gamma=1024.0, kernel=rbf; total=2625, TP=69, TN=2489, FP=11, FN=56; precision=0.863, recall=0.552
accuracy: (test=0.974) average_precision: (test=0.654) balanced_accuracy: (test=0.774) f1: (test=0.673) roc_auc: (test=0.847) 15.88s
==get_scoring_result==
base_score: total=2625, TP=26, TN=2500, FP=0, FN=99; precision=1.000, recall=0.208

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.962) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.645) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.604) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.344) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.832) ===
score_result_dict: {'Total': 2625, 'TP': 26, 'TN': 2500, 'FP': 0, 'FN': 99, 'precision': 1.0, 'recall': 0.208, 'accuracy': 0.9622857142857143, 'average_precision': 0.6445598323931643, 'balanced_accuracy': 0.604, 'f1': 0.3443708609271523, 'roc_auc': 0.832416}
==getted_scoring_result==
[fit 222/850] END C=0.25, gamma=2048.0, kernel=rbf; total=2625, TP=26, TN=2500, FP=0, FN=99; precision=1.000, recall=0.208
accuracy: (test=0.962) average_precision: (test=0.645) balanced_accuracy: (test=0.604) f1: (test=0.344) roc_auc: (test=0.832) 9.72s
==get_scoring_result==
base_score: total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.960) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.588) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.584) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.288) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.807) ===
score_result_dict: {'Total': 2625, 'TP': 21, 'TN': 2500, 'FP': 0, 'FN': 104, 'precision': 1.0, 'recall': 0.168, 'accuracy': 0.9603809523809523, 'average_precision': 0.5878639395587429, 'balanced_accuracy': 0.584, 'f1': 0.28767123287671237, 'roc_auc': 0.8067872}
==getted_scoring_result==
[fit 223/850] END C=0.25, gamma=4096.0, kernel=rbf; total=2625, TP=21, TN=2500, FP=0, FN=104; precision=1.000, recall=0.168
accuracy: (test=0.960) average_precision: (test=0.588) balanced_accuracy: (test=0.584) f1: (test=0.288) roc_auc: (test=0.807) 9.70s
==get_scoring_result==
base_score: total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.957) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.476) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.552) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.188) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.738) ===
score_result_dict: {'Total': 2625, 'TP': 13, 'TN': 2500, 'FP': 0, 'FN': 112, 'precision': 1.0, 'recall': 0.104, 'accuracy': 0.9573333333333334, 'average_precision': 0.4757612433988784, 'balanced_accuracy': 0.552, 'f1': 0.18840579710144925, 'roc_auc': 0.7376128}
==getted_scoring_result==
[fit 224/850] END C=0.25, gamma=8192.0, kernel=rbf; total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104
accuracy: (test=0.957) average_precision: (test=0.476) balanced_accuracy: (test=0.552) f1: (test=0.188) roc_auc: (test=0.738) 9.69s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.955) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.679) ===
score_result_dict: {'Total': 2625, 'TP': 6, 'TN': 2500, 'FP': 0, 'FN': 119, 'precision': 1.0, 'recall': 0.048, 'accuracy': 0.9546666666666667, 'average_precision': 0.36866430539157813, 'balanced_accuracy': 0.524, 'f1': 0.0916030534351145, 'roc_auc': 0.6791552}
==getted_scoring_result==
[fit 225/850] END C=0.25, gamma=16384.0, kernel=rbf; total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048
accuracy: (test=0.955) average_precision: (test=0.369) balanced_accuracy: (test=0.524) f1: (test=0.092) roc_auc: (test=0.679) 10.24s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.04623369626776429, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.506592}
==getted_scoring_result==
[fit 226/850] END C=0.5, gamma=0.0009765625, kernel=rbf; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.61s
==get_scoring_result==
base_score: total=2625, TP=87, TN=859, FP=1641, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 859, 'FP': 1641, 'FN': 38, 'precision': 0.050347222222222224, 'recall': 0.696, 'accuracy': 0.36038095238095236, 'average_precision': 0.04623735749473493, 'balanced_accuracy': 0.5198, 'f1': 0.09390178089584458, 'roc_auc': 0.5066624}
==getted_scoring_result==
[fit 227/850] END C=0.5, gamma=0.001953125, kernel=rbf; total=2625, TP=87, TN=859, FP=1641, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.58s
==get_scoring_result==
base_score: total=2625, TP=87, TN=860, FP=1640, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.361) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 860, 'FP': 1640, 'FN': 38, 'precision': 0.05037637521713955, 'recall': 0.696, 'accuracy': 0.3607619047619048, 'average_precision': 0.046238561192048486, 'balanced_accuracy': 0.52, 'f1': 0.09395248380129591, 'roc_auc': 0.506696}
==getted_scoring_result==
[fit 228/850] END C=0.5, gamma=0.00390625, kernel=rbf; total=2625, TP=87, TN=860, FP=1640, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.361) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.62s
==get_scoring_result==
base_score: total=2625, TP=80, TN=933, FP=1567, FN=45; precision=0.049, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.386) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.507) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.090) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 933, 'FP': 1567, 'FN': 45, 'precision': 0.048573163327261686, 'recall': 0.64, 'accuracy': 0.3859047619047619, 'average_precision': 0.04639764494856085, 'balanced_accuracy': 0.5065999999999999, 'f1': 0.09029345372460496, 'roc_auc': 0.5087984}
==getted_scoring_result==
[fit 229/850] END C=0.5, gamma=0.0078125, kernel=rbf; total=2625, TP=80, TN=933, FP=1567, FN=45; precision=0.049, recall=0.640
accuracy: (test=0.386) average_precision: (test=0.046) balanced_accuracy: (test=0.507) f1: (test=0.090) roc_auc: (test=0.509) 9.61s
==get_scoring_result==
base_score: total=2625, TP=65, TN=1286, FP=1214, FN=60; precision=0.051, recall=0.520

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.515) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.517) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.514) ===
score_result_dict: {'Total': 2625, 'TP': 65, 'TN': 1286, 'FP': 1214, 'FN': 60, 'precision': 0.0508209538702111, 'recall': 0.52, 'accuracy': 0.5146666666666667, 'average_precision': 0.047005180505975894, 'balanced_accuracy': 0.5172, 'f1': 0.09259259259259259, 'roc_auc': 0.5143296}
==getted_scoring_result==
[fit 230/850] END C=0.5, gamma=0.015625, kernel=rbf; total=2625, TP=65, TN=1286, FP=1214, FN=60; precision=0.051, recall=0.520
accuracy: (test=0.515) average_precision: (test=0.047) balanced_accuracy: (test=0.517) f1: (test=0.093) roc_auc: (test=0.514) 9.67s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1299, FP=1201, FN=58; precision=0.053, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.520) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.528) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1299, 'FP': 1201, 'FN': 58, 'precision': 0.0528391167192429, 'recall': 0.536, 'accuracy': 0.5203809523809524, 'average_precision': 0.04819678433523067, 'balanced_accuracy': 0.5278, 'f1': 0.09619526202440774, 'roc_auc': 0.5232496}
==getted_scoring_result==
[fit 231/850] END C=0.5, gamma=0.03125, kernel=rbf; total=2625, TP=67, TN=1299, FP=1201, FN=58; precision=0.053, recall=0.536
accuracy: (test=0.520) average_precision: (test=0.048) balanced_accuracy: (test=0.528) f1: (test=0.096) roc_auc: (test=0.523) 10.07s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1324, FP=1176, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.530) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.533) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.537) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1324, 'FP': 1176, 'FN': 58, 'precision': 0.053901850362027354, 'recall': 0.536, 'accuracy': 0.5299047619047619, 'average_precision': 0.05011851469739469, 'balanced_accuracy': 0.5327999999999999, 'f1': 0.09795321637426901, 'roc_auc': 0.537368}
==getted_scoring_result==
[fit 232/850] END C=0.5, gamma=0.0625, kernel=rbf; total=2625, TP=67, TN=1324, FP=1176, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.530) average_precision: (test=0.050) balanced_accuracy: (test=0.533) f1: (test=0.098) roc_auc: (test=0.537) 10.35s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1354, FP=1146, FN=56; precision=0.057, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.542) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.547) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.556) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1354, 'FP': 1146, 'FN': 56, 'precision': 0.056790123456790124, 'recall': 0.552, 'accuracy': 0.5420952380952381, 'average_precision': 0.05317230384090713, 'balanced_accuracy': 0.5468, 'f1': 0.10298507462686568, 'roc_auc': 0.5556752}
==getted_scoring_result==
[fit 233/850] END C=0.5, gamma=0.125, kernel=rbf; total=2625, TP=69, TN=1354, FP=1146, FN=56; precision=0.057, recall=0.552
accuracy: (test=0.542) average_precision: (test=0.053) balanced_accuracy: (test=0.547) f1: (test=0.103) roc_auc: (test=0.556) 10.28s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1390, FP=1110, FN=59; precision=0.056, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.555) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.542) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.101) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.579) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1390, 'FP': 1110, 'FN': 59, 'precision': 0.05612244897959184, 'recall': 0.528, 'accuracy': 0.5546666666666666, 'average_precision': 0.057909150100177595, 'balanced_accuracy': 0.542, 'f1': 0.10146041506533436, 'roc_auc': 0.5786016}
==getted_scoring_result==
[fit 234/850] END C=0.5, gamma=0.25, kernel=rbf; total=2625, TP=66, TN=1390, FP=1110, FN=59; precision=0.056, recall=0.528
accuracy: (test=0.555) average_precision: (test=0.058) balanced_accuracy: (test=0.542) f1: (test=0.101) roc_auc: (test=0.579) 10.43s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1461, FP=1039, FN=53; precision=0.065, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.584) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.066) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.580) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.117) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.606) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1461, 'FP': 1039, 'FN': 53, 'precision': 0.06480648064806481, 'recall': 0.576, 'accuracy': 0.584, 'average_precision': 0.06604394505267606, 'balanced_accuracy': 0.5802, 'f1': 0.11650485436893204, 'roc_auc': 0.6058848}
==getted_scoring_result==
[fit 235/850] END C=0.5, gamma=0.5, kernel=rbf; total=2625, TP=72, TN=1461, FP=1039, FN=53; precision=0.065, recall=0.576
accuracy: (test=0.584) average_precision: (test=0.066) balanced_accuracy: (test=0.580) f1: (test=0.117) roc_auc: (test=0.606) 10.38s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1510, FP=990, FN=55; precision=0.066, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.602) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.077) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.582) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.118) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.632) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1510, 'FP': 990, 'FN': 55, 'precision': 0.0660377358490566, 'recall': 0.56, 'accuracy': 0.6019047619047619, 'average_precision': 0.07738283755337369, 'balanced_accuracy': 0.5820000000000001, 'f1': 0.1181434599156118, 'roc_auc': 0.6316992}
==getted_scoring_result==
[fit 236/850] END C=0.5, gamma=1.0, kernel=rbf; total=2625, TP=70, TN=1510, FP=990, FN=55; precision=0.066, recall=0.560
accuracy: (test=0.602) average_precision: (test=0.077) balanced_accuracy: (test=0.582) f1: (test=0.118) roc_auc: (test=0.632) 10.16s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1619, FP=881, FN=55; precision=0.074, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.643) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.088) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.604) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.658) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1619, 'FP': 881, 'FN': 55, 'precision': 0.07360672975814932, 'recall': 0.56, 'accuracy': 0.6434285714285715, 'average_precision': 0.08819756850507335, 'balanced_accuracy': 0.6038, 'f1': 0.13011152416356878, 'roc_auc': 0.6584672}
==getted_scoring_result==
[fit 237/850] END C=0.5, gamma=2.0, kernel=rbf; total=2625, TP=70, TN=1619, FP=881, FN=55; precision=0.074, recall=0.560
accuracy: (test=0.643) average_precision: (test=0.088) balanced_accuracy: (test=0.604) f1: (test=0.130) roc_auc: (test=0.658) 10.21s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1697, FP=803, FN=51; precision=0.084, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.675) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.104) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.635) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.696) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1697, 'FP': 803, 'FN': 51, 'precision': 0.08437856328392246, 'recall': 0.592, 'accuracy': 0.6746666666666666, 'average_precision': 0.1037539992449189, 'balanced_accuracy': 0.6354, 'f1': 0.14770459081836326, 'roc_auc': 0.6961312}
==getted_scoring_result==
[fit 238/850] END C=0.5, gamma=4.0, kernel=rbf; total=2625, TP=74, TN=1697, FP=803, FN=51; precision=0.084, recall=0.592
accuracy: (test=0.675) average_precision: (test=0.104) balanced_accuracy: (test=0.635) f1: (test=0.148) roc_auc: (test=0.696) 10.36s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=82, TN=1825, FP=675, FN=43; precision=0.108, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.726) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.143) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.693) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.186) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.750) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 1825, 'FP': 675, 'FN': 43, 'precision': 0.1083223249669749, 'recall': 0.656, 'accuracy': 0.7264761904761905, 'average_precision': 0.1426956247605747, 'balanced_accuracy': 0.6930000000000001, 'f1': 0.18594104308390022, 'roc_auc': 0.7503072}
==getted_scoring_result==
[fit 239/850] END C=0.5, gamma=8.0, kernel=rbf; total=2625, TP=82, TN=1825, FP=675, FN=43; precision=0.108, recall=0.656
accuracy: (test=0.726) average_precision: (test=0.143) balanced_accuracy: (test=0.693) f1: (test=0.186) roc_auc: (test=0.750) 10.42s
==get_scoring_result==
base_score: total=2625, TP=87, TN=2014, FP=486, FN=38; precision=0.152, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.800) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.227) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.751) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.249) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.826) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 2014, 'FP': 486, 'FN': 38, 'precision': 0.1518324607329843, 'recall': 0.696, 'accuracy': 0.8003809523809524, 'average_precision': 0.22716062353298758, 'balanced_accuracy': 0.7507999999999999, 'f1': 0.2492836676217765, 'roc_auc': 0.825784}
==getted_scoring_result==
[fit 240/850] END C=0.5, gamma=16.0, kernel=rbf; total=2625, TP=87, TN=2014, FP=486, FN=38; precision=0.152, recall=0.696
accuracy: (test=0.800) average_precision: (test=0.227) balanced_accuracy: (test=0.751) f1: (test=0.249) roc_auc: (test=0.826) 9.95s
==get_scoring_result==
base_score: total=2625, TP=86, TN=2259, FP=241, FN=39; precision=0.263, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.893) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.437) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.796) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.381) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.884) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 2259, 'FP': 241, 'FN': 39, 'precision': 0.26299694189602446, 'recall': 0.688, 'accuracy': 0.8933333333333333, 'average_precision': 0.4372498393870267, 'balanced_accuracy': 0.7958, 'f1': 0.3805309734513274, 'roc_auc': 0.8836096}
==getted_scoring_result==
[fit 241/850] END C=0.5, gamma=32.0, kernel=rbf; total=2625, TP=86, TN=2259, FP=241, FN=39; precision=0.263, recall=0.688
accuracy: (test=0.893) average_precision: (test=0.437) balanced_accuracy: (test=0.796) f1: (test=0.381) roc_auc: (test=0.884) 10.72s
==get_scoring_result==
base_score: total=2625, TP=79, TN=2389, FP=111, FN=46; precision=0.416, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.940) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.643) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.794) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.502) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.902) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2389, 'FP': 111, 'FN': 46, 'precision': 0.41578947368421054, 'recall': 0.632, 'accuracy': 0.9401904761904762, 'average_precision': 0.6426642316305952, 'balanced_accuracy': 0.7938000000000001, 'f1': 0.5015873015873016, 'roc_auc': 0.902152}
==getted_scoring_result==
[fit 242/850] END C=0.5, gamma=64.0, kernel=rbf; total=2625, TP=79, TN=2389, FP=111, FN=46; precision=0.416, recall=0.632
accuracy: (test=0.940) average_precision: (test=0.643) balanced_accuracy: (test=0.794) f1: (test=0.502) roc_auc: (test=0.902) 11.93s
==get_scoring_result==
base_score: total=2625, TP=77, TN=2452, FP=48, FN=48; precision=0.616, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.684) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.798) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.616) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.897) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 2452, 'FP': 48, 'FN': 48, 'precision': 0.616, 'recall': 0.616, 'accuracy': 0.9634285714285714, 'average_precision': 0.6844473157458595, 'balanced_accuracy': 0.7984, 'f1': 0.616, 'roc_auc': 0.896976}
==getted_scoring_result==
[fit 243/850] END C=0.5, gamma=128.0, kernel=rbf; total=2625, TP=77, TN=2452, FP=48, FN=48; precision=0.616, recall=0.616
accuracy: (test=0.963) average_precision: (test=0.684) balanced_accuracy: (test=0.798) f1: (test=0.616) roc_auc: (test=0.897) 14.90s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2472, FP=28, FN=50; precision=0.728, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.676) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.794) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.658) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.886) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2472, 'FP': 28, 'FN': 50, 'precision': 0.7281553398058253, 'recall': 0.6, 'accuracy': 0.9702857142857143, 'average_precision': 0.6759393483567009, 'balanced_accuracy': 0.7944, 'f1': 0.6578947368421052, 'roc_auc': 0.8864064}
==getted_scoring_result==
[fit 244/850] END C=0.5, gamma=256.0, kernel=rbf; total=2625, TP=75, TN=2472, FP=28, FN=50; precision=0.728, recall=0.600
accuracy: (test=0.970) average_precision: (test=0.676) balanced_accuracy: (test=0.794) f1: (test=0.658) roc_auc: (test=0.886) 18.31s
==get_scoring_result==
base_score: total=2625, TP=72, TN=2478, FP=22, FN=53; precision=0.766, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.657) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.784) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.658) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.868) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 2478, 'FP': 22, 'FN': 53, 'precision': 0.7659574468085106, 'recall': 0.576, 'accuracy': 0.9714285714285714, 'average_precision': 0.6571944957734696, 'balanced_accuracy': 0.7836, 'f1': 0.6575342465753425, 'roc_auc': 0.8675488}
==getted_scoring_result==
[fit 245/850] END C=0.5, gamma=512.0, kernel=rbf; total=2625, TP=72, TN=2478, FP=22, FN=53; precision=0.766, recall=0.576
accuracy: (test=0.971) average_precision: (test=0.657) balanced_accuracy: (test=0.784) f1: (test=0.658) roc_auc: (test=0.868) 20.46s
==get_scoring_result==
base_score: total=2625, TP=63, TN=2496, FP=4, FN=62; precision=0.940, recall=0.504

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.975) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.657) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.751) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.656) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.850) ===
score_result_dict: {'Total': 2625, 'TP': 63, 'TN': 2496, 'FP': 4, 'FN': 62, 'precision': 0.9402985074626866, 'recall': 0.504, 'accuracy': 0.9748571428571429, 'average_precision': 0.6569256652730202, 'balanced_accuracy': 0.7512, 'f1': 0.65625, 'roc_auc': 0.8504016}
==getted_scoring_result==
[fit 246/850] END C=0.5, gamma=1024.0, kernel=rbf; total=2625, TP=63, TN=2496, FP=4, FN=62; precision=0.940, recall=0.504
accuracy: (test=0.975) average_precision: (test=0.657) balanced_accuracy: (test=0.751) f1: (test=0.656) roc_auc: (test=0.850) 21.43s
==get_scoring_result==
base_score: total=2625, TP=49, TN=2500, FP=0, FN=76; precision=1.000, recall=0.392

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.648) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.696) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.563) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.833) ===
score_result_dict: {'Total': 2625, 'TP': 49, 'TN': 2500, 'FP': 0, 'FN': 76, 'precision': 1.0, 'recall': 0.392, 'accuracy': 0.971047619047619, 'average_precision': 0.6481538541561189, 'balanced_accuracy': 0.696, 'f1': 0.5632183908045978, 'roc_auc': 0.8332}
==getted_scoring_result==
[fit 247/850] END C=0.5, gamma=2048.0, kernel=rbf; total=2625, TP=49, TN=2500, FP=0, FN=76; precision=1.000, recall=0.392
accuracy: (test=0.971) average_precision: (test=0.648) balanced_accuracy: (test=0.696) f1: (test=0.563) roc_auc: (test=0.833) 19.71s
==get_scoring_result==
base_score: total=2625, TP=22, TN=2500, FP=0, FN=103; precision=1.000, recall=0.176

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.961) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.593) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.588) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.299) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.809) ===
score_result_dict: {'Total': 2625, 'TP': 22, 'TN': 2500, 'FP': 0, 'FN': 103, 'precision': 1.0, 'recall': 0.176, 'accuracy': 0.9607619047619048, 'average_precision': 0.593295156547796, 'balanced_accuracy': 0.588, 'f1': 0.29931972789115646, 'roc_auc': 0.8088608}
==getted_scoring_result==
[fit 248/850] END C=0.5, gamma=4096.0, kernel=rbf; total=2625, TP=22, TN=2500, FP=0, FN=103; precision=1.000, recall=0.176
accuracy: (test=0.961) average_precision: (test=0.593) balanced_accuracy: (test=0.588) f1: (test=0.299) roc_auc: (test=0.809) 10.96s
==get_scoring_result==
base_score: total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.957) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.504) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.552) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.188) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.752) ===
score_result_dict: {'Total': 2625, 'TP': 13, 'TN': 2500, 'FP': 0, 'FN': 112, 'precision': 1.0, 'recall': 0.104, 'accuracy': 0.9573333333333334, 'average_precision': 0.5043033288175808, 'balanced_accuracy': 0.552, 'f1': 0.18840579710144925, 'roc_auc': 0.7519584}
==getted_scoring_result==
[fit 249/850] END C=0.5, gamma=8192.0, kernel=rbf; total=2625, TP=13, TN=2500, FP=0, FN=112; precision=1.000, recall=0.104
accuracy: (test=0.957) average_precision: (test=0.504) balanced_accuracy: (test=0.552) f1: (test=0.188) roc_auc: (test=0.752) 11.15s
==get_scoring_result==
base_score: total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.955) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.679) ===
score_result_dict: {'Total': 2625, 'TP': 6, 'TN': 2500, 'FP': 0, 'FN': 119, 'precision': 1.0, 'recall': 0.048, 'accuracy': 0.9546666666666667, 'average_precision': 0.3686900354470264, 'balanced_accuracy': 0.524, 'f1': 0.0916030534351145, 'roc_auc': 0.6794208}
==getted_scoring_result==
[fit 250/850] END C=0.5, gamma=16384.0, kernel=rbf; total=2625, TP=6, TN=2500, FP=0, FN=119; precision=1.000, recall=0.048
accuracy: (test=0.955) average_precision: (test=0.369) balanced_accuracy: (test=0.524) f1: (test=0.092) roc_auc: (test=0.679) 11.29s
==get_scoring_result==
base_score: total=2625, TP=87, TN=859, FP=1641, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 859, 'FP': 1641, 'FN': 38, 'precision': 0.050347222222222224, 'recall': 0.696, 'accuracy': 0.36038095238095236, 'average_precision': 0.04623628178983642, 'balanced_accuracy': 0.5198, 'f1': 0.09390178089584458, 'roc_auc': 0.5066528}
==getted_scoring_result==
[fit 251/850] END C=1.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=87, TN=859, FP=1641, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.98s
==get_scoring_result==
base_score: total=2625, TP=87, TN=860, FP=1640, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.361) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 860, 'FP': 1640, 'FN': 38, 'precision': 0.05037637521713955, 'recall': 0.696, 'accuracy': 0.3607619047619048, 'average_precision': 0.04623945651036898, 'balanced_accuracy': 0.52, 'f1': 0.09395248380129591, 'roc_auc': 0.50672}
==getted_scoring_result==
[fit 252/850] END C=1.0, gamma=0.001953125, kernel=rbf; total=2625, TP=87, TN=860, FP=1640, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.361) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.74s
==get_scoring_result==
base_score: total=2625, TP=64, TN=1219, FP=1281, FN=61; precision=0.048, recall=0.512

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.489) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.087) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 64, 'TN': 1219, 'FP': 1281, 'FN': 61, 'precision': 0.04758364312267658, 'recall': 0.512, 'accuracy': 0.4887619047619048, 'average_precision': 0.04640318991383827, 'balanced_accuracy': 0.4998, 'f1': 0.08707482993197278, 'roc_auc': 0.5089968}
==getted_scoring_result==
[fit 253/850] END C=1.0, gamma=0.00390625, kernel=rbf; total=2625, TP=64, TN=1219, FP=1281, FN=61; precision=0.048, recall=0.512
accuracy: (test=0.489) average_precision: (test=0.046) balanced_accuracy: (test=0.500) f1: (test=0.087) roc_auc: (test=0.509) 11.19s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1136, FP=1364, FN=53; precision=0.050, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.460) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.515) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.514) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1136, 'FP': 1364, 'FN': 53, 'precision': 0.05013927576601671, 'recall': 0.576, 'accuracy': 0.4601904761904762, 'average_precision': 0.04700350174335617, 'balanced_accuracy': 0.5152, 'f1': 0.09224855861627161, 'roc_auc': 0.5143808}
==getted_scoring_result==
[fit 254/850] END C=1.0, gamma=0.0078125, kernel=rbf; total=2625, TP=72, TN=1136, FP=1364, FN=53; precision=0.050, recall=0.576
accuracy: (test=0.460) average_precision: (test=0.047) balanced_accuracy: (test=0.515) f1: (test=0.092) roc_auc: (test=0.514) 10.17s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1299, FP=1201, FN=59; precision=0.052, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.520) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1299, 'FP': 1201, 'FN': 59, 'precision': 0.05209155485398579, 'recall': 0.528, 'accuracy': 0.52, 'average_precision': 0.04817114429516113, 'balanced_accuracy': 0.5238, 'f1': 0.09482758620689655, 'roc_auc': 0.5229776}
==getted_scoring_result==
[fit 255/850] END C=1.0, gamma=0.015625, kernel=rbf; total=2625, TP=66, TN=1299, FP=1201, FN=59; precision=0.052, recall=0.528
accuracy: (test=0.520) average_precision: (test=0.048) balanced_accuracy: (test=0.524) f1: (test=0.095) roc_auc: (test=0.523) 9.85s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1324, FP=1176, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.530) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.533) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.538) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1324, 'FP': 1176, 'FN': 58, 'precision': 0.053901850362027354, 'recall': 0.536, 'accuracy': 0.5299047619047619, 'average_precision': 0.05015871595919385, 'balanced_accuracy': 0.5327999999999999, 'f1': 0.09795321637426901, 'roc_auc': 0.5375424}
==getted_scoring_result==
[fit 256/850] END C=1.0, gamma=0.03125, kernel=rbf; total=2625, TP=67, TN=1324, FP=1176, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.530) average_precision: (test=0.050) balanced_accuracy: (test=0.533) f1: (test=0.098) roc_auc: (test=0.538) 10.01s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1349, FP=1151, FN=56; precision=0.057, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.540) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.546) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.556) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1349, 'FP': 1151, 'FN': 56, 'precision': 0.056557377049180325, 'recall': 0.552, 'accuracy': 0.5401904761904762, 'average_precision': 0.05323163529219148, 'balanced_accuracy': 0.5458000000000001, 'f1': 0.10260223048327137, 'roc_auc': 0.5558368}
==getted_scoring_result==
[fit 257/850] END C=1.0, gamma=0.0625, kernel=rbf; total=2625, TP=69, TN=1349, FP=1151, FN=56; precision=0.057, recall=0.552
accuracy: (test=0.540) average_precision: (test=0.053) balanced_accuracy: (test=0.546) f1: (test=0.103) roc_auc: (test=0.556) 10.08s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=66, TN=1393, FP=1107, FN=59; precision=0.056, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.556) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.543) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.102) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.579) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1393, 'FP': 1107, 'FN': 59, 'precision': 0.056265984654731455, 'recall': 0.528, 'accuracy': 0.5558095238095239, 'average_precision': 0.057984787041041055, 'balanced_accuracy': 0.5426, 'f1': 0.1016949152542373, 'roc_auc': 0.57896}
==getted_scoring_result==
[fit 258/850] END C=1.0, gamma=0.125, kernel=rbf; total=2625, TP=66, TN=1393, FP=1107, FN=59; precision=0.056, recall=0.528
accuracy: (test=0.556) average_precision: (test=0.058) balanced_accuracy: (test=0.543) f1: (test=0.102) roc_auc: (test=0.579) 10.26s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1470, FP=1030, FN=56; precision=0.063, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.586) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.066) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.570) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.113) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.605) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1470, 'FP': 1030, 'FN': 56, 'precision': 0.06278434940855324, 'recall': 0.552, 'accuracy': 0.5862857142857143, 'average_precision': 0.06566726530557898, 'balanced_accuracy': 0.5700000000000001, 'f1': 0.11274509803921569, 'roc_auc': 0.605152}
==getted_scoring_result==
[fit 259/850] END C=1.0, gamma=0.25, kernel=rbf; total=2625, TP=69, TN=1470, FP=1030, FN=56; precision=0.063, recall=0.552
accuracy: (test=0.586) average_precision: (test=0.066) balanced_accuracy: (test=0.570) f1: (test=0.113) roc_auc: (test=0.605) 10.05s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=71, TN=1501, FP=999, FN=54; precision=0.066, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.599) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.076) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.584) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.119) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.630) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1501, 'FP': 999, 'FN': 54, 'precision': 0.06635514018691589, 'recall': 0.568, 'accuracy': 0.5988571428571429, 'average_precision': 0.07641819223884565, 'balanced_accuracy': 0.5842, 'f1': 0.1188284518828452, 'roc_auc': 0.6302016}
==getted_scoring_result==
[fit 260/850] END C=1.0, gamma=0.5, kernel=rbf; total=2625, TP=71, TN=1501, FP=999, FN=54; precision=0.066, recall=0.568
accuracy: (test=0.599) average_precision: (test=0.076) balanced_accuracy: (test=0.584) f1: (test=0.119) roc_auc: (test=0.630) 10.39s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1593, FP=907, FN=54; precision=0.073, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.634) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.603) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.129) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.654) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1593, 'FP': 907, 'FN': 54, 'precision': 0.07259713701431493, 'recall': 0.568, 'accuracy': 0.6339047619047619, 'average_precision': 0.08607440987702725, 'balanced_accuracy': 0.6026, 'f1': 0.128739800543971, 'roc_auc': 0.653528}
==getted_scoring_result==
[fit 261/850] END C=1.0, gamma=1.0, kernel=rbf; total=2625, TP=71, TN=1593, FP=907, FN=54; precision=0.073, recall=0.568
accuracy: (test=0.634) average_precision: (test=0.086) balanced_accuracy: (test=0.603) f1: (test=0.129) roc_auc: (test=0.654) 10.27s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1642, FP=858, FN=52; precision=0.078, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.653) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.095) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.620) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.138) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1642, 'FP': 858, 'FN': 52, 'precision': 0.07841031149301826, 'recall': 0.584, 'accuracy': 0.6533333333333333, 'average_precision': 0.09498265356726748, 'balanced_accuracy': 0.6204000000000001, 'f1': 0.13825757575757575, 'roc_auc': 0.6803056}
==getted_scoring_result==
[fit 262/850] END C=1.0, gamma=2.0, kernel=rbf; total=2625, TP=73, TN=1642, FP=858, FN=52; precision=0.078, recall=0.584
accuracy: (test=0.653) average_precision: (test=0.095) balanced_accuracy: (test=0.620) f1: (test=0.138) roc_auc: (test=0.680) 10.70s
==get_scoring_result==
base_score: total=2625, TP=83, TN=1750, FP=750, FN=42; precision=0.100, recall=0.664

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.698) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.118) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.682) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.173) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.725) ===
score_result_dict: {'Total': 2625, 'TP': 83, 'TN': 1750, 'FP': 750, 'FN': 42, 'precision': 0.09963985594237695, 'recall': 0.664, 'accuracy': 0.6982857142857143, 'average_precision': 0.11849547202183043, 'balanced_accuracy': 0.6819999999999999, 'f1': 0.1732776617954071, 'roc_auc': 0.7245312}
==getted_scoring_result==
[fit 263/850] END C=1.0, gamma=4.0, kernel=rbf; total=2625, TP=83, TN=1750, FP=750, FN=42; precision=0.100, recall=0.664
accuracy: (test=0.698) average_precision: (test=0.118) balanced_accuracy: (test=0.682) f1: (test=0.173) roc_auc: (test=0.725) 10.74s
==get_scoring_result==
base_score: total=2625, TP=83, TN=1899, FP=601, FN=42; precision=0.121, recall=0.664

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.755) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.175) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.712) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.205) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.787) ===
score_result_dict: {'Total': 2625, 'TP': 83, 'TN': 1899, 'FP': 601, 'FN': 42, 'precision': 0.12134502923976608, 'recall': 0.664, 'accuracy': 0.7550476190476191, 'average_precision': 0.17542310920505463, 'balanced_accuracy': 0.7118, 'f1': 0.20519159456118663, 'roc_auc': 0.7872448}
==getted_scoring_result==
[fit 264/850] END C=1.0, gamma=8.0, kernel=rbf; total=2625, TP=83, TN=1899, FP=601, FN=42; precision=0.121, recall=0.664
accuracy: (test=0.755) average_precision: (test=0.175) balanced_accuracy: (test=0.712) f1: (test=0.205) roc_auc: (test=0.787) 10.97s
==get_scoring_result==
base_score: total=2625, TP=88, TN=2126, FP=374, FN=37; precision=0.190, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.843) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.304) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.777) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.300) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.859) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 2126, 'FP': 374, 'FN': 37, 'precision': 0.19047619047619047, 'recall': 0.704, 'accuracy': 0.8434285714285714, 'average_precision': 0.3036661185890673, 'balanced_accuracy': 0.7772, 'f1': 0.2998296422487223, 'roc_auc': 0.8594176}
==getted_scoring_result==
[fit 265/850] END C=1.0, gamma=16.0, kernel=rbf; total=2625, TP=88, TN=2126, FP=374, FN=37; precision=0.190, recall=0.704
accuracy: (test=0.843) average_precision: (test=0.304) balanced_accuracy: (test=0.777) f1: (test=0.300) roc_auc: (test=0.859) 11.59s
==get_scoring_result==
base_score: total=2625, TP=87, TN=2336, FP=164, FN=38; precision=0.347, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.923) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.556) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.815) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.463) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.901) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 2336, 'FP': 164, 'FN': 38, 'precision': 0.3466135458167331, 'recall': 0.696, 'accuracy': 0.923047619047619, 'average_precision': 0.5563277585877123, 'balanced_accuracy': 0.8151999999999999, 'f1': 0.46276595744680854, 'roc_auc': 0.9012368}
==getted_scoring_result==
[fit 266/850] END C=1.0, gamma=32.0, kernel=rbf; total=2625, TP=87, TN=2336, FP=164, FN=38; precision=0.347, recall=0.696
accuracy: (test=0.923) average_precision: (test=0.556) balanced_accuracy: (test=0.815) f1: (test=0.463) roc_auc: (test=0.901) 13.32s
==get_scoring_result==
base_score: total=2625, TP=78, TN=2443, FP=57, FN=47; precision=0.578, recall=0.624

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.960) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.675) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.801) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.600) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.901) ===
score_result_dict: {'Total': 2625, 'TP': 78, 'TN': 2443, 'FP': 57, 'FN': 47, 'precision': 0.5777777777777777, 'recall': 0.624, 'accuracy': 0.9603809523809523, 'average_precision': 0.6751181752715317, 'balanced_accuracy': 0.8006, 'f1': 0.6000000000000001, 'roc_auc': 0.9014112}
==getted_scoring_result==
[fit 267/850] END C=1.0, gamma=64.0, kernel=rbf; total=2625, TP=78, TN=2443, FP=57, FN=47; precision=0.578, recall=0.624
accuracy: (test=0.960) average_precision: (test=0.675) balanced_accuracy: (test=0.801) f1: (test=0.600) roc_auc: (test=0.901) 15.30s
==get_scoring_result==
base_score: total=2625, TP=78, TN=2470, FP=30, FN=47; precision=0.722, recall=0.624

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.694) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.806) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.670) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.896) ===
score_result_dict: {'Total': 2625, 'TP': 78, 'TN': 2470, 'FP': 30, 'FN': 47, 'precision': 0.7222222222222222, 'recall': 0.624, 'accuracy': 0.9706666666666667, 'average_precision': 0.6941648464613873, 'balanced_accuracy': 0.806, 'f1': 0.6695278969957081, 'roc_auc': 0.8957952}
==getted_scoring_result==
[fit 268/850] END C=1.0, gamma=128.0, kernel=rbf; total=2625, TP=78, TN=2470, FP=30, FN=47; precision=0.722, recall=0.624
accuracy: (test=0.971) average_precision: (test=0.694) balanced_accuracy: (test=0.806) f1: (test=0.670) roc_auc: (test=0.896) 17.81s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2480, FP=20, FN=51; precision=0.787, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.973) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.676) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.888) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2480, 'FP': 20, 'FN': 51, 'precision': 0.7872340425531915, 'recall': 0.592, 'accuracy': 0.9729523809523809, 'average_precision': 0.6792835100857112, 'balanced_accuracy': 0.792, 'f1': 0.6757990867579908, 'roc_auc': 0.888144}
==getted_scoring_result==
[fit 269/850] END C=1.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2480, FP=20, FN=51; precision=0.787, recall=0.592
accuracy: (test=0.973) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.676) roc_auc: (test=0.888) 19.50s
==get_scoring_result==
base_score: total=2625, TP=72, TN=2481, FP=19, FN=53; precision=0.791, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.973) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.784) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.667) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.866) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 2481, 'FP': 19, 'FN': 53, 'precision': 0.7912087912087912, 'recall': 0.576, 'accuracy': 0.9725714285714285, 'average_precision': 0.6583016085161393, 'balanced_accuracy': 0.7842, 'f1': 0.6666666666666666, 'roc_auc': 0.8661472}
==getted_scoring_result==
[fit 270/850] END C=1.0, gamma=512.0, kernel=rbf; total=2625, TP=72, TN=2481, FP=19, FN=53; precision=0.791, recall=0.576
accuracy: (test=0.973) average_precision: (test=0.658) balanced_accuracy: (test=0.784) f1: (test=0.667) roc_auc: (test=0.866) 22.89s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.656) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.849) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6563488058036913, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8492608}
==getted_scoring_result==
[fit 271/850] END C=1.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.656) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.849) 27.01s
==get_scoring_result==
base_score: total=2625, TP=46, TN=2500, FP=0, FN=79; precision=1.000, recall=0.368

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.648) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.684) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.538) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 46, 'TN': 2500, 'FP': 0, 'FN': 79, 'precision': 1.0, 'recall': 0.368, 'accuracy': 0.9699047619047619, 'average_precision': 0.6480700080193765, 'balanced_accuracy': 0.6839999999999999, 'f1': 0.5380116959064328, 'roc_auc': 0.8348464}
==getted_scoring_result==
[fit 272/850] END C=1.0, gamma=2048.0, kernel=rbf; total=2625, TP=46, TN=2500, FP=0, FN=79; precision=1.000, recall=0.368
accuracy: (test=0.970) average_precision: (test=0.648) balanced_accuracy: (test=0.684) f1: (test=0.538) roc_auc: (test=0.835) 27.88s
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.594) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.812) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.5942292159665558, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8118176}
==getted_scoring_result==
[fit 273/850] END C=1.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.594) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.812) 23.91s
==get_scoring_result==
base_score: total=2625, TP=18, TN=2500, FP=0, FN=107; precision=1.000, recall=0.144

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.572) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.252) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.747) ===
score_result_dict: {'Total': 2625, 'TP': 18, 'TN': 2500, 'FP': 0, 'FN': 107, 'precision': 1.0, 'recall': 0.144, 'accuracy': 0.9592380952380952, 'average_precision': 0.50596196900501, 'balanced_accuracy': 0.572, 'f1': 0.2517482517482518, 'roc_auc': 0.7469344}
==getted_scoring_result==
[fit 274/850] END C=1.0, gamma=8192.0, kernel=rbf; total=2625, TP=18, TN=2500, FP=0, FN=107; precision=1.000, recall=0.144
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.572) f1: (test=0.252) roc_auc: (test=0.747) 21.23s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.678) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.36863530472335904, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6775552}
==getted_scoring_result==
[fit 275/850] END C=1.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.678) 19.79s
==get_scoring_result==
base_score: total=2625, TP=87, TN=861, FP=1639, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.361) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 861, 'FP': 1639, 'FN': 38, 'precision': 0.05040556199304751, 'recall': 0.696, 'accuracy': 0.36114285714285715, 'average_precision': 0.04624048225333584, 'balanced_accuracy': 0.5202, 'f1': 0.0940032414910859, 'roc_auc': 0.5067248}
==getted_scoring_result==
[fit 276/850] END C=2.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=87, TN=861, FP=1639, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.361) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.12s
==get_scoring_result==
base_score: total=2625, TP=77, TN=1015, FP=1485, FN=48; precision=0.049, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.416) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.511) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 1015, 'FP': 1485, 'FN': 48, 'precision': 0.04929577464788732, 'recall': 0.616, 'accuracy': 0.416, 'average_precision': 0.04639510498131729, 'balanced_accuracy': 0.511, 'f1': 0.0912863070539419, 'roc_auc': 0.5088256}
==getted_scoring_result==
[fit 277/850] END C=2.0, gamma=0.001953125, kernel=rbf; total=2625, TP=77, TN=1015, FP=1485, FN=48; precision=0.049, recall=0.616
accuracy: (test=0.416) average_precision: (test=0.046) balanced_accuracy: (test=0.511) f1: (test=0.091) roc_auc: (test=0.509) 9.72s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1226, FP=1274, FN=58; precision=0.050, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.493) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.513) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.515) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1226, 'FP': 1274, 'FN': 58, 'precision': 0.049962714392244596, 'recall': 0.536, 'accuracy': 0.49257142857142855, 'average_precision': 0.04700559241106217, 'balanced_accuracy': 0.5132, 'f1': 0.09140518417462483, 'roc_auc': 0.514608}
==getted_scoring_result==
[fit 278/850] END C=2.0, gamma=0.00390625, kernel=rbf; total=2625, TP=67, TN=1226, FP=1274, FN=58; precision=0.050, recall=0.536
accuracy: (test=0.493) average_precision: (test=0.047) balanced_accuracy: (test=0.513) f1: (test=0.091) roc_auc: (test=0.515) 9.45s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.520) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1298, 'FP': 1202, 'FN': 59, 'precision': 0.052050473186119876, 'recall': 0.528, 'accuracy': 0.5196190476190476, 'average_precision': 0.04817648108498551, 'balanced_accuracy': 0.5236000000000001, 'f1': 0.09475951184493898, 'roc_auc': 0.5230112}
==getted_scoring_result==
[fit 279/850] END C=2.0, gamma=0.0078125, kernel=rbf; total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528
accuracy: (test=0.520) average_precision: (test=0.048) balanced_accuracy: (test=0.524) f1: (test=0.095) roc_auc: (test=0.523) 9.51s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1324, FP=1176, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.530) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.533) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.538) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1324, 'FP': 1176, 'FN': 58, 'precision': 0.053901850362027354, 'recall': 0.536, 'accuracy': 0.5299047619047619, 'average_precision': 0.05018335832176825, 'balanced_accuracy': 0.5327999999999999, 'f1': 0.09795321637426901, 'roc_auc': 0.537632}
==getted_scoring_result==
[fit 280/850] END C=2.0, gamma=0.015625, kernel=rbf; total=2625, TP=67, TN=1324, FP=1176, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.530) average_precision: (test=0.050) balanced_accuracy: (test=0.533) f1: (test=0.098) roc_auc: (test=0.538) 9.26s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1350, FP=1150, FN=56; precision=0.057, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.541) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.546) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.556) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1350, 'FP': 1150, 'FN': 56, 'precision': 0.05660377358490566, 'recall': 0.552, 'accuracy': 0.5405714285714286, 'average_precision': 0.053310238560341186, 'balanced_accuracy': 0.546, 'f1': 0.10267857142857142, 'roc_auc': 0.5561312}
==getted_scoring_result==
[fit 281/850] END C=2.0, gamma=0.03125, kernel=rbf; total=2625, TP=69, TN=1350, FP=1150, FN=56; precision=0.057, recall=0.552
accuracy: (test=0.541) average_precision: (test=0.053) balanced_accuracy: (test=0.546) f1: (test=0.103) roc_auc: (test=0.556) 9.52s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=67, TN=1394, FP=1106, FN=58; precision=0.057, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.557) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.547) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.579) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1394, 'FP': 1106, 'FN': 58, 'precision': 0.05711849957374254, 'recall': 0.536, 'accuracy': 0.5565714285714286, 'average_precision': 0.057979220939371176, 'balanced_accuracy': 0.5468, 'f1': 0.10323574730354391, 'roc_auc': 0.5792416}
==getted_scoring_result==
[fit 282/850] END C=2.0, gamma=0.0625, kernel=rbf; total=2625, TP=67, TN=1394, FP=1106, FN=58; precision=0.057, recall=0.536
accuracy: (test=0.557) average_precision: (test=0.058) balanced_accuracy: (test=0.547) f1: (test=0.103) roc_auc: (test=0.579) 9.64s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=68, TN=1478, FP=1022, FN=57; precision=0.062, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.589) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.065) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.112) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.605) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1478, 'FP': 1022, 'FN': 57, 'precision': 0.062385321100917435, 'recall': 0.544, 'accuracy': 0.588952380952381, 'average_precision': 0.06546561564289795, 'balanced_accuracy': 0.5676, 'f1': 0.11193415637860084, 'roc_auc': 0.604792}
==getted_scoring_result==
[fit 283/850] END C=2.0, gamma=0.125, kernel=rbf; total=2625, TP=68, TN=1478, FP=1022, FN=57; precision=0.062, recall=0.544
accuracy: (test=0.589) average_precision: (test=0.065) balanced_accuracy: (test=0.568) f1: (test=0.112) roc_auc: (test=0.605) 9.95s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1489, FP=1011, FN=55; precision=0.065, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.594) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.578) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.116) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.629) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1489, 'FP': 1011, 'FN': 55, 'precision': 0.06475485661424607, 'recall': 0.56, 'accuracy': 0.5939047619047619, 'average_precision': 0.07534174636682305, 'balanced_accuracy': 0.5778000000000001, 'f1': 0.11608623548922058, 'roc_auc': 0.6289376}
==getted_scoring_result==
[fit 284/850] END C=2.0, gamma=0.25, kernel=rbf; total=2625, TP=70, TN=1489, FP=1011, FN=55; precision=0.065, recall=0.560
accuracy: (test=0.594) average_precision: (test=0.075) balanced_accuracy: (test=0.578) f1: (test=0.116) roc_auc: (test=0.629) 10.35s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1557, FP=943, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.621) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.599) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.126) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.650) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1557, 'FP': 943, 'FN': 53, 'precision': 0.07093596059113301, 'recall': 0.576, 'accuracy': 0.6205714285714286, 'average_precision': 0.08471993983128692, 'balanced_accuracy': 0.5993999999999999, 'f1': 0.12631578947368421, 'roc_auc': 0.6503968}
==getted_scoring_result==
[fit 285/850] END C=2.0, gamma=0.5, kernel=rbf; total=2625, TP=72, TN=1557, FP=943, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.621) average_precision: (test=0.085) balanced_accuracy: (test=0.599) f1: (test=0.126) roc_auc: (test=0.650) 10.51s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1621, FP=879, FN=52; precision=0.077, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.645) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.091) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.616) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.136) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.670) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1621, 'FP': 879, 'FN': 52, 'precision': 0.07668067226890757, 'recall': 0.584, 'accuracy': 0.6453333333333333, 'average_precision': 0.09122322301038993, 'balanced_accuracy': 0.6162, 'f1': 0.13556174558960074, 'roc_auc': 0.6702832}
==getted_scoring_result==
[fit 286/850] END C=2.0, gamma=1.0, kernel=rbf; total=2625, TP=73, TN=1621, FP=879, FN=52; precision=0.077, recall=0.584
accuracy: (test=0.645) average_precision: (test=0.091) balanced_accuracy: (test=0.616) f1: (test=0.136) roc_auc: (test=0.670) 10.64s
==get_scoring_result==
base_score: total=2625, TP=78, TN=1693, FP=807, FN=47; precision=0.088, recall=0.624

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.675) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.104) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.651) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.154) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.702) ===
score_result_dict: {'Total': 2625, 'TP': 78, 'TN': 1693, 'FP': 807, 'FN': 47, 'precision': 0.08813559322033898, 'recall': 0.624, 'accuracy': 0.6746666666666666, 'average_precision': 0.10352662540458829, 'balanced_accuracy': 0.6506000000000001, 'f1': 0.15445544554455445, 'roc_auc': 0.7020144}
==getted_scoring_result==
[fit 287/850] END C=2.0, gamma=2.0, kernel=rbf; total=2625, TP=78, TN=1693, FP=807, FN=47; precision=0.088, recall=0.624
accuracy: (test=0.675) average_precision: (test=0.104) balanced_accuracy: (test=0.651) f1: (test=0.154) roc_auc: (test=0.702) 11.08s
==get_scoring_result==
base_score: total=2625, TP=82, TN=1810, FP=690, FN=43; precision=0.106, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.721) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.141) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.690) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.183) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.753) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 1810, 'FP': 690, 'FN': 43, 'precision': 0.10621761658031088, 'recall': 0.656, 'accuracy': 0.7207619047619047, 'average_precision': 0.140599865146701, 'balanced_accuracy': 0.69, 'f1': 0.18283166109253063, 'roc_auc': 0.752712}
==getted_scoring_result==
[fit 288/850] END C=2.0, gamma=4.0, kernel=rbf; total=2625, TP=82, TN=1810, FP=690, FN=43; precision=0.106, recall=0.656
accuracy: (test=0.721) average_precision: (test=0.141) balanced_accuracy: (test=0.690) f1: (test=0.183) roc_auc: (test=0.753) 11.97s
==get_scoring_result==
base_score: total=2625, TP=88, TN=2002, FP=498, FN=37; precision=0.150, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.796) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.213) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.752) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.248) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.824) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 2002, 'FP': 498, 'FN': 37, 'precision': 0.15017064846416384, 'recall': 0.704, 'accuracy': 0.7961904761904762, 'average_precision': 0.21300081867699133, 'balanced_accuracy': 0.7524, 'f1': 0.24753867791842477, 'roc_auc': 0.8238048}
==getted_scoring_result==
[fit 289/850] END C=2.0, gamma=8.0, kernel=rbf; total=2625, TP=88, TN=2002, FP=498, FN=37; precision=0.150, recall=0.704
accuracy: (test=0.796) average_precision: (test=0.213) balanced_accuracy: (test=0.752) f1: (test=0.248) roc_auc: (test=0.824) 12.77s
==get_scoring_result==
base_score: total=2625, TP=91, TN=2221, FP=279, FN=34; precision=0.246, recall=0.728

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.881) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.392) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.808) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.368) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.887) ===
score_result_dict: {'Total': 2625, 'TP': 91, 'TN': 2221, 'FP': 279, 'FN': 34, 'precision': 0.24594594594594596, 'recall': 0.728, 'accuracy': 0.8807619047619047, 'average_precision': 0.39184929089664056, 'balanced_accuracy': 0.8082, 'f1': 0.3676767676767677, 'roc_auc': 0.88728}
==getted_scoring_result==
[fit 290/850] END C=2.0, gamma=16.0, kernel=rbf; total=2625, TP=91, TN=2221, FP=279, FN=34; precision=0.246, recall=0.728
accuracy: (test=0.881) average_precision: (test=0.392) balanced_accuracy: (test=0.808) f1: (test=0.368) roc_auc: (test=0.887) 15.18s
==get_scoring_result==
base_score: total=2625, TP=84, TN=2391, FP=109, FN=41; precision=0.435, recall=0.672

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.943) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.633) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.814) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.528) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.908) ===
score_result_dict: {'Total': 2625, 'TP': 84, 'TN': 2391, 'FP': 109, 'FN': 41, 'precision': 0.43523316062176165, 'recall': 0.672, 'accuracy': 0.9428571428571428, 'average_precision': 0.6330755675309522, 'balanced_accuracy': 0.8142, 'f1': 0.5283018867924528, 'roc_auc': 0.907808}
==getted_scoring_result==
[fit 291/850] END C=2.0, gamma=32.0, kernel=rbf; total=2625, TP=84, TN=2391, FP=109, FN=41; precision=0.435, recall=0.672
accuracy: (test=0.943) average_precision: (test=0.633) balanced_accuracy: (test=0.814) f1: (test=0.528) roc_auc: (test=0.908) 18.69s
==get_scoring_result==
base_score: total=2625, TP=77, TN=2467, FP=33, FN=48; precision=0.700, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.969) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.694) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.801) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.655) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.905) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 2467, 'FP': 33, 'FN': 48, 'precision': 0.7, 'recall': 0.616, 'accuracy': 0.9691428571428572, 'average_precision': 0.6940886422174114, 'balanced_accuracy': 0.8014, 'f1': 0.6553191489361703, 'roc_auc': 0.9045536}
==getted_scoring_result==
[fit 292/850] END C=2.0, gamma=64.0, kernel=rbf; total=2625, TP=77, TN=2467, FP=33, FN=48; precision=0.700, recall=0.616
accuracy: (test=0.969) average_precision: (test=0.694) balanced_accuracy: (test=0.801) f1: (test=0.655) roc_auc: (test=0.905) 20.49s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2477, FP=23, FN=49; precision=0.768, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.973) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.700) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.679) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2477, 'FP': 23, 'FN': 49, 'precision': 0.7676767676767676, 'recall': 0.608, 'accuracy': 0.9725714285714285, 'average_precision': 0.699878418974659, 'balanced_accuracy': 0.7994, 'f1': 0.6785714285714285, 'roc_auc': 0.895392}
==getted_scoring_result==
[fit 293/850] END C=2.0, gamma=128.0, kernel=rbf; total=2625, TP=76, TN=2477, FP=23, FN=49; precision=0.768, recall=0.608
accuracy: (test=0.973) average_precision: (test=0.700) balanced_accuracy: (test=0.799) f1: (test=0.679) roc_auc: (test=0.895) 19.81s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6787734619554221, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.8885472}
==getted_scoring_result==
[fit 294/850] END C=2.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 20.79s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6582813774138194, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666336}
==getted_scoring_result==
[fit 295/850] END C=2.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 24.07s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550569466807216, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8471808}
==getted_scoring_result==
[fit 296/850] END C=2.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 27.90s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.648) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6479635492444087, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347472}
==getted_scoring_result==
[fit 297/850] END C=2.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.648) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 27.39s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 298/850] END C=2.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 23.51s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 299/850] END C=2.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 21.18s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 300/850] END C=2.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 17.91s
==get_scoring_result==
base_score: total=2625, TP=77, TN=1016, FP=1484, FN=48; precision=0.049, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.416) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.511) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 1016, 'FP': 1484, 'FN': 48, 'precision': 0.04932735426008968, 'recall': 0.616, 'accuracy': 0.4163809523809524, 'average_precision': 0.046395919257959044, 'balanced_accuracy': 0.5112, 'f1': 0.09134045077105574, 'roc_auc': 0.508832}
==getted_scoring_result==
[fit 301/850] END C=4.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=77, TN=1016, FP=1484, FN=48; precision=0.049, recall=0.616
accuracy: (test=0.416) average_precision: (test=0.046) balanced_accuracy: (test=0.511) f1: (test=0.091) roc_auc: (test=0.509) 10.89s
==get_scoring_result==
base_score: total=2625, TP=65, TN=1286, FP=1214, FN=60; precision=0.051, recall=0.520

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.515) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.517) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.514) ===
score_result_dict: {'Total': 2625, 'TP': 65, 'TN': 1286, 'FP': 1214, 'FN': 60, 'precision': 0.0508209538702111, 'recall': 0.52, 'accuracy': 0.5146666666666667, 'average_precision': 0.04700515685832085, 'balanced_accuracy': 0.5172, 'f1': 0.09259259259259259, 'roc_auc': 0.5143456}
==getted_scoring_result==
[fit 302/850] END C=4.0, gamma=0.001953125, kernel=rbf; total=2625, TP=65, TN=1286, FP=1214, FN=60; precision=0.051, recall=0.520
accuracy: (test=0.515) average_precision: (test=0.047) balanced_accuracy: (test=0.517) f1: (test=0.093) roc_auc: (test=0.514) 10.91s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.520) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1298, 'FP': 1202, 'FN': 59, 'precision': 0.052050473186119876, 'recall': 0.528, 'accuracy': 0.5196190476190476, 'average_precision': 0.048180999464048885, 'balanced_accuracy': 0.5236000000000001, 'f1': 0.09475951184493898, 'roc_auc': 0.5230512}
==getted_scoring_result==
[fit 303/850] END C=4.0, gamma=0.00390625, kernel=rbf; total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528
accuracy: (test=0.520) average_precision: (test=0.048) balanced_accuracy: (test=0.524) f1: (test=0.095) roc_auc: (test=0.523) 11.28s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1325, FP=1175, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.530) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.533) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.538) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1325, 'FP': 1175, 'FN': 58, 'precision': 0.05394524959742351, 'recall': 0.536, 'accuracy': 0.5302857142857142, 'average_precision': 0.05017723365332881, 'balanced_accuracy': 0.533, 'f1': 0.09802487198244329, 'roc_auc': 0.537688}
==getted_scoring_result==
[fit 304/850] END C=4.0, gamma=0.0078125, kernel=rbf; total=2625, TP=67, TN=1325, FP=1175, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.530) average_precision: (test=0.050) balanced_accuracy: (test=0.533) f1: (test=0.098) roc_auc: (test=0.538) 10.99s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1351, FP=1149, FN=55; precision=0.057, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.541) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.550) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.104) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.556) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1351, 'FP': 1149, 'FN': 55, 'precision': 0.05742411812961444, 'recall': 0.56, 'accuracy': 0.5413333333333333, 'average_precision': 0.0533736124432286, 'balanced_accuracy': 0.5502, 'f1': 0.10416666666666666, 'roc_auc': 0.556408}
==getted_scoring_result==
[fit 305/850] END C=4.0, gamma=0.015625, kernel=rbf; total=2625, TP=70, TN=1351, FP=1149, FN=55; precision=0.057, recall=0.560
accuracy: (test=0.541) average_precision: (test=0.053) balanced_accuracy: (test=0.550) f1: (test=0.104) roc_auc: (test=0.556) 10.88s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1397, FP=1103, FN=58; precision=0.057, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.558) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.547) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.580) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1397, 'FP': 1103, 'FN': 58, 'precision': 0.05726495726495726, 'recall': 0.536, 'accuracy': 0.5577142857142857, 'average_precision': 0.05807013658022807, 'balanced_accuracy': 0.5474, 'f1': 0.10347490347490346, 'roc_auc': 0.5795552}
==getted_scoring_result==
[fit 306/850] END C=4.0, gamma=0.03125, kernel=rbf; total=2625, TP=67, TN=1397, FP=1103, FN=58; precision=0.057, recall=0.536
accuracy: (test=0.558) average_precision: (test=0.058) balanced_accuracy: (test=0.547) f1: (test=0.103) roc_auc: (test=0.580) 11.12s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=68, TN=1479, FP=1021, FN=57; precision=0.062, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.589) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.065) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.112) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.604) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1479, 'FP': 1021, 'FN': 57, 'precision': 0.06244260789715335, 'recall': 0.544, 'accuracy': 0.5893333333333334, 'average_precision': 0.06528691007076147, 'balanced_accuracy': 0.5678000000000001, 'f1': 0.11202635914332783, 'roc_auc': 0.6044832}
==getted_scoring_result==
[fit 307/850] END C=4.0, gamma=0.0625, kernel=rbf; total=2625, TP=68, TN=1479, FP=1021, FN=57; precision=0.062, recall=0.544
accuracy: (test=0.589) average_precision: (test=0.065) balanced_accuracy: (test=0.568) f1: (test=0.112) roc_auc: (test=0.604) 9.76s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1496, FP=1004, FN=56; precision=0.064, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.596) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.575) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.115) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.628) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1496, 'FP': 1004, 'FN': 56, 'precision': 0.06430568499534017, 'recall': 0.552, 'accuracy': 0.5961904761904762, 'average_precision': 0.07487652759549256, 'balanced_accuracy': 0.5752, 'f1': 0.11519198664440734, 'roc_auc': 0.628192}
==getted_scoring_result==
[fit 308/850] END C=4.0, gamma=0.125, kernel=rbf; total=2625, TP=69, TN=1496, FP=1004, FN=56; precision=0.064, recall=0.552
accuracy: (test=0.596) average_precision: (test=0.075) balanced_accuracy: (test=0.575) f1: (test=0.115) roc_auc: (test=0.628) 10.14s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1553, FP=947, FN=54; precision=0.070, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.619) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.595) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.124) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.649) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1553, 'FP': 947, 'FN': 54, 'precision': 0.06974459724950884, 'recall': 0.568, 'accuracy': 0.6186666666666667, 'average_precision': 0.08381993970978618, 'balanced_accuracy': 0.5946, 'f1': 0.12423447069116358, 'roc_auc': 0.6485888}
==getted_scoring_result==
[fit 309/850] END C=4.0, gamma=0.25, kernel=rbf; total=2625, TP=71, TN=1553, FP=947, FN=54; precision=0.070, recall=0.568
accuracy: (test=0.619) average_precision: (test=0.084) balanced_accuracy: (test=0.595) f1: (test=0.124) roc_auc: (test=0.649) 9.97s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1603, FP=897, FN=54; precision=0.073, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.638) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.089) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.605) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.664) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1603, 'FP': 897, 'FN': 54, 'precision': 0.07334710743801653, 'recall': 0.568, 'accuracy': 0.6377142857142857, 'average_precision': 0.08887932919740608, 'balanced_accuracy': 0.6046, 'f1': 0.12991765782250686, 'roc_auc': 0.6640848}
==getted_scoring_result==
[fit 310/850] END C=4.0, gamma=0.5, kernel=rbf; total=2625, TP=71, TN=1603, FP=897, FN=54; precision=0.073, recall=0.568
accuracy: (test=0.638) average_precision: (test=0.089) balanced_accuracy: (test=0.605) f1: (test=0.130) roc_auc: (test=0.664) 10.24s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1648, FP=852, FN=51; precision=0.080, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.656) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.095) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.626) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.141) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.686) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1648, 'FP': 852, 'FN': 51, 'precision': 0.07991360691144708, 'recall': 0.592, 'accuracy': 0.656, 'average_precision': 0.0952760821920755, 'balanced_accuracy': 0.6255999999999999, 'f1': 0.14081826831588962, 'roc_auc': 0.686368}
==getted_scoring_result==
[fit 311/850] END C=4.0, gamma=1.0, kernel=rbf; total=2625, TP=74, TN=1648, FP=852, FN=51; precision=0.080, recall=0.592
accuracy: (test=0.656) average_precision: (test=0.095) balanced_accuracy: (test=0.626) f1: (test=0.141) roc_auc: (test=0.686) 11.17s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=81, TN=1741, FP=759, FN=44; precision=0.096, recall=0.648

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.694) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.116) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.672) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.168) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.725) ===
score_result_dict: {'Total': 2625, 'TP': 81, 'TN': 1741, 'FP': 759, 'FN': 44, 'precision': 0.09642857142857143, 'recall': 0.648, 'accuracy': 0.6940952380952381, 'average_precision': 0.11616802602195406, 'balanced_accuracy': 0.6722, 'f1': 0.1678756476683938, 'roc_auc': 0.7252688}
==getted_scoring_result==
[fit 312/850] END C=4.0, gamma=2.0, kernel=rbf; total=2625, TP=81, TN=1741, FP=759, FN=44; precision=0.096, recall=0.648
accuracy: (test=0.694) average_precision: (test=0.116) balanced_accuracy: (test=0.672) f1: (test=0.168) roc_auc: (test=0.725) 11.88s
==get_scoring_result==
base_score: total=2625, TP=82, TN=1897, FP=603, FN=43; precision=0.120, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.754) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.167) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.707) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.202) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.782) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 1897, 'FP': 603, 'FN': 43, 'precision': 0.11970802919708029, 'recall': 0.656, 'accuracy': 0.7539047619047619, 'average_precision': 0.16685760417051362, 'balanced_accuracy': 0.7074, 'f1': 0.2024691358024691, 'roc_auc': 0.7823856}
==getted_scoring_result==
[fit 313/850] END C=4.0, gamma=4.0, kernel=rbf; total=2625, TP=82, TN=1897, FP=603, FN=43; precision=0.120, recall=0.656
accuracy: (test=0.754) average_precision: (test=0.167) balanced_accuracy: (test=0.707) f1: (test=0.202) roc_auc: (test=0.782) 14.01s
==get_scoring_result==
base_score: total=2625, TP=89, TN=2094, FP=406, FN=36; precision=0.180, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.832) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.275) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.775) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.287) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.855) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 2094, 'FP': 406, 'FN': 36, 'precision': 0.1797979797979798, 'recall': 0.712, 'accuracy': 0.8316190476190476, 'average_precision': 0.27516084145852765, 'balanced_accuracy': 0.7747999999999999, 'f1': 0.2870967741935484, 'roc_auc': 0.8549952}
==getted_scoring_result==
[fit 314/850] END C=4.0, gamma=8.0, kernel=rbf; total=2625, TP=89, TN=2094, FP=406, FN=36; precision=0.180, recall=0.712
accuracy: (test=0.832) average_precision: (test=0.275) balanced_accuracy: (test=0.775) f1: (test=0.287) roc_auc: (test=0.855) 15.78s
==get_scoring_result==
base_score: total=2625, TP=91, TN=2306, FP=194, FN=34; precision=0.319, recall=0.728

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.913) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.495) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.825) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.444) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.902) ===
score_result_dict: {'Total': 2625, 'TP': 91, 'TN': 2306, 'FP': 194, 'FN': 34, 'precision': 0.3192982456140351, 'recall': 0.728, 'accuracy': 0.9131428571428571, 'average_precision': 0.49495949056428945, 'balanced_accuracy': 0.8251999999999999, 'f1': 0.4439024390243903, 'roc_auc': 0.9024864}
==getted_scoring_result==
[fit 315/850] END C=4.0, gamma=16.0, kernel=rbf; total=2625, TP=91, TN=2306, FP=194, FN=34; precision=0.319, recall=0.728
accuracy: (test=0.913) average_precision: (test=0.495) balanced_accuracy: (test=0.825) f1: (test=0.444) roc_auc: (test=0.902) 20.62s
==get_scoring_result==
base_score: total=2625, TP=79, TN=2435, FP=65, FN=46; precision=0.549, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.958) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.665) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.803) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.587) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.910) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2435, 'FP': 65, 'FN': 46, 'precision': 0.5486111111111112, 'recall': 0.632, 'accuracy': 0.9577142857142857, 'average_precision': 0.6653892404497735, 'balanced_accuracy': 0.8029999999999999, 'f1': 0.587360594795539, 'roc_auc': 0.9099264}
==getted_scoring_result==
[fit 316/850] END C=4.0, gamma=32.0, kernel=rbf; total=2625, TP=79, TN=2435, FP=65, FN=46; precision=0.549, recall=0.632
accuracy: (test=0.958) average_precision: (test=0.665) balanced_accuracy: (test=0.803) f1: (test=0.587) roc_auc: (test=0.910) 25.46s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2475, FP=25, FN=49; precision=0.752, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.703) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.901) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2475, 'FP': 25, 'FN': 49, 'precision': 0.7524752475247525, 'recall': 0.608, 'accuracy': 0.9718095238095238, 'average_precision': 0.7031786510830066, 'balanced_accuracy': 0.7989999999999999, 'f1': 0.672566371681416, 'roc_auc': 0.901216}
==getted_scoring_result==
[fit 317/850] END C=4.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2475, FP=25, FN=49; precision=0.752, recall=0.608
accuracy: (test=0.972) average_precision: (test=0.703) balanced_accuracy: (test=0.799) f1: (test=0.673) roc_auc: (test=0.901) 24.88s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2477, FP=23, FN=49; precision=0.768, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.973) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.700) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.679) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2477, 'FP': 23, 'FN': 49, 'precision': 0.7676767676767676, 'recall': 0.608, 'accuracy': 0.9725714285714285, 'average_precision': 0.6998927596116956, 'balanced_accuracy': 0.7994, 'f1': 0.6785714285714285, 'roc_auc': 0.8946464}
==getted_scoring_result==
[fit 318/850] END C=4.0, gamma=128.0, kernel=rbf; total=2625, TP=76, TN=2477, FP=23, FN=49; precision=0.768, recall=0.608
accuracy: (test=0.973) average_precision: (test=0.700) balanced_accuracy: (test=0.799) f1: (test=0.679) roc_auc: (test=0.895) 19.40s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786734678632911, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888688}
==getted_scoring_result==
[fit 319/850] END C=4.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 19.44s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6582828405370649, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666688}
==getted_scoring_result==
[fit 320/850] END C=4.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 22.37s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550447862904911, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.847248}
==getted_scoring_result==
[fit 321/850] END C=4.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 26.90s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 322/850] END C=4.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 26.55s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 323/850] END C=4.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 23.09s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 324/850] END C=4.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 21.09s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 325/850] END C=4.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 17.55s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1226, FP=1274, FN=58; precision=0.050, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.493) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.513) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.515) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1226, 'FP': 1274, 'FN': 58, 'precision': 0.049962714392244596, 'recall': 0.536, 'accuracy': 0.49257142857142855, 'average_precision': 0.047006460953113435, 'balanced_accuracy': 0.5132, 'f1': 0.09140518417462483, 'roc_auc': 0.5145728}
==getted_scoring_result==
[fit 326/850] END C=8.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=67, TN=1226, FP=1274, FN=58; precision=0.050, recall=0.536
accuracy: (test=0.493) average_precision: (test=0.047) balanced_accuracy: (test=0.513) f1: (test=0.091) roc_auc: (test=0.515) 9.20s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.520) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1298, 'FP': 1202, 'FN': 59, 'precision': 0.052050473186119876, 'recall': 0.528, 'accuracy': 0.5196190476190476, 'average_precision': 0.04817791916608598, 'balanced_accuracy': 0.5236000000000001, 'f1': 0.09475951184493898, 'roc_auc': 0.5230384}
==getted_scoring_result==
[fit 327/850] END C=8.0, gamma=0.001953125, kernel=rbf; total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528
accuracy: (test=0.520) average_precision: (test=0.048) balanced_accuracy: (test=0.524) f1: (test=0.095) roc_auc: (test=0.523) 9.50s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1325, FP=1175, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.530) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.533) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.538) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1325, 'FP': 1175, 'FN': 58, 'precision': 0.05394524959742351, 'recall': 0.536, 'accuracy': 0.5302857142857142, 'average_precision': 0.050194117770701714, 'balanced_accuracy': 0.533, 'f1': 0.09802487198244329, 'roc_auc': 0.5377296}
==getted_scoring_result==
[fit 328/850] END C=8.0, gamma=0.00390625, kernel=rbf; total=2625, TP=67, TN=1325, FP=1175, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.530) average_precision: (test=0.050) balanced_accuracy: (test=0.533) f1: (test=0.098) roc_auc: (test=0.538) 9.34s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1353, FP=1147, FN=57; precision=0.056, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.541) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.543) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.101) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.556) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1353, 'FP': 1147, 'FN': 57, 'precision': 0.05596707818930041, 'recall': 0.544, 'accuracy': 0.5413333333333333, 'average_precision': 0.05328239317872826, 'balanced_accuracy': 0.5426, 'f1': 0.10149253731343283, 'roc_auc': 0.5561504}
==getted_scoring_result==
[fit 329/850] END C=8.0, gamma=0.0078125, kernel=rbf; total=2625, TP=68, TN=1353, FP=1147, FN=57; precision=0.056, recall=0.544
accuracy: (test=0.541) average_precision: (test=0.053) balanced_accuracy: (test=0.543) f1: (test=0.101) roc_auc: (test=0.556) 8.84s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1397, FP=1103, FN=57; precision=0.058, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.558) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.551) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.105) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.580) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1397, 'FP': 1103, 'FN': 57, 'precision': 0.05807002561912895, 'recall': 0.544, 'accuracy': 0.5580952380952381, 'average_precision': 0.05817284312358731, 'balanced_accuracy': 0.5514, 'f1': 0.10493827160493825, 'roc_auc': 0.5798688}
==getted_scoring_result==
[fit 330/850] END C=8.0, gamma=0.015625, kernel=rbf; total=2625, TP=68, TN=1397, FP=1103, FN=57; precision=0.058, recall=0.544
accuracy: (test=0.558) average_precision: (test=0.058) balanced_accuracy: (test=0.551) f1: (test=0.105) roc_auc: (test=0.580) 8.39s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=68, TN=1477, FP=1023, FN=57; precision=0.062, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.589) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.065) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.567) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.112) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.605) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1477, 'FP': 1023, 'FN': 57, 'precision': 0.06232813932172319, 'recall': 0.544, 'accuracy': 0.5885714285714285, 'average_precision': 0.06535252509354039, 'balanced_accuracy': 0.5674, 'f1': 0.11184210526315788, 'roc_auc': 0.6045728}
==getted_scoring_result==
[fit 331/850] END C=8.0, gamma=0.03125, kernel=rbf; total=2625, TP=68, TN=1477, FP=1023, FN=57; precision=0.062, recall=0.544
accuracy: (test=0.589) average_precision: (test=0.065) balanced_accuracy: (test=0.567) f1: (test=0.112) roc_auc: (test=0.605) 8.83s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1498, FP=1002, FN=56; precision=0.064, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.597) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.576) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.115) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.628) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1498, 'FP': 1002, 'FN': 56, 'precision': 0.06442577030812324, 'recall': 0.552, 'accuracy': 0.5969523809523809, 'average_precision': 0.07484957707168943, 'balanced_accuracy': 0.5756, 'f1': 0.11538461538461538, 'roc_auc': 0.6277952}
==getted_scoring_result==
[fit 332/850] END C=8.0, gamma=0.0625, kernel=rbf; total=2625, TP=69, TN=1498, FP=1002, FN=56; precision=0.064, recall=0.552
accuracy: (test=0.597) average_precision: (test=0.075) balanced_accuracy: (test=0.576) f1: (test=0.115) roc_auc: (test=0.628) 9.79s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1555, FP=945, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.620) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.599) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.126) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.648) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1555, 'FP': 945, 'FN': 53, 'precision': 0.07079646017699115, 'recall': 0.576, 'accuracy': 0.6198095238095238, 'average_precision': 0.08380218800116186, 'balanced_accuracy': 0.599, 'f1': 0.12609457092819615, 'roc_auc': 0.647568}
==getted_scoring_result==
[fit 333/850] END C=8.0, gamma=0.125, kernel=rbf; total=2625, TP=72, TN=1555, FP=945, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.620) average_precision: (test=0.084) balanced_accuracy: (test=0.599) f1: (test=0.126) roc_auc: (test=0.648) 10.30s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1595, FP=905, FN=53; precision=0.074, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.635) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.088) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.607) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.660) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1595, 'FP': 905, 'FN': 53, 'precision': 0.0736949846468782, 'recall': 0.576, 'accuracy': 0.6350476190476191, 'average_precision': 0.08782094927931176, 'balanced_accuracy': 0.607, 'f1': 0.1306715063520871, 'roc_auc': 0.6598624}
==getted_scoring_result==
[fit 334/850] END C=8.0, gamma=0.25, kernel=rbf; total=2625, TP=72, TN=1595, FP=905, FN=53; precision=0.074, recall=0.576
accuracy: (test=0.635) average_precision: (test=0.088) balanced_accuracy: (test=0.607) f1: (test=0.131) roc_auc: (test=0.660) 10.59s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1623, FP=877, FN=53; precision=0.076, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.646) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.091) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.613) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.134) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.676) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1623, 'FP': 877, 'FN': 53, 'precision': 0.07586933614330875, 'recall': 0.576, 'accuracy': 0.6457142857142857, 'average_precision': 0.0911484776959435, 'balanced_accuracy': 0.6126, 'f1': 0.13407821229050282, 'roc_auc': 0.6758032}
==getted_scoring_result==
[fit 335/850] END C=8.0, gamma=0.5, kernel=rbf; total=2625, TP=72, TN=1623, FP=877, FN=53; precision=0.076, recall=0.576
accuracy: (test=0.646) average_precision: (test=0.091) balanced_accuracy: (test=0.613) f1: (test=0.134) roc_auc: (test=0.676) 10.55s
==get_scoring_result==
base_score: total=2625, TP=77, TN=1684, FP=816, FN=48; precision=0.086, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.671) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.102) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.645) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.151) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.704) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 1684, 'FP': 816, 'FN': 48, 'precision': 0.08622620380739082, 'recall': 0.616, 'accuracy': 0.6708571428571428, 'average_precision': 0.10221689496569838, 'balanced_accuracy': 0.6448, 'f1': 0.1512770137524558, 'roc_auc': 0.7038496}
==getted_scoring_result==
[fit 336/850] END C=8.0, gamma=1.0, kernel=rbf; total=2625, TP=77, TN=1684, FP=816, FN=48; precision=0.086, recall=0.616
accuracy: (test=0.671) average_precision: (test=0.102) balanced_accuracy: (test=0.645) f1: (test=0.151) roc_auc: (test=0.704) 11.27s
==get_scoring_result==
base_score: total=2625, TP=83, TN=1808, FP=692, FN=42; precision=0.107, recall=0.664

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.720) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.138) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.694) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.184) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.752) ===
score_result_dict: {'Total': 2625, 'TP': 83, 'TN': 1808, 'FP': 692, 'FN': 42, 'precision': 0.10709677419354839, 'recall': 0.664, 'accuracy': 0.7203809523809523, 'average_precision': 0.1375925030888069, 'balanced_accuracy': 0.6936, 'f1': 0.18444444444444447, 'roc_auc': 0.7524384}
==getted_scoring_result==
[fit 337/850] END C=8.0, gamma=2.0, kernel=rbf; total=2625, TP=83, TN=1808, FP=692, FN=42; precision=0.107, recall=0.664
accuracy: (test=0.720) average_precision: (test=0.138) balanced_accuracy: (test=0.694) f1: (test=0.184) roc_auc: (test=0.752) 12.14s
==get_scoring_result==
base_score: total=2625, TP=89, TN=1977, FP=523, FN=36; precision=0.145, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.787) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.200) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.751) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.242) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.820) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 1977, 'FP': 523, 'FN': 36, 'precision': 0.1454248366013072, 'recall': 0.712, 'accuracy': 0.787047619047619, 'average_precision': 0.20032265886992648, 'balanced_accuracy': 0.7514, 'f1': 0.24151967435549526, 'roc_auc': 0.8197664}
==getted_scoring_result==
[fit 338/850] END C=8.0, gamma=4.0, kernel=rbf; total=2625, TP=89, TN=1977, FP=523, FN=36; precision=0.145, recall=0.712
accuracy: (test=0.787) average_precision: (test=0.200) balanced_accuracy: (test=0.751) f1: (test=0.242) roc_auc: (test=0.820) 13.77s
==get_scoring_result==
base_score: total=2625, TP=93, TN=2180, FP=320, FN=32; precision=0.225, recall=0.744

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.866) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.352) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.808) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.346) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.881) ===
score_result_dict: {'Total': 2625, 'TP': 93, 'TN': 2180, 'FP': 320, 'FN': 32, 'precision': 0.22518159806295399, 'recall': 0.744, 'accuracy': 0.865904761904762, 'average_precision': 0.351604092669227, 'balanced_accuracy': 0.808, 'f1': 0.34572490706319703, 'roc_auc': 0.8811776}
==getted_scoring_result==
[fit 339/850] END C=8.0, gamma=8.0, kernel=rbf; total=2625, TP=93, TN=2180, FP=320, FN=32; precision=0.225, recall=0.744
accuracy: (test=0.866) average_precision: (test=0.352) balanced_accuracy: (test=0.808) f1: (test=0.346) roc_auc: (test=0.881) 20.15s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=87, TN=2369, FP=131, FN=38; precision=0.399, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.936) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.597) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.822) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.507) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.911) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 2369, 'FP': 131, 'FN': 38, 'precision': 0.39908256880733944, 'recall': 0.696, 'accuracy': 0.9356190476190476, 'average_precision': 0.5967893104826221, 'balanced_accuracy': 0.8218, 'f1': 0.5072886297376094, 'roc_auc': 0.9105376}
==getted_scoring_result==
[fit 340/850] END C=8.0, gamma=16.0, kernel=rbf; total=2625, TP=87, TN=2369, FP=131, FN=38; precision=0.399, recall=0.696
accuracy: (test=0.936) average_precision: (test=0.597) balanced_accuracy: (test=0.822) f1: (test=0.507) roc_auc: (test=0.911) 29.71s
==get_scoring_result==
base_score: total=2625, TP=77, TN=2457, FP=43, FN=48; precision=0.642, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.965) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.687) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.629) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.913) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 2457, 'FP': 43, 'FN': 48, 'precision': 0.6416666666666667, 'recall': 0.616, 'accuracy': 0.9653333333333334, 'average_precision': 0.6870758977681697, 'balanced_accuracy': 0.7994, 'f1': 0.6285714285714287, 'roc_auc': 0.9127072}
==getted_scoring_result==
[fit 341/850] END C=8.0, gamma=32.0, kernel=rbf; total=2625, TP=77, TN=2457, FP=43, FN=48; precision=0.642, recall=0.616
accuracy: (test=0.965) average_precision: (test=0.687) balanced_accuracy: (test=0.799) f1: (test=0.629) roc_auc: (test=0.913) 35.07s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2475, FP=25, FN=49; precision=0.752, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.703) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2475, 'FP': 25, 'FN': 49, 'precision': 0.7524752475247525, 'recall': 0.608, 'accuracy': 0.9718095238095238, 'average_precision': 0.7034603286400057, 'balanced_accuracy': 0.7989999999999999, 'f1': 0.672566371681416, 'roc_auc': 0.8990336}
==getted_scoring_result==
[fit 342/850] END C=8.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2475, FP=25, FN=49; precision=0.752, recall=0.608
accuracy: (test=0.972) average_precision: (test=0.703) balanced_accuracy: (test=0.799) f1: (test=0.673) roc_auc: (test=0.899) 27.01s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2478, FP=22, FN=50; precision=0.773, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.973) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.796) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.676) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2478, 'FP': 22, 'FN': 50, 'precision': 0.7731958762886598, 'recall': 0.6, 'accuracy': 0.9725714285714285, 'average_precision': 0.6971296552235983, 'balanced_accuracy': 0.7956, 'f1': 0.6756756756756757, 'roc_auc': 0.8948416}
==getted_scoring_result==
[fit 343/850] END C=8.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2478, FP=22, FN=50; precision=0.773, recall=0.600
accuracy: (test=0.973) average_precision: (test=0.697) balanced_accuracy: (test=0.796) f1: (test=0.676) roc_auc: (test=0.895) 19.21s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6788195631625037, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 344/850] END C=8.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 19.49s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6582658712522441, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.866592}
==getted_scoring_result==
[fit 345/850] END C=8.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 22.72s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 346/850] END C=8.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 26.17s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 347/850] END C=8.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 25.90s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 348/850] END C=8.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 22.06s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 349/850] END C=8.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 19.73s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 350/850] END C=8.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 15.94s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.520) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1298, 'FP': 1202, 'FN': 59, 'precision': 0.052050473186119876, 'recall': 0.528, 'accuracy': 0.5196190476190476, 'average_precision': 0.048177906460393105, 'balanced_accuracy': 0.5236000000000001, 'f1': 0.09475951184493898, 'roc_auc': 0.5230416}
==getted_scoring_result==
[fit 351/850] END C=16.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528
accuracy: (test=0.520) average_precision: (test=0.048) balanced_accuracy: (test=0.524) f1: (test=0.095) roc_auc: (test=0.523) 8.20s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1326, FP=1174, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.531) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.533) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.538) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1326, 'FP': 1174, 'FN': 58, 'precision': 0.053988718775181306, 'recall': 0.536, 'accuracy': 0.5306666666666666, 'average_precision': 0.0501938931257178, 'balanced_accuracy': 0.5332, 'f1': 0.09809663250366032, 'roc_auc': 0.5377248}
==getted_scoring_result==
[fit 352/850] END C=16.0, gamma=0.001953125, kernel=rbf; total=2625, TP=67, TN=1326, FP=1174, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.531) average_precision: (test=0.050) balanced_accuracy: (test=0.533) f1: (test=0.098) roc_auc: (test=0.538) 8.18s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1353, FP=1147, FN=56; precision=0.057, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.542) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.547) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.556) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1353, 'FP': 1147, 'FN': 56, 'precision': 0.05674342105263158, 'recall': 0.552, 'accuracy': 0.5417142857142857, 'average_precision': 0.05332337733081331, 'balanced_accuracy': 0.5466, 'f1': 0.10290827740492169, 'roc_auc': 0.5563584}
==getted_scoring_result==
[fit 353/850] END C=16.0, gamma=0.00390625, kernel=rbf; total=2625, TP=69, TN=1353, FP=1147, FN=56; precision=0.057, recall=0.552
accuracy: (test=0.542) average_precision: (test=0.053) balanced_accuracy: (test=0.547) f1: (test=0.103) roc_auc: (test=0.556) 8.20s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=67, TN=1398, FP=1102, FN=58; precision=0.057, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.558) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.548) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.104) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.580) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1398, 'FP': 1102, 'FN': 58, 'precision': 0.05731394354148845, 'recall': 0.536, 'accuracy': 0.5580952380952381, 'average_precision': 0.05817679247943723, 'balanced_accuracy': 0.5476000000000001, 'f1': 0.1035548686244204, 'roc_auc': 0.5795936}
==getted_scoring_result==
[fit 354/850] END C=16.0, gamma=0.0078125, kernel=rbf; total=2625, TP=67, TN=1398, FP=1102, FN=58; precision=0.057, recall=0.536
accuracy: (test=0.558) average_precision: (test=0.058) balanced_accuracy: (test=0.548) f1: (test=0.104) roc_auc: (test=0.580) 8.36s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=68, TN=1483, FP=1017, FN=57; precision=0.063, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.591) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.065) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.569) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.112) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.604) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1483, 'FP': 1017, 'FN': 57, 'precision': 0.06267281105990784, 'recall': 0.544, 'accuracy': 0.5908571428571429, 'average_precision': 0.06532955106093061, 'balanced_accuracy': 0.5686, 'f1': 0.11239669421487604, 'roc_auc': 0.6044256}
==getted_scoring_result==
[fit 355/850] END C=16.0, gamma=0.015625, kernel=rbf; total=2625, TP=68, TN=1483, FP=1017, FN=57; precision=0.063, recall=0.544
accuracy: (test=0.591) average_precision: (test=0.065) balanced_accuracy: (test=0.569) f1: (test=0.112) roc_auc: (test=0.604) 8.68s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=69, TN=1497, FP=1003, FN=56; precision=0.064, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.597) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.575) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.115) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.628) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1497, 'FP': 1003, 'FN': 56, 'precision': 0.06436567164179105, 'recall': 0.552, 'accuracy': 0.5965714285714285, 'average_precision': 0.07474826523713285, 'balanced_accuracy': 0.5754, 'f1': 0.11528822055137844, 'roc_auc': 0.6278112}
==getted_scoring_result==
[fit 356/850] END C=16.0, gamma=0.03125, kernel=rbf; total=2625, TP=69, TN=1497, FP=1003, FN=56; precision=0.064, recall=0.552
accuracy: (test=0.597) average_precision: (test=0.075) balanced_accuracy: (test=0.575) f1: (test=0.115) roc_auc: (test=0.628) 9.05s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1558, FP=942, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.621) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.600) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.126) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.647) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1558, 'FP': 942, 'FN': 53, 'precision': 0.07100591715976332, 'recall': 0.576, 'accuracy': 0.6209523809523809, 'average_precision': 0.08373104675739455, 'balanced_accuracy': 0.5995999999999999, 'f1': 0.12642669007901666, 'roc_auc': 0.6465248}
==getted_scoring_result==
[fit 357/850] END C=16.0, gamma=0.0625, kernel=rbf; total=2625, TP=72, TN=1558, FP=942, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.621) average_precision: (test=0.084) balanced_accuracy: (test=0.600) f1: (test=0.126) roc_auc: (test=0.647) 10.15s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1589, FP=911, FN=51; precision=0.075, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.634) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.087) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.614) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.133) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.657) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1589, 'FP': 911, 'FN': 51, 'precision': 0.0751269035532995, 'recall': 0.592, 'accuracy': 0.6335238095238095, 'average_precision': 0.0867805382054646, 'balanced_accuracy': 0.6138, 'f1': 0.13333333333333333, 'roc_auc': 0.6573472}
==getted_scoring_result==
[fit 358/850] END C=16.0, gamma=0.125, kernel=rbf; total=2625, TP=74, TN=1589, FP=911, FN=51; precision=0.075, recall=0.592
accuracy: (test=0.634) average_precision: (test=0.087) balanced_accuracy: (test=0.614) f1: (test=0.133) roc_auc: (test=0.657) 10.55s
==get_scoring_result==
base_score: total=2625, TP=70, TN=1604, FP=896, FN=55; precision=0.072, recall=0.560

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.638) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.089) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.601) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.128) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.668) ===
score_result_dict: {'Total': 2625, 'TP': 70, 'TN': 1604, 'FP': 896, 'FN': 55, 'precision': 0.07246376811594203, 'recall': 0.56, 'accuracy': 0.6377142857142857, 'average_precision': 0.08878117821246766, 'balanced_accuracy': 0.6008, 'f1': 0.12832263978001834, 'roc_auc': 0.6676112}
==getted_scoring_result==
[fit 359/850] END C=16.0, gamma=0.25, kernel=rbf; total=2625, TP=70, TN=1604, FP=896, FN=55; precision=0.072, recall=0.560
accuracy: (test=0.638) average_precision: (test=0.089) balanced_accuracy: (test=0.601) f1: (test=0.128) roc_auc: (test=0.668) 10.59s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1650, FP=850, FN=51; precision=0.080, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.657) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.095) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.626) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.141) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.688) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1650, 'FP': 850, 'FN': 51, 'precision': 0.08008658008658008, 'recall': 0.592, 'accuracy': 0.6567619047619048, 'average_precision': 0.09456846765484556, 'balanced_accuracy': 0.626, 'f1': 0.14108674928503334, 'roc_auc': 0.6877888}
==getted_scoring_result==
[fit 360/850] END C=16.0, gamma=0.5, kernel=rbf; total=2625, TP=74, TN=1650, FP=850, FN=51; precision=0.080, recall=0.592
accuracy: (test=0.657) average_precision: (test=0.095) balanced_accuracy: (test=0.626) f1: (test=0.141) roc_auc: (test=0.688) 11.29s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=81, TN=1734, FP=766, FN=44; precision=0.096, recall=0.648

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.691) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.114) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.671) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.167) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.724) ===
score_result_dict: {'Total': 2625, 'TP': 81, 'TN': 1734, 'FP': 766, 'FN': 44, 'precision': 0.09563164108618655, 'recall': 0.648, 'accuracy': 0.6914285714285714, 'average_precision': 0.11423200122688723, 'balanced_accuracy': 0.6708000000000001, 'f1': 0.16666666666666669, 'roc_auc': 0.7243168}
==getted_scoring_result==
[fit 361/850] END C=16.0, gamma=1.0, kernel=rbf; total=2625, TP=81, TN=1734, FP=766, FN=44; precision=0.096, recall=0.648
accuracy: (test=0.691) average_precision: (test=0.114) balanced_accuracy: (test=0.671) f1: (test=0.167) roc_auc: (test=0.724) 12.72s
==get_scoring_result==
base_score: total=2625, TP=85, TN=1888, FP=612, FN=40; precision=0.122, recall=0.680

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.752) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.162) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.718) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.207) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.780) ===
score_result_dict: {'Total': 2625, 'TP': 85, 'TN': 1888, 'FP': 612, 'FN': 40, 'precision': 0.12195121951219512, 'recall': 0.68, 'accuracy': 0.7516190476190476, 'average_precision': 0.1618701931969785, 'balanced_accuracy': 0.7176, 'f1': 0.20681265206812652, 'roc_auc': 0.7801504}
==getted_scoring_result==
[fit 362/850] END C=16.0, gamma=2.0, kernel=rbf; total=2625, TP=85, TN=1888, FP=612, FN=40; precision=0.122, recall=0.680
accuracy: (test=0.752) average_precision: (test=0.162) balanced_accuracy: (test=0.718) f1: (test=0.207) roc_auc: (test=0.780) 14.31s
==get_scoring_result==
base_score: total=2625, TP=92, TN=2044, FP=456, FN=33; precision=0.168, recall=0.736

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.814) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.246) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.777) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.273) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.849) ===
score_result_dict: {'Total': 2625, 'TP': 92, 'TN': 2044, 'FP': 456, 'FN': 33, 'precision': 0.1678832116788321, 'recall': 0.736, 'accuracy': 0.8137142857142857, 'average_precision': 0.24576257446490346, 'balanced_accuracy': 0.7767999999999999, 'f1': 0.27340267459138184, 'roc_auc': 0.8491088}
==getted_scoring_result==
[fit 363/850] END C=16.0, gamma=4.0, kernel=rbf; total=2625, TP=92, TN=2044, FP=456, FN=33; precision=0.168, recall=0.736
accuracy: (test=0.814) average_precision: (test=0.246) balanced_accuracy: (test=0.777) f1: (test=0.273) roc_auc: (test=0.849) 19.11s
==get_scoring_result==
base_score: total=2625, TP=92, TN=2269, FP=231, FN=33; precision=0.285, recall=0.736

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.899) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.433) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.822) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.411) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 92, 'TN': 2269, 'FP': 231, 'FN': 33, 'precision': 0.2848297213622291, 'recall': 0.736, 'accuracy': 0.8994285714285715, 'average_precision': 0.4333578205508751, 'balanced_accuracy': 0.8218, 'f1': 0.41071428571428575, 'roc_auc': 0.8986336}
==getted_scoring_result==
[fit 364/850] END C=16.0, gamma=8.0, kernel=rbf; total=2625, TP=92, TN=2269, FP=231, FN=33; precision=0.285, recall=0.736
accuracy: (test=0.899) average_precision: (test=0.433) balanced_accuracy: (test=0.822) f1: (test=0.411) roc_auc: (test=0.899) 33.76s
==get_scoring_result==
base_score: total=2625, TP=83, TN=2411, FP=89, FN=42; precision=0.483, recall=0.664

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.950) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.657) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.814) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.559) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.914) ===
score_result_dict: {'Total': 2625, 'TP': 83, 'TN': 2411, 'FP': 89, 'FN': 42, 'precision': 0.48255813953488375, 'recall': 0.664, 'accuracy': 0.9500952380952381, 'average_precision': 0.6570942587234323, 'balanced_accuracy': 0.8142, 'f1': 0.5589225589225589, 'roc_auc': 0.91408}
==getted_scoring_result==
[fit 365/850] END C=16.0, gamma=16.0, kernel=rbf; total=2625, TP=83, TN=2411, FP=89, FN=42; precision=0.483, recall=0.664
accuracy: (test=0.950) average_precision: (test=0.657) balanced_accuracy: (test=0.814) f1: (test=0.559) roc_auc: (test=0.914) 47.01s
==get_scoring_result==
base_score: total=2625, TP=80, TN=2468, FP=32, FN=45; precision=0.714, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.702) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.814) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.675) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.910) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2468, 'FP': 32, 'FN': 45, 'precision': 0.7142857142857143, 'recall': 0.64, 'accuracy': 0.9706666666666667, 'average_precision': 0.7015276689992925, 'balanced_accuracy': 0.8136, 'f1': 0.6751054852320676, 'roc_auc': 0.9095584}
==getted_scoring_result==
[fit 366/850] END C=16.0, gamma=32.0, kernel=rbf; total=2625, TP=80, TN=2468, FP=32, FN=45; precision=0.714, recall=0.640
accuracy: (test=0.971) average_precision: (test=0.702) balanced_accuracy: (test=0.814) f1: (test=0.675) roc_auc: (test=0.910) 45.42s
==get_scoring_result==
base_score: total=2625, TP=77, TN=2477, FP=23, FN=48; precision=0.770, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.973) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.702) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.803) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.684) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.898) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 2477, 'FP': 23, 'FN': 48, 'precision': 0.77, 'recall': 0.616, 'accuracy': 0.9729523809523809, 'average_precision': 0.7020271023627703, 'balanced_accuracy': 0.8034, 'f1': 0.6844444444444444, 'roc_auc': 0.8982432}
==getted_scoring_result==
[fit 367/850] END C=16.0, gamma=64.0, kernel=rbf; total=2625, TP=77, TN=2477, FP=23, FN=48; precision=0.770, recall=0.616
accuracy: (test=0.973) average_precision: (test=0.702) balanced_accuracy: (test=0.803) f1: (test=0.684) roc_auc: (test=0.898) 28.06s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2478, FP=22, FN=50; precision=0.773, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.973) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.796) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.676) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2478, 'FP': 22, 'FN': 50, 'precision': 0.7731958762886598, 'recall': 0.6, 'accuracy': 0.9725714285714285, 'average_precision': 0.6973828073138781, 'balanced_accuracy': 0.7956, 'f1': 0.6756756756756757, 'roc_auc': 0.8953088}
==getted_scoring_result==
[fit 368/850] END C=16.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2478, FP=22, FN=50; precision=0.773, recall=0.600
accuracy: (test=0.973) average_precision: (test=0.697) balanced_accuracy: (test=0.796) f1: (test=0.676) roc_auc: (test=0.895) 19.96s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6787524697414195, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.8887776}
==getted_scoring_result==
[fit 369/850] END C=16.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 19.63s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 370/850] END C=16.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 21.90s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 371/850] END C=16.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 25.90s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 372/850] END C=16.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 25.89s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 373/850] END C=16.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 22.02s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 374/850] END C=16.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 19.73s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 375/850] END C=16.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 15.91s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1325, FP=1175, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.530) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.533) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.538) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1325, 'FP': 1175, 'FN': 58, 'precision': 0.05394524959742351, 'recall': 0.536, 'accuracy': 0.5302857142857142, 'average_precision': 0.05018176373172225, 'balanced_accuracy': 0.533, 'f1': 0.09802487198244329, 'roc_auc': 0.5376656}
==getted_scoring_result==
[fit 376/850] END C=32.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=67, TN=1325, FP=1175, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.530) average_precision: (test=0.050) balanced_accuracy: (test=0.533) f1: (test=0.098) roc_auc: (test=0.538) 8.13s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1353, FP=1147, FN=56; precision=0.057, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.542) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.547) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.556) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1353, 'FP': 1147, 'FN': 56, 'precision': 0.05674342105263158, 'recall': 0.552, 'accuracy': 0.5417142857142857, 'average_precision': 0.05333829487166532, 'balanced_accuracy': 0.5466, 'f1': 0.10290827740492169, 'roc_auc': 0.5563872}
==getted_scoring_result==
[fit 377/850] END C=32.0, gamma=0.001953125, kernel=rbf; total=2625, TP=69, TN=1353, FP=1147, FN=56; precision=0.057, recall=0.552
accuracy: (test=0.542) average_precision: (test=0.053) balanced_accuracy: (test=0.547) f1: (test=0.103) roc_auc: (test=0.556) 8.18s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1397, FP=1103, FN=58; precision=0.057, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.558) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.547) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.580) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1397, 'FP': 1103, 'FN': 58, 'precision': 0.05726495726495726, 'recall': 0.536, 'accuracy': 0.5577142857142857, 'average_precision': 0.05819590517257234, 'balanced_accuracy': 0.5474, 'f1': 0.10347490347490346, 'roc_auc': 0.57964}
==getted_scoring_result==
[fit 378/850] END C=32.0, gamma=0.00390625, kernel=rbf; total=2625, TP=67, TN=1397, FP=1103, FN=58; precision=0.057, recall=0.536
accuracy: (test=0.558) average_precision: (test=0.058) balanced_accuracy: (test=0.547) f1: (test=0.103) roc_auc: (test=0.580) 8.24s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1480, FP=1020, FN=57; precision=0.062, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.590) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.065) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.112) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.604) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1480, 'FP': 1020, 'FN': 57, 'precision': 0.0625, 'recall': 0.544, 'accuracy': 0.5897142857142857, 'average_precision': 0.0653606542917035, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.11211871393239901, 'roc_auc': 0.604432}
==getted_scoring_result==
[fit 379/850] END C=32.0, gamma=0.0078125, kernel=rbf; total=2625, TP=68, TN=1480, FP=1020, FN=57; precision=0.062, recall=0.544
accuracy: (test=0.590) average_precision: (test=0.065) balanced_accuracy: (test=0.568) f1: (test=0.112) roc_auc: (test=0.604) 8.58s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1499, FP=1001, FN=56; precision=0.064, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.597) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.576) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.115) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.628) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1499, 'FP': 1001, 'FN': 56, 'precision': 0.06448598130841121, 'recall': 0.552, 'accuracy': 0.5973333333333334, 'average_precision': 0.0747606541536262, 'balanced_accuracy': 0.5758000000000001, 'f1': 0.11548117154811714, 'roc_auc': 0.6275072}
==getted_scoring_result==
[fit 380/850] END C=32.0, gamma=0.015625, kernel=rbf; total=2625, TP=69, TN=1499, FP=1001, FN=56; precision=0.064, recall=0.552
accuracy: (test=0.597) average_precision: (test=0.075) balanced_accuracy: (test=0.576) f1: (test=0.115) roc_auc: (test=0.628) 8.91s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1557, FP=943, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.621) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.083) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.599) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.126) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.646) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1557, 'FP': 943, 'FN': 53, 'precision': 0.07093596059113301, 'recall': 0.576, 'accuracy': 0.6205714285714286, 'average_precision': 0.08312155784818116, 'balanced_accuracy': 0.5993999999999999, 'f1': 0.12631578947368421, 'roc_auc': 0.6459232}
==getted_scoring_result==
[fit 381/850] END C=32.0, gamma=0.03125, kernel=rbf; total=2625, TP=72, TN=1557, FP=943, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.621) average_precision: (test=0.083) balanced_accuracy: (test=0.599) f1: (test=0.126) roc_auc: (test=0.646) 9.51s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1591, FP=909, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.634) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.656) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1591, 'FP': 909, 'FN': 53, 'precision': 0.07339449541284404, 'recall': 0.576, 'accuracy': 0.6335238095238095, 'average_precision': 0.08634880383549606, 'balanced_accuracy': 0.6062, 'f1': 0.1301989150090416, 'roc_auc': 0.6561392}
==getted_scoring_result==
[fit 382/850] END C=32.0, gamma=0.0625, kernel=rbf; total=2625, TP=72, TN=1591, FP=909, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.634) average_precision: (test=0.086) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.656) 10.37s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1590, FP=910, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.633) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.088) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.664) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1590, 'FP': 910, 'FN': 53, 'precision': 0.07331975560081466, 'recall': 0.576, 'accuracy': 0.6331428571428571, 'average_precision': 0.08826887145052192, 'balanced_accuracy': 0.606, 'f1': 0.13008130081300814, 'roc_auc': 0.6639856}
==getted_scoring_result==
[fit 383/850] END C=32.0, gamma=0.125, kernel=rbf; total=2625, TP=72, TN=1590, FP=910, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.633) average_precision: (test=0.088) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.664) 10.85s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1621, FP=879, FN=53; precision=0.076, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.645) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.091) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.134) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.677) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1621, 'FP': 879, 'FN': 53, 'precision': 0.07570977917981073, 'recall': 0.576, 'accuracy': 0.6449523809523809, 'average_precision': 0.0909664126727021, 'balanced_accuracy': 0.6122, 'f1': 0.1338289962825279, 'roc_auc': 0.676928}
==getted_scoring_result==
[fit 384/850] END C=32.0, gamma=0.25, kernel=rbf; total=2625, TP=72, TN=1621, FP=879, FN=53; precision=0.076, recall=0.576
accuracy: (test=0.645) average_precision: (test=0.091) balanced_accuracy: (test=0.612) f1: (test=0.134) roc_auc: (test=0.677) 11.37s
==get_scoring_result==
base_score: total=2625, TP=77, TN=1676, FP=824, FN=48; precision=0.085, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.668) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.100) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.643) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.150) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.703) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 1676, 'FP': 824, 'FN': 48, 'precision': 0.08546059933407325, 'recall': 0.616, 'accuracy': 0.6678095238095239, 'average_precision': 0.10021609101044074, 'balanced_accuracy': 0.6432, 'f1': 0.15009746588693956, 'roc_auc': 0.702784}
==getted_scoring_result==
[fit 385/850] END C=32.0, gamma=0.5, kernel=rbf; total=2625, TP=77, TN=1676, FP=824, FN=48; precision=0.085, recall=0.616
accuracy: (test=0.668) average_precision: (test=0.100) balanced_accuracy: (test=0.643) f1: (test=0.150) roc_auc: (test=0.703) 12.71s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=85, TN=1800, FP=700, FN=40; precision=0.108, recall=0.680

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.718) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.135) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.700) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.187) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.750) ===
score_result_dict: {'Total': 2625, 'TP': 85, 'TN': 1800, 'FP': 700, 'FN': 40, 'precision': 0.10828025477707007, 'recall': 0.68, 'accuracy': 0.7180952380952381, 'average_precision': 0.13454620715665552, 'balanced_accuracy': 0.7, 'f1': 0.18681318681318682, 'roc_auc': 0.7500896}
==getted_scoring_result==
[fit 386/850] END C=32.0, gamma=1.0, kernel=rbf; total=2625, TP=85, TN=1800, FP=700, FN=40; precision=0.108, recall=0.680
accuracy: (test=0.718) average_precision: (test=0.135) balanced_accuracy: (test=0.700) f1: (test=0.187) roc_auc: (test=0.750) 15.21s
==get_scoring_result==
base_score: total=2625, TP=91, TN=1963, FP=537, FN=34; precision=0.145, recall=0.728

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.782) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.189) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.757) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.242) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.814) ===
score_result_dict: {'Total': 2625, 'TP': 91, 'TN': 1963, 'FP': 537, 'FN': 34, 'precision': 0.1449044585987261, 'recall': 0.728, 'accuracy': 0.7824761904761904, 'average_precision': 0.18930338242638878, 'balanced_accuracy': 0.7565999999999999, 'f1': 0.24169986719787515, 'roc_auc': 0.8144128}
==getted_scoring_result==
[fit 387/850] END C=32.0, gamma=2.0, kernel=rbf; total=2625, TP=91, TN=1963, FP=537, FN=34; precision=0.145, recall=0.728
accuracy: (test=0.782) average_precision: (test=0.189) balanced_accuracy: (test=0.757) f1: (test=0.242) roc_auc: (test=0.814) 19.51s
==get_scoring_result==
base_score: total=2625, TP=96, TN=2132, FP=368, FN=29; precision=0.207, recall=0.768

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.849) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.314) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.810) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.326) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.871) ===
score_result_dict: {'Total': 2625, 'TP': 96, 'TN': 2132, 'FP': 368, 'FN': 29, 'precision': 0.20689655172413793, 'recall': 0.768, 'accuracy': 0.8487619047619047, 'average_precision': 0.31396456177980536, 'balanced_accuracy': 0.8104, 'f1': 0.32597623089983024, 'roc_auc': 0.8708032}
==getted_scoring_result==
[fit 388/850] END C=32.0, gamma=4.0, kernel=rbf; total=2625, TP=96, TN=2132, FP=368, FN=29; precision=0.207, recall=0.768
accuracy: (test=0.849) average_precision: (test=0.314) balanced_accuracy: (test=0.810) f1: (test=0.326) roc_auc: (test=0.871) 31.79s
==get_scoring_result==
base_score: total=2625, TP=89, TN=2342, FP=158, FN=36; precision=0.360, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.926) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.519) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.824) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.478) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.909) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 2342, 'FP': 158, 'FN': 36, 'precision': 0.3603238866396761, 'recall': 0.712, 'accuracy': 0.9260952380952381, 'average_precision': 0.5193338159649292, 'balanced_accuracy': 0.8244, 'f1': 0.478494623655914, 'roc_auc': 0.9087664}
==getted_scoring_result==
[fit 389/850] END C=32.0, gamma=8.0, kernel=rbf; total=2625, TP=89, TN=2342, FP=158, FN=36; precision=0.360, recall=0.712
accuracy: (test=0.926) average_precision: (test=0.519) balanced_accuracy: (test=0.824) f1: (test=0.478) roc_auc: (test=0.909) 57.11s
==get_scoring_result==
base_score: total=2625, TP=81, TN=2436, FP=64, FN=44; precision=0.559, recall=0.648

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.811) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.600) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.910) ===
score_result_dict: {'Total': 2625, 'TP': 81, 'TN': 2436, 'FP': 64, 'FN': 44, 'precision': 0.5586206896551724, 'recall': 0.648, 'accuracy': 0.9588571428571429, 'average_precision': 0.6792619205391341, 'balanced_accuracy': 0.8112, 'f1': 0.6, 'roc_auc': 0.9095392}
==getted_scoring_result==
[fit 390/850] END C=32.0, gamma=16.0, kernel=rbf; total=2625, TP=81, TN=2436, FP=64, FN=44; precision=0.559, recall=0.648
accuracy: (test=0.959) average_precision: (test=0.679) balanced_accuracy: (test=0.811) f1: (test=0.600) roc_auc: (test=0.910) 1.20min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2467, FP=33, FN=46; precision=0.705, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.704) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.809) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.667) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.906) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2467, 'FP': 33, 'FN': 46, 'precision': 0.7053571428571429, 'recall': 0.632, 'accuracy': 0.9699047619047619, 'average_precision': 0.7039039142159101, 'balanced_accuracy': 0.8094, 'f1': 0.6666666666666667, 'roc_auc': 0.9061728}
==getted_scoring_result==
[fit 391/850] END C=32.0, gamma=32.0, kernel=rbf; total=2625, TP=79, TN=2467, FP=33, FN=46; precision=0.705, recall=0.632
accuracy: (test=0.970) average_precision: (test=0.704) balanced_accuracy: (test=0.809) f1: (test=0.667) roc_auc: (test=0.906) 52.50s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2475, FP=25, FN=49; precision=0.752, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.699) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2475, 'FP': 25, 'FN': 49, 'precision': 0.7524752475247525, 'recall': 0.608, 'accuracy': 0.9718095238095238, 'average_precision': 0.6989632854985153, 'balanced_accuracy': 0.7989999999999999, 'f1': 0.672566371681416, 'roc_auc': 0.8993088}
==getted_scoring_result==
[fit 392/850] END C=32.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2475, FP=25, FN=49; precision=0.752, recall=0.608
accuracy: (test=0.972) average_precision: (test=0.699) balanced_accuracy: (test=0.799) f1: (test=0.673) roc_auc: (test=0.899) 27.63s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.698) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.795) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.896) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2477, 'FP': 23, 'FN': 50, 'precision': 0.7653061224489796, 'recall': 0.6, 'accuracy': 0.9721904761904762, 'average_precision': 0.6975499660639747, 'balanced_accuracy': 0.7954, 'f1': 0.6726457399103138, 'roc_auc': 0.895584}
==getted_scoring_result==
[fit 393/850] END C=32.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600
accuracy: (test=0.972) average_precision: (test=0.698) balanced_accuracy: (test=0.795) f1: (test=0.673) roc_auc: (test=0.896) 19.10s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786539160578525, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 394/850] END C=32.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 18.87s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 395/850] END C=32.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 22.37s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 396/850] END C=32.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 25.93s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 397/850] END C=32.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 25.89s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 398/850] END C=32.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 22.46s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 399/850] END C=32.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 20.18s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 400/850] END C=32.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 15.91s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1353, FP=1147, FN=57; precision=0.056, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.541) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.543) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.101) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.556) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1353, 'FP': 1147, 'FN': 57, 'precision': 0.05596707818930041, 'recall': 0.544, 'accuracy': 0.5413333333333333, 'average_precision': 0.05328255320398662, 'balanced_accuracy': 0.5426, 'f1': 0.10149253731343283, 'roc_auc': 0.5561952}
==getted_scoring_result==
[fit 401/850] END C=64.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=68, TN=1353, FP=1147, FN=57; precision=0.056, recall=0.544
accuracy: (test=0.541) average_precision: (test=0.053) balanced_accuracy: (test=0.543) f1: (test=0.101) roc_auc: (test=0.556) 8.17s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=67, TN=1398, FP=1102, FN=58; precision=0.057, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.558) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.548) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.104) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.580) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1398, 'FP': 1102, 'FN': 58, 'precision': 0.05731394354148845, 'recall': 0.536, 'accuracy': 0.5580952380952381, 'average_precision': 0.05819239664065279, 'balanced_accuracy': 0.5476000000000001, 'f1': 0.1035548686244204, 'roc_auc': 0.5797024}
==getted_scoring_result==
[fit 402/850] END C=64.0, gamma=0.001953125, kernel=rbf; total=2625, TP=67, TN=1398, FP=1102, FN=58; precision=0.057, recall=0.536
accuracy: (test=0.558) average_precision: (test=0.058) balanced_accuracy: (test=0.548) f1: (test=0.104) roc_auc: (test=0.580) 8.32s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1480, FP=1020, FN=57; precision=0.062, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.590) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.065) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.112) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.604) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1480, 'FP': 1020, 'FN': 57, 'precision': 0.0625, 'recall': 0.544, 'accuracy': 0.5897142857142857, 'average_precision': 0.06540110773405211, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.11211871393239901, 'roc_auc': 0.6044736}
==getted_scoring_result==
[fit 403/850] END C=64.0, gamma=0.00390625, kernel=rbf; total=2625, TP=68, TN=1480, FP=1020, FN=57; precision=0.062, recall=0.544
accuracy: (test=0.590) average_precision: (test=0.065) balanced_accuracy: (test=0.568) f1: (test=0.112) roc_auc: (test=0.604) 8.55s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1500, FP=1000, FN=56; precision=0.065, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.598) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.576) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.116) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.627) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1500, 'FP': 1000, 'FN': 56, 'precision': 0.06454630495790459, 'recall': 0.552, 'accuracy': 0.5977142857142858, 'average_precision': 0.07481870907685045, 'balanced_accuracy': 0.5760000000000001, 'f1': 0.1155778894472362, 'roc_auc': 0.6274528}
==getted_scoring_result==
[fit 404/850] END C=64.0, gamma=0.0078125, kernel=rbf; total=2625, TP=69, TN=1500, FP=1000, FN=56; precision=0.065, recall=0.552
accuracy: (test=0.598) average_precision: (test=0.075) balanced_accuracy: (test=0.576) f1: (test=0.116) roc_auc: (test=0.627) 8.96s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1561, FP=939, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.622) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.083) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.600) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.127) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.646) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1561, 'FP': 939, 'FN': 53, 'precision': 0.0712166172106825, 'recall': 0.576, 'accuracy': 0.6220952380952381, 'average_precision': 0.08280164555327568, 'balanced_accuracy': 0.6002, 'f1': 0.1267605633802817, 'roc_auc': 0.6455792}
==getted_scoring_result==
[fit 405/850] END C=64.0, gamma=0.015625, kernel=rbf; total=2625, TP=72, TN=1561, FP=939, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.622) average_precision: (test=0.083) balanced_accuracy: (test=0.600) f1: (test=0.127) roc_auc: (test=0.646) 9.53s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1588, FP=912, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.632) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.655) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1588, 'FP': 912, 'FN': 53, 'precision': 0.07317073170731707, 'recall': 0.576, 'accuracy': 0.6323809523809524, 'average_precision': 0.08598841927370983, 'balanced_accuracy': 0.6055999999999999, 'f1': 0.12984670874661858, 'roc_auc': 0.6546528}
==getted_scoring_result==
[fit 406/850] END C=64.0, gamma=0.03125, kernel=rbf; total=2625, TP=72, TN=1588, FP=912, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.632) average_precision: (test=0.086) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.655) 10.55s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1584, FP=916, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.631) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.087) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.605) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.129) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.662) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1584, 'FP': 916, 'FN': 53, 'precision': 0.0728744939271255, 'recall': 0.576, 'accuracy': 0.6308571428571429, 'average_precision': 0.08748028911631935, 'balanced_accuracy': 0.6048, 'f1': 0.12938005390835577, 'roc_auc': 0.6620224}
==getted_scoring_result==
[fit 407/850] END C=64.0, gamma=0.0625, kernel=rbf; total=2625, TP=72, TN=1584, FP=916, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.631) average_precision: (test=0.087) balanced_accuracy: (test=0.605) f1: (test=0.129) roc_auc: (test=0.662) 10.63s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1600, FP=900, FN=54; precision=0.073, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.637) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.089) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.604) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.670) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1600, 'FP': 900, 'FN': 54, 'precision': 0.07312049433573635, 'recall': 0.568, 'accuracy': 0.6365714285714286, 'average_precision': 0.08861671446916736, 'balanced_accuracy': 0.604, 'f1': 0.12956204379562045, 'roc_auc': 0.669904}
==getted_scoring_result==
[fit 408/850] END C=64.0, gamma=0.125, kernel=rbf; total=2625, TP=71, TN=1600, FP=900, FN=54; precision=0.073, recall=0.568
accuracy: (test=0.637) average_precision: (test=0.089) balanced_accuracy: (test=0.604) f1: (test=0.130) roc_auc: (test=0.670) 10.28s
==get_scoring_result==
base_score: total=2625, TP=75, TN=1639, FP=861, FN=50; precision=0.080, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.653) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.094) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.628) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.141) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.687) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1639, 'FP': 861, 'FN': 50, 'precision': 0.08012820512820513, 'recall': 0.6, 'accuracy': 0.652952380952381, 'average_precision': 0.09365329584302257, 'balanced_accuracy': 0.6277999999999999, 'f1': 0.1413760603204524, 'roc_auc': 0.6873856}
==getted_scoring_result==
[fit 409/850] END C=64.0, gamma=0.25, kernel=rbf; total=2625, TP=75, TN=1639, FP=861, FN=50; precision=0.080, recall=0.600
accuracy: (test=0.653) average_precision: (test=0.094) balanced_accuracy: (test=0.628) f1: (test=0.141) roc_auc: (test=0.687) 11.70s
==get_scoring_result==
base_score: total=2625, TP=82, TN=1733, FP=767, FN=43; precision=0.097, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.691) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.112) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.675) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.168) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.725) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 1733, 'FP': 767, 'FN': 43, 'precision': 0.09658421672555949, 'recall': 0.656, 'accuracy': 0.6914285714285714, 'average_precision': 0.11227590277713007, 'balanced_accuracy': 0.6746000000000001, 'f1': 0.16837782340862426, 'roc_auc': 0.7246016}
==getted_scoring_result==
[fit 410/850] END C=64.0, gamma=0.5, kernel=rbf; total=2625, TP=82, TN=1733, FP=767, FN=43; precision=0.097, recall=0.656
accuracy: (test=0.691) average_precision: (test=0.112) balanced_accuracy: (test=0.675) f1: (test=0.168) roc_auc: (test=0.725) 14.57s
==get_scoring_result==
base_score: total=2625, TP=86, TN=1871, FP=629, FN=39; precision=0.120, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.746) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.158) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.718) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.205) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.778) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 1871, 'FP': 629, 'FN': 39, 'precision': 0.12027972027972028, 'recall': 0.688, 'accuracy': 0.7455238095238095, 'average_precision': 0.1576141235435583, 'balanced_accuracy': 0.7182, 'f1': 0.20476190476190476, 'roc_auc': 0.7778624}
==getted_scoring_result==
[fit 411/850] END C=64.0, gamma=1.0, kernel=rbf; total=2625, TP=86, TN=1871, FP=629, FN=39; precision=0.120, recall=0.688
accuracy: (test=0.746) average_precision: (test=0.158) balanced_accuracy: (test=0.718) f1: (test=0.205) roc_auc: (test=0.778) 20.10s
==get_scoring_result==
base_score: total=2625, TP=93, TN=2017, FP=483, FN=32; precision=0.161, recall=0.744

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.804) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.231) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.775) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.265) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.843) ===
score_result_dict: {'Total': 2625, 'TP': 93, 'TN': 2017, 'FP': 483, 'FN': 32, 'precision': 0.16145833333333334, 'recall': 0.744, 'accuracy': 0.8038095238095239, 'average_precision': 0.2308432031556873, 'balanced_accuracy': 0.7754, 'f1': 0.2653352353780314, 'roc_auc': 0.8431104}
==getted_scoring_result==
[fit 412/850] END C=64.0, gamma=2.0, kernel=rbf; total=2625, TP=93, TN=2017, FP=483, FN=32; precision=0.161, recall=0.744
accuracy: (test=0.804) average_precision: (test=0.231) balanced_accuracy: (test=0.775) f1: (test=0.265) roc_auc: (test=0.843) 30.72s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=93, TN=2229, FP=271, FN=32; precision=0.255, recall=0.744

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.885) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.387) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.818) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.380) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.891) ===
score_result_dict: {'Total': 2625, 'TP': 93, 'TN': 2229, 'FP': 271, 'FN': 32, 'precision': 0.2554945054945055, 'recall': 0.744, 'accuracy': 0.8845714285714286, 'average_precision': 0.38735680148619545, 'balanced_accuracy': 0.8178, 'f1': 0.38036809815950917, 'roc_auc': 0.8906432}
==getted_scoring_result==
[fit 413/850] END C=64.0, gamma=4.0, kernel=rbf; total=2625, TP=93, TN=2229, FP=271, FN=32; precision=0.255, recall=0.744
accuracy: (test=0.885) average_precision: (test=0.387) balanced_accuracy: (test=0.818) f1: (test=0.380) roc_auc: (test=0.891) 1.04min
==get_scoring_result==
base_score: total=2625, TP=85, TN=2388, FP=112, FN=40; precision=0.431, recall=0.680

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.942) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.607) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.818) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.528) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.912) ===
score_result_dict: {'Total': 2625, 'TP': 85, 'TN': 2388, 'FP': 112, 'FN': 40, 'precision': 0.43147208121827413, 'recall': 0.68, 'accuracy': 0.9420952380952381, 'average_precision': 0.6065865416565631, 'balanced_accuracy': 0.8176000000000001, 'f1': 0.5279503105590063, 'roc_auc': 0.9120864}
==getted_scoring_result==
[fit 414/850] END C=64.0, gamma=8.0, kernel=rbf; total=2625, TP=85, TN=2388, FP=112, FN=40; precision=0.431, recall=0.680
accuracy: (test=0.942) average_precision: (test=0.607) balanced_accuracy: (test=0.818) f1: (test=0.528) roc_auc: (test=0.912) 1.60min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2454, FP=46, FN=46; precision=0.632, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.965) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.695) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.807) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.632) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.908) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2454, 'FP': 46, 'FN': 46, 'precision': 0.632, 'recall': 0.632, 'accuracy': 0.964952380952381, 'average_precision': 0.6951705888389836, 'balanced_accuracy': 0.8068, 'f1': 0.632, 'roc_auc': 0.9082912}
==getted_scoring_result==
[fit 415/850] END C=64.0, gamma=16.0, kernel=rbf; total=2625, TP=79, TN=2454, FP=46, FN=46; precision=0.632, recall=0.632
accuracy: (test=0.965) average_precision: (test=0.695) balanced_accuracy: (test=0.807) f1: (test=0.632) roc_auc: (test=0.908) 1.72min
==get_scoring_result==
base_score: total=2625, TP=80, TN=2470, FP=30, FN=45; precision=0.727, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.703) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.814) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.681) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.904) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2470, 'FP': 30, 'FN': 45, 'precision': 0.7272727272727273, 'recall': 0.64, 'accuracy': 0.9714285714285714, 'average_precision': 0.7026384288775553, 'balanced_accuracy': 0.8140000000000001, 'f1': 0.6808510638297872, 'roc_auc': 0.9042304}
==getted_scoring_result==
[fit 416/850] END C=64.0, gamma=32.0, kernel=rbf; total=2625, TP=80, TN=2470, FP=30, FN=45; precision=0.727, recall=0.640
accuracy: (test=0.971) average_precision: (test=0.703) balanced_accuracy: (test=0.814) f1: (test=0.681) roc_auc: (test=0.904) 54.17s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2475, FP=25, FN=49; precision=0.752, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.699) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.900) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2475, 'FP': 25, 'FN': 49, 'precision': 0.7524752475247525, 'recall': 0.608, 'accuracy': 0.9718095238095238, 'average_precision': 0.6986764560962714, 'balanced_accuracy': 0.7989999999999999, 'f1': 0.672566371681416, 'roc_auc': 0.8999456}
==getted_scoring_result==
[fit 417/850] END C=64.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2475, FP=25, FN=49; precision=0.752, recall=0.608
accuracy: (test=0.972) average_precision: (test=0.699) balanced_accuracy: (test=0.799) f1: (test=0.673) roc_auc: (test=0.900) 27.41s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.795) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2477, 'FP': 23, 'FN': 50, 'precision': 0.7653061224489796, 'recall': 0.6, 'accuracy': 0.9721904761904762, 'average_precision': 0.6970823317728058, 'balanced_accuracy': 0.7954, 'f1': 0.6726457399103138, 'roc_auc': 0.8954368}
==getted_scoring_result==
[fit 418/850] END C=64.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600
accuracy: (test=0.972) average_precision: (test=0.697) balanced_accuracy: (test=0.795) f1: (test=0.673) roc_auc: (test=0.895) 18.82s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786539160578525, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 419/850] END C=64.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 18.40s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 420/850] END C=64.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 21.42s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 421/850] END C=64.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 25.46s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 422/850] END C=64.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 25.45s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 423/850] END C=64.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 21.61s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 424/850] END C=64.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 19.29s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 425/850] END C=64.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 15.49s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=67, TN=1399, FP=1101, FN=58; precision=0.057, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.558) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.548) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.104) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.580) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1399, 'FP': 1101, 'FN': 58, 'precision': 0.05736301369863014, 'recall': 0.536, 'accuracy': 0.5584761904761905, 'average_precision': 0.05821433240186272, 'balanced_accuracy': 0.5478000000000001, 'f1': 0.10363495746326372, 'roc_auc': 0.5797408}
==getted_scoring_result==
[fit 426/850] END C=128.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=67, TN=1399, FP=1101, FN=58; precision=0.057, recall=0.536
accuracy: (test=0.558) average_precision: (test=0.058) balanced_accuracy: (test=0.548) f1: (test=0.104) roc_auc: (test=0.580) 7.97s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1479, FP=1021, FN=57; precision=0.062, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.589) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.065) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.112) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.604) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1479, 'FP': 1021, 'FN': 57, 'precision': 0.06244260789715335, 'recall': 0.544, 'accuracy': 0.5893333333333334, 'average_precision': 0.06539974025449083, 'balanced_accuracy': 0.5678000000000001, 'f1': 0.11202635914332783, 'roc_auc': 0.604496}
==getted_scoring_result==
[fit 427/850] END C=128.0, gamma=0.001953125, kernel=rbf; total=2625, TP=68, TN=1479, FP=1021, FN=57; precision=0.062, recall=0.544
accuracy: (test=0.589) average_precision: (test=0.065) balanced_accuracy: (test=0.568) f1: (test=0.112) roc_auc: (test=0.604) 8.20s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=69, TN=1501, FP=999, FN=56; precision=0.065, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.598) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.576) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.116) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.627) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1501, 'FP': 999, 'FN': 56, 'precision': 0.06460674157303371, 'recall': 0.552, 'accuracy': 0.5980952380952381, 'average_precision': 0.07480907858435973, 'balanced_accuracy': 0.5762, 'f1': 0.115674769488684, 'roc_auc': 0.6272448}
==getted_scoring_result==
[fit 428/850] END C=128.0, gamma=0.00390625, kernel=rbf; total=2625, TP=69, TN=1501, FP=999, FN=56; precision=0.065, recall=0.552
accuracy: (test=0.598) average_precision: (test=0.075) balanced_accuracy: (test=0.576) f1: (test=0.116) roc_auc: (test=0.627) 8.73s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1558, FP=942, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.621) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.082) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.600) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.126) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.645) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1558, 'FP': 942, 'FN': 53, 'precision': 0.07100591715976332, 'recall': 0.576, 'accuracy': 0.6209523809523809, 'average_precision': 0.0824733954024098, 'balanced_accuracy': 0.5995999999999999, 'f1': 0.12642669007901666, 'roc_auc': 0.6448752}
==getted_scoring_result==
[fit 429/850] END C=128.0, gamma=0.0078125, kernel=rbf; total=2625, TP=72, TN=1558, FP=942, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.621) average_precision: (test=0.082) balanced_accuracy: (test=0.600) f1: (test=0.126) roc_auc: (test=0.645) 8.83s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1588, FP=912, FN=52; precision=0.074, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.633) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.610) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.132) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.654) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1588, 'FP': 912, 'FN': 52, 'precision': 0.07411167512690356, 'recall': 0.584, 'accuracy': 0.6327619047619047, 'average_precision': 0.08617513466489612, 'balanced_accuracy': 0.6095999999999999, 'f1': 0.13153153153153155, 'roc_auc': 0.6540784}
==getted_scoring_result==
[fit 430/850] END C=128.0, gamma=0.015625, kernel=rbf; total=2625, TP=73, TN=1588, FP=912, FN=52; precision=0.074, recall=0.584
accuracy: (test=0.633) average_precision: (test=0.086) balanced_accuracy: (test=0.610) f1: (test=0.132) roc_auc: (test=0.654) 9.25s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1584, FP=916, FN=54; precision=0.072, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.630) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.087) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.601) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.128) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.660) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1584, 'FP': 916, 'FN': 54, 'precision': 0.07193515704154002, 'recall': 0.568, 'accuracy': 0.6304761904761905, 'average_precision': 0.08660697705968459, 'balanced_accuracy': 0.6008, 'f1': 0.12769784172661872, 'roc_auc': 0.6600304}
==getted_scoring_result==
[fit 431/850] END C=128.0, gamma=0.03125, kernel=rbf; total=2625, TP=71, TN=1584, FP=916, FN=54; precision=0.072, recall=0.568
accuracy: (test=0.630) average_precision: (test=0.087) balanced_accuracy: (test=0.601) f1: (test=0.128) roc_auc: (test=0.660) 9.73s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1594, FP=906, FN=53; precision=0.074, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.635) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.087) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.607) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.665) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1594, 'FP': 906, 'FN': 53, 'precision': 0.0736196319018405, 'recall': 0.576, 'accuracy': 0.6346666666666667, 'average_precision': 0.08728072663153522, 'balanced_accuracy': 0.6068, 'f1': 0.13055303717135086, 'roc_auc': 0.6654016}
==getted_scoring_result==
[fit 432/850] END C=128.0, gamma=0.0625, kernel=rbf; total=2625, TP=72, TN=1594, FP=906, FN=53; precision=0.074, recall=0.576
accuracy: (test=0.635) average_precision: (test=0.087) balanced_accuracy: (test=0.607) f1: (test=0.131) roc_auc: (test=0.665) 10.33s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1614, FP=886, FN=51; precision=0.077, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.643) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.091) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.619) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.136) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.677) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1614, 'FP': 886, 'FN': 51, 'precision': 0.07708333333333334, 'recall': 0.592, 'accuracy': 0.6430476190476191, 'average_precision': 0.0906007724770714, 'balanced_accuracy': 0.6188, 'f1': 0.13640552995391705, 'roc_auc': 0.6765216}
==getted_scoring_result==
[fit 433/850] END C=128.0, gamma=0.125, kernel=rbf; total=2625, TP=74, TN=1614, FP=886, FN=51; precision=0.077, recall=0.592
accuracy: (test=0.643) average_precision: (test=0.091) balanced_accuracy: (test=0.619) f1: (test=0.136) roc_auc: (test=0.677) 11.85s
==get_scoring_result==
base_score: total=2625, TP=79, TN=1670, FP=830, FN=46; precision=0.087, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.666) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.099) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.650) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.153) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.703) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 1670, 'FP': 830, 'FN': 46, 'precision': 0.08690869086908691, 'recall': 0.632, 'accuracy': 0.6662857142857143, 'average_precision': 0.09934994375610902, 'balanced_accuracy': 0.65, 'f1': 0.1528046421663443, 'roc_auc': 0.7029472}
==getted_scoring_result==
[fit 434/850] END C=128.0, gamma=0.25, kernel=rbf; total=2625, TP=79, TN=1670, FP=830, FN=46; precision=0.087, recall=0.632
accuracy: (test=0.666) average_precision: (test=0.099) balanced_accuracy: (test=0.650) f1: (test=0.153) roc_auc: (test=0.703) 14.86s
==get_scoring_result==
base_score: total=2625, TP=84, TN=1789, FP=711, FN=41; precision=0.106, recall=0.672

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.714) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.134) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.694) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.183) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.750) ===
score_result_dict: {'Total': 2625, 'TP': 84, 'TN': 1789, 'FP': 711, 'FN': 41, 'precision': 0.10566037735849057, 'recall': 0.672, 'accuracy': 0.7135238095238096, 'average_precision': 0.13402376085554202, 'balanced_accuracy': 0.6938, 'f1': 0.18260869565217394, 'roc_auc': 0.749792}
==getted_scoring_result==
[fit 435/850] END C=128.0, gamma=0.5, kernel=rbf; total=2625, TP=84, TN=1789, FP=711, FN=41; precision=0.106, recall=0.672
accuracy: (test=0.714) average_precision: (test=0.134) balanced_accuracy: (test=0.694) f1: (test=0.183) roc_auc: (test=0.750) 20.96s
==get_scoring_result==
base_score: total=2625, TP=90, TN=1944, FP=556, FN=35; precision=0.139, recall=0.720

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.775) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.180) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.749) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.233) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.809) ===
score_result_dict: {'Total': 2625, 'TP': 90, 'TN': 1944, 'FP': 556, 'FN': 35, 'precision': 0.1393188854489164, 'recall': 0.72, 'accuracy': 0.7748571428571429, 'average_precision': 0.1801796832233041, 'balanced_accuracy': 0.7487999999999999, 'f1': 0.23346303501945526, 'roc_auc': 0.8086848}
==getted_scoring_result==
[fit 436/850] END C=128.0, gamma=1.0, kernel=rbf; total=2625, TP=90, TN=1944, FP=556, FN=35; precision=0.139, recall=0.720
accuracy: (test=0.775) average_precision: (test=0.180) balanced_accuracy: (test=0.749) f1: (test=0.233) roc_auc: (test=0.809) 31.69s
==get_scoring_result==
base_score: total=2625, TP=93, TN=2102, FP=398, FN=32; precision=0.189, recall=0.744

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.836) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.290) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.302) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.865) ===
score_result_dict: {'Total': 2625, 'TP': 93, 'TN': 2102, 'FP': 398, 'FN': 32, 'precision': 0.1894093686354379, 'recall': 0.744, 'accuracy': 0.8361904761904762, 'average_precision': 0.28955675362482813, 'balanced_accuracy': 0.7924, 'f1': 0.30194805194805197, 'roc_auc': 0.864608}
==getted_scoring_result==
[fit 437/850] END C=128.0, gamma=2.0, kernel=rbf; total=2625, TP=93, TN=2102, FP=398, FN=32; precision=0.189, recall=0.744
accuracy: (test=0.836) average_precision: (test=0.290) balanced_accuracy: (test=0.792) f1: (test=0.302) roc_auc: (test=0.865) 55.42s
==get_scoring_result==
base_score: total=2625, TP=92, TN=2306, FP=194, FN=33; precision=0.322, recall=0.736

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.914) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.464) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.829) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.448) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.901) ===
score_result_dict: {'Total': 2625, 'TP': 92, 'TN': 2306, 'FP': 194, 'FN': 33, 'precision': 0.32167832167832167, 'recall': 0.736, 'accuracy': 0.9135238095238095, 'average_precision': 0.4642100847529949, 'balanced_accuracy': 0.8291999999999999, 'f1': 0.4476885644768856, 'roc_auc': 0.901408}
==getted_scoring_result==
[fit 438/850] END C=128.0, gamma=4.0, kernel=rbf; total=2625, TP=92, TN=2306, FP=194, FN=33; precision=0.322, recall=0.736
accuracy: (test=0.914) average_precision: (test=0.464) balanced_accuracy: (test=0.829) f1: (test=0.448) roc_auc: (test=0.901) 1.88min
==get_scoring_result==
base_score: total=2625, TP=82, TN=2426, FP=74, FN=43; precision=0.526, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.955) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.634) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.813) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.584) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.907) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 2426, 'FP': 74, 'FN': 43, 'precision': 0.5256410256410257, 'recall': 0.656, 'accuracy': 0.9554285714285714, 'average_precision': 0.6336613429162608, 'balanced_accuracy': 0.8132, 'f1': 0.5836298932384342, 'roc_auc': 0.9071904}
==getted_scoring_result==
[fit 439/850] END C=128.0, gamma=8.0, kernel=rbf; total=2625, TP=82, TN=2426, FP=74, FN=43; precision=0.526, recall=0.656
accuracy: (test=0.955) average_precision: (test=0.634) balanced_accuracy: (test=0.813) f1: (test=0.584) roc_auc: (test=0.907) 2.65min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2462, FP=38, FN=46; precision=0.675, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.968) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.693) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.808) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.653) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.907) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2462, 'FP': 38, 'FN': 46, 'precision': 0.6752136752136753, 'recall': 0.632, 'accuracy': 0.968, 'average_precision': 0.6928037958788397, 'balanced_accuracy': 0.8084, 'f1': 0.6528925619834711, 'roc_auc': 0.9069024}
==getted_scoring_result==
[fit 440/850] END C=128.0, gamma=16.0, kernel=rbf; total=2625, TP=79, TN=2462, FP=38, FN=46; precision=0.675, recall=0.632
accuracy: (test=0.968) average_precision: (test=0.693) balanced_accuracy: (test=0.808) f1: (test=0.653) roc_auc: (test=0.907) 2.09min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2469, FP=31, FN=46; precision=0.718, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.699) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.810) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.672) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.905) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2469, 'FP': 31, 'FN': 46, 'precision': 0.7181818181818181, 'recall': 0.632, 'accuracy': 0.9706666666666667, 'average_precision': 0.6985585439348773, 'balanced_accuracy': 0.8098000000000001, 'f1': 0.6723404255319149, 'roc_auc': 0.9046272}
==getted_scoring_result==
[fit 441/850] END C=128.0, gamma=32.0, kernel=rbf; total=2625, TP=79, TN=2469, FP=31, FN=46; precision=0.718, recall=0.632
accuracy: (test=0.971) average_precision: (test=0.699) balanced_accuracy: (test=0.810) f1: (test=0.672) roc_auc: (test=0.905) 54.72s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2475, FP=25, FN=49; precision=0.752, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.698) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.900) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2475, 'FP': 25, 'FN': 49, 'precision': 0.7524752475247525, 'recall': 0.608, 'accuracy': 0.9718095238095238, 'average_precision': 0.6975940433691713, 'balanced_accuracy': 0.7989999999999999, 'f1': 0.672566371681416, 'roc_auc': 0.8998496}
==getted_scoring_result==
[fit 442/850] END C=128.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2475, FP=25, FN=49; precision=0.752, recall=0.608
accuracy: (test=0.972) average_precision: (test=0.698) balanced_accuracy: (test=0.799) f1: (test=0.673) roc_auc: (test=0.900) 27.25s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.795) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2477, 'FP': 23, 'FN': 50, 'precision': 0.7653061224489796, 'recall': 0.6, 'accuracy': 0.9721904761904762, 'average_precision': 0.6970638985448205, 'balanced_accuracy': 0.7954, 'f1': 0.6726457399103138, 'roc_auc': 0.895408}
==getted_scoring_result==
[fit 443/850] END C=128.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600
accuracy: (test=0.972) average_precision: (test=0.697) balanced_accuracy: (test=0.795) f1: (test=0.673) roc_auc: (test=0.895) 19.07s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786539160578525, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 444/850] END C=128.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 18.38s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 445/850] END C=128.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 21.44s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 446/850] END C=128.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 25.52s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 447/850] END C=128.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 25.47s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 448/850] END C=128.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 21.66s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 449/850] END C=128.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 19.31s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 450/850] END C=128.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 15.54s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1478, FP=1022, FN=57; precision=0.062, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.589) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.065) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.112) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.605) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1478, 'FP': 1022, 'FN': 57, 'precision': 0.062385321100917435, 'recall': 0.544, 'accuracy': 0.588952380952381, 'average_precision': 0.06546222098367638, 'balanced_accuracy': 0.5676, 'f1': 0.11193415637860084, 'roc_auc': 0.6047136}
==getted_scoring_result==
[fit 451/850] END C=256.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=68, TN=1478, FP=1022, FN=57; precision=0.062, recall=0.544
accuracy: (test=0.589) average_precision: (test=0.065) balanced_accuracy: (test=0.568) f1: (test=0.112) roc_auc: (test=0.605) 8.29s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1501, FP=999, FN=56; precision=0.065, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.598) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.576) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.116) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.627) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1501, 'FP': 999, 'FN': 56, 'precision': 0.06460674157303371, 'recall': 0.552, 'accuracy': 0.5980952380952381, 'average_precision': 0.0747816469440358, 'balanced_accuracy': 0.5762, 'f1': 0.115674769488684, 'roc_auc': 0.6270784}
==getted_scoring_result==
[fit 452/850] END C=256.0, gamma=0.001953125, kernel=rbf; total=2625, TP=69, TN=1501, FP=999, FN=56; precision=0.065, recall=0.552
accuracy: (test=0.598) average_precision: (test=0.075) balanced_accuracy: (test=0.576) f1: (test=0.116) roc_auc: (test=0.627) 8.66s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1559, FP=941, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.621) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.082) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.600) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.127) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.645) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1559, 'FP': 941, 'FN': 53, 'precision': 0.07107601184600197, 'recall': 0.576, 'accuracy': 0.6213333333333333, 'average_precision': 0.08249533663886413, 'balanced_accuracy': 0.5998, 'f1': 0.1265377855887522, 'roc_auc': 0.6447776}
==getted_scoring_result==
[fit 453/850] END C=256.0, gamma=0.00390625, kernel=rbf; total=2625, TP=72, TN=1559, FP=941, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.621) average_precision: (test=0.082) balanced_accuracy: (test=0.600) f1: (test=0.127) roc_auc: (test=0.645) 9.21s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1587, FP=913, FN=52; precision=0.074, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.632) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.609) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.654) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1587, 'FP': 913, 'FN': 52, 'precision': 0.07403651115618662, 'recall': 0.584, 'accuracy': 0.6323809523809524, 'average_precision': 0.08614787405311104, 'balanced_accuracy': 0.6093999999999999, 'f1': 0.13141314131413143, 'roc_auc': 0.6537872}
==getted_scoring_result==
[fit 454/850] END C=256.0, gamma=0.0078125, kernel=rbf; total=2625, TP=73, TN=1587, FP=913, FN=52; precision=0.074, recall=0.584
accuracy: (test=0.632) average_precision: (test=0.086) balanced_accuracy: (test=0.609) f1: (test=0.131) roc_auc: (test=0.654) 9.27s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1586, FP=914, FN=54; precision=0.072, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.631) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.601) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.128) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.659) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1586, 'FP': 914, 'FN': 54, 'precision': 0.07208121827411168, 'recall': 0.568, 'accuracy': 0.6312380952380953, 'average_precision': 0.08583047175464087, 'balanced_accuracy': 0.6012, 'f1': 0.12792792792792793, 'roc_auc': 0.6588416}
==getted_scoring_result==
[fit 455/850] END C=256.0, gamma=0.015625, kernel=rbf; total=2625, TP=71, TN=1586, FP=914, FN=54; precision=0.072, recall=0.568
accuracy: (test=0.631) average_precision: (test=0.086) balanced_accuracy: (test=0.601) f1: (test=0.128) roc_auc: (test=0.659) 9.76s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1590, FP=910, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.633) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.662) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1590, 'FP': 910, 'FN': 53, 'precision': 0.07331975560081466, 'recall': 0.576, 'accuracy': 0.6331428571428571, 'average_precision': 0.0862650326233162, 'balanced_accuracy': 0.606, 'f1': 0.13008130081300814, 'roc_auc': 0.6621552}
==getted_scoring_result==
[fit 456/850] END C=256.0, gamma=0.03125, kernel=rbf; total=2625, TP=72, TN=1590, FP=910, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.633) average_precision: (test=0.086) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.662) 10.41s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1595, FP=905, FN=51; precision=0.076, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.636) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.088) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.615) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.134) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.670) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1595, 'FP': 905, 'FN': 51, 'precision': 0.0755873340143003, 'recall': 0.592, 'accuracy': 0.6358095238095238, 'average_precision': 0.08790696266900555, 'balanced_accuracy': 0.615, 'f1': 0.13405797101449277, 'roc_auc': 0.6695056}
==getted_scoring_result==
[fit 457/850] END C=256.0, gamma=0.0625, kernel=rbf; total=2625, TP=74, TN=1595, FP=905, FN=51; precision=0.076, recall=0.592
accuracy: (test=0.636) average_precision: (test=0.088) balanced_accuracy: (test=0.615) f1: (test=0.134) roc_auc: (test=0.670) 11.90s
==get_scoring_result==
base_score: total=2625, TP=75, TN=1634, FP=866, FN=50; precision=0.080, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.651) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.093) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.627) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.141) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.687) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1634, 'FP': 866, 'FN': 50, 'precision': 0.07970244420828905, 'recall': 0.6, 'accuracy': 0.6510476190476191, 'average_precision': 0.09307591147455277, 'balanced_accuracy': 0.6268, 'f1': 0.14071294559099434, 'roc_auc': 0.6867504}
==getted_scoring_result==
[fit 458/850] END C=256.0, gamma=0.125, kernel=rbf; total=2625, TP=75, TN=1634, FP=866, FN=50; precision=0.080, recall=0.600
accuracy: (test=0.651) average_precision: (test=0.093) balanced_accuracy: (test=0.627) f1: (test=0.141) roc_auc: (test=0.687) 15.02s
==get_scoring_result==
base_score: total=2625, TP=82, TN=1735, FP=765, FN=43; precision=0.097, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.692) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.112) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.675) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.169) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.725) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 1735, 'FP': 765, 'FN': 43, 'precision': 0.09681227863046045, 'recall': 0.656, 'accuracy': 0.6921904761904762, 'average_precision': 0.11182238824413838, 'balanced_accuracy': 0.675, 'f1': 0.16872427983539093, 'roc_auc': 0.7253344}
==getted_scoring_result==
[fit 459/850] END C=256.0, gamma=0.25, kernel=rbf; total=2625, TP=82, TN=1735, FP=765, FN=43; precision=0.097, recall=0.656
accuracy: (test=0.692) average_precision: (test=0.112) balanced_accuracy: (test=0.675) f1: (test=0.169) roc_auc: (test=0.725) 21.17s
==get_scoring_result==
base_score: total=2625, TP=86, TN=1861, FP=639, FN=39; precision=0.119, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.742) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.153) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.716) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.202) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.775) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 1861, 'FP': 639, 'FN': 39, 'precision': 0.11862068965517242, 'recall': 0.688, 'accuracy': 0.7417142857142857, 'average_precision': 0.15344851535590032, 'balanced_accuracy': 0.7162, 'f1': 0.2023529411764706, 'roc_auc': 0.775088}
==getted_scoring_result==
[fit 460/850] END C=256.0, gamma=0.5, kernel=rbf; total=2625, TP=86, TN=1861, FP=639, FN=39; precision=0.119, recall=0.688
accuracy: (test=0.742) average_precision: (test=0.153) balanced_accuracy: (test=0.716) f1: (test=0.202) roc_auc: (test=0.775) 33.10s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=92, TN=2001, FP=499, FN=33; precision=0.156, recall=0.736

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.797) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.216) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.768) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.257) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.837) ===
score_result_dict: {'Total': 2625, 'TP': 92, 'TN': 2001, 'FP': 499, 'FN': 33, 'precision': 0.155668358714044, 'recall': 0.736, 'accuracy': 0.7973333333333333, 'average_precision': 0.21576265511289827, 'balanced_accuracy': 0.7682, 'f1': 0.2569832402234637, 'roc_auc': 0.8365696}
==getted_scoring_result==
[fit 461/850] END C=256.0, gamma=1.0, kernel=rbf; total=2625, TP=92, TN=2001, FP=499, FN=33; precision=0.156, recall=0.736
accuracy: (test=0.797) average_precision: (test=0.216) balanced_accuracy: (test=0.768) f1: (test=0.257) roc_auc: (test=0.837) 54.22s
==get_scoring_result==
base_score: total=2625, TP=93, TN=2182, FP=318, FN=32; precision=0.226, recall=0.744

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.867) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.348) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.808) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.347) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.883) ===
score_result_dict: {'Total': 2625, 'TP': 93, 'TN': 2182, 'FP': 318, 'FN': 32, 'precision': 0.22627737226277372, 'recall': 0.744, 'accuracy': 0.8666666666666667, 'average_precision': 0.34838671894657214, 'balanced_accuracy': 0.8084, 'f1': 0.3470149253731343, 'roc_auc': 0.8829312}
==getted_scoring_result==
[fit 462/850] END C=256.0, gamma=2.0, kernel=rbf; total=2625, TP=93, TN=2182, FP=318, FN=32; precision=0.226, recall=0.744
accuracy: (test=0.867) average_precision: (test=0.348) balanced_accuracy: (test=0.808) f1: (test=0.347) roc_auc: (test=0.883) 1.90min
==get_scoring_result==
base_score: total=2625, TP=86, TN=2359, FP=141, FN=39; precision=0.379, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.931) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.539) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.816) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.489) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.908) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 2359, 'FP': 141, 'FN': 39, 'precision': 0.3788546255506608, 'recall': 0.688, 'accuracy': 0.9314285714285714, 'average_precision': 0.5391163331684192, 'balanced_accuracy': 0.8158, 'f1': 0.48863636363636365, 'roc_auc': 0.9075824}
==getted_scoring_result==
[fit 463/850] END C=256.0, gamma=4.0, kernel=rbf; total=2625, TP=86, TN=2359, FP=141, FN=39; precision=0.379, recall=0.688
accuracy: (test=0.931) average_precision: (test=0.539) balanced_accuracy: (test=0.816) f1: (test=0.489) roc_auc: (test=0.908) 3.34min
==get_scoring_result==
base_score: total=2625, TP=82, TN=2446, FP=54, FN=43; precision=0.603, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.817) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.628) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.907) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 2446, 'FP': 54, 'FN': 43, 'precision': 0.6029411764705882, 'recall': 0.656, 'accuracy': 0.963047619047619, 'average_precision': 0.6546304835562278, 'balanced_accuracy': 0.8172, 'f1': 0.6283524904214559, 'roc_auc': 0.9069488}
==getted_scoring_result==
[fit 464/850] END C=256.0, gamma=8.0, kernel=rbf; total=2625, TP=82, TN=2446, FP=54, FN=43; precision=0.603, recall=0.656
accuracy: (test=0.963) average_precision: (test=0.655) balanced_accuracy: (test=0.817) f1: (test=0.628) roc_auc: (test=0.907) 5.47min
==get_scoring_result==
base_score: total=2625, TP=80, TN=2460, FP=40, FN=45; precision=0.667, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.968) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.688) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.812) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.653) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.905) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2460, 'FP': 40, 'FN': 45, 'precision': 0.6666666666666666, 'recall': 0.64, 'accuracy': 0.9676190476190476, 'average_precision': 0.6880950543408647, 'balanced_accuracy': 0.812, 'f1': 0.6530612244897959, 'roc_auc': 0.9045408}
==getted_scoring_result==
[fit 465/850] END C=256.0, gamma=16.0, kernel=rbf; total=2625, TP=80, TN=2460, FP=40, FN=45; precision=0.667, recall=0.640
accuracy: (test=0.968) average_precision: (test=0.688) balanced_accuracy: (test=0.812) f1: (test=0.653) roc_auc: (test=0.905) 2.30min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2468, FP=32, FN=46; precision=0.712, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.810) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.669) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.905) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2468, 'FP': 32, 'FN': 46, 'precision': 0.7117117117117117, 'recall': 0.632, 'accuracy': 0.9702857142857143, 'average_precision': 0.6967619752899123, 'balanced_accuracy': 0.8096, 'f1': 0.6694915254237288, 'roc_auc': 0.9054272}
==getted_scoring_result==
[fit 466/850] END C=256.0, gamma=32.0, kernel=rbf; total=2625, TP=79, TN=2468, FP=32, FN=46; precision=0.712, recall=0.632
accuracy: (test=0.970) average_precision: (test=0.697) balanced_accuracy: (test=0.810) f1: (test=0.669) roc_auc: (test=0.905) 54.04s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.670) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2474, 'FP': 26, 'FN': 49, 'precision': 0.7450980392156863, 'recall': 0.608, 'accuracy': 0.9714285714285714, 'average_precision': 0.6967551398498117, 'balanced_accuracy': 0.7988, 'f1': 0.6696035242290749, 'roc_auc': 0.8993504}
==getted_scoring_result==
[fit 467/850] END C=256.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608
accuracy: (test=0.971) average_precision: (test=0.697) balanced_accuracy: (test=0.799) f1: (test=0.670) roc_auc: (test=0.899) 27.08s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.795) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2477, 'FP': 23, 'FN': 50, 'precision': 0.7653061224489796, 'recall': 0.6, 'accuracy': 0.9721904761904762, 'average_precision': 0.6970638985448205, 'balanced_accuracy': 0.7954, 'f1': 0.6726457399103138, 'roc_auc': 0.895408}
==getted_scoring_result==
[fit 468/850] END C=256.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600
accuracy: (test=0.972) average_precision: (test=0.697) balanced_accuracy: (test=0.795) f1: (test=0.673) roc_auc: (test=0.895) 19.07s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786539160578525, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 469/850] END C=256.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 18.38s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 470/850] END C=256.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 21.42s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 471/850] END C=256.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 25.53s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 472/850] END C=256.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 25.48s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 473/850] END C=256.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 21.65s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 474/850] END C=256.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 19.33s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 475/850] END C=256.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 15.54s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=69, TN=1501, FP=999, FN=56; precision=0.065, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.598) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.576) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.116) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.627) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1501, 'FP': 999, 'FN': 56, 'precision': 0.06460674157303371, 'recall': 0.552, 'accuracy': 0.5980952380952381, 'average_precision': 0.0747922172271911, 'balanced_accuracy': 0.5762, 'f1': 0.115674769488684, 'roc_auc': 0.6273216}
==getted_scoring_result==
[fit 476/850] END C=512.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=69, TN=1501, FP=999, FN=56; precision=0.065, recall=0.552
accuracy: (test=0.598) average_precision: (test=0.075) balanced_accuracy: (test=0.576) f1: (test=0.116) roc_auc: (test=0.627) 8.74s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1560, FP=940, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.622) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.083) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.600) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.127) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.645) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1560, 'FP': 940, 'FN': 53, 'precision': 0.07114624505928854, 'recall': 0.576, 'accuracy': 0.6217142857142857, 'average_precision': 0.08255750021373176, 'balanced_accuracy': 0.6, 'f1': 0.12664907651715038, 'roc_auc': 0.6447584}
==getted_scoring_result==
[fit 477/850] END C=512.0, gamma=0.001953125, kernel=rbf; total=2625, TP=72, TN=1560, FP=940, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.622) average_precision: (test=0.083) balanced_accuracy: (test=0.600) f1: (test=0.127) roc_auc: (test=0.645) 9.17s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1584, FP=916, FN=52; precision=0.074, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.631) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.609) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.653) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1584, 'FP': 916, 'FN': 52, 'precision': 0.07381193124368049, 'recall': 0.584, 'accuracy': 0.6312380952380953, 'average_precision': 0.08609918487963975, 'balanced_accuracy': 0.6088, 'f1': 0.13105924596050272, 'roc_auc': 0.6532288}
==getted_scoring_result==
[fit 478/850] END C=512.0, gamma=0.00390625, kernel=rbf; total=2625, TP=73, TN=1584, FP=916, FN=52; precision=0.074, recall=0.584
accuracy: (test=0.631) average_precision: (test=0.086) balanced_accuracy: (test=0.609) f1: (test=0.131) roc_auc: (test=0.653) 9.22s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1589, FP=911, FN=54; precision=0.072, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.632) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.602) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.128) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.658) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1589, 'FP': 911, 'FN': 54, 'precision': 0.07230142566191446, 'recall': 0.568, 'accuracy': 0.6323809523809524, 'average_precision': 0.08589651897190184, 'balanced_accuracy': 0.6018, 'f1': 0.1282746160794941, 'roc_auc': 0.6581648}
==getted_scoring_result==
[fit 479/850] END C=512.0, gamma=0.0078125, kernel=rbf; total=2625, TP=71, TN=1589, FP=911, FN=54; precision=0.072, recall=0.568
accuracy: (test=0.632) average_precision: (test=0.086) balanced_accuracy: (test=0.602) f1: (test=0.128) roc_auc: (test=0.658) 9.81s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1588, FP=912, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.632) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.660) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1588, 'FP': 912, 'FN': 53, 'precision': 0.07317073170731707, 'recall': 0.576, 'accuracy': 0.6323809523809524, 'average_precision': 0.08543102961461643, 'balanced_accuracy': 0.6055999999999999, 'f1': 0.12984670874661858, 'roc_auc': 0.6600432}
==getted_scoring_result==
[fit 480/850] END C=512.0, gamma=0.015625, kernel=rbf; total=2625, TP=72, TN=1588, FP=912, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.632) average_precision: (test=0.085) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.660) 10.50s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1596, FP=904, FN=51; precision=0.076, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.636) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.615) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.134) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.666) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1596, 'FP': 904, 'FN': 51, 'precision': 0.07566462167689161, 'recall': 0.592, 'accuracy': 0.6361904761904762, 'average_precision': 0.08649048116745858, 'balanced_accuracy': 0.6152, 'f1': 0.13417951042611062, 'roc_auc': 0.665816}
==getted_scoring_result==
[fit 481/850] END C=512.0, gamma=0.03125, kernel=rbf; total=2625, TP=74, TN=1596, FP=904, FN=51; precision=0.076, recall=0.592
accuracy: (test=0.636) average_precision: (test=0.086) balanced_accuracy: (test=0.615) f1: (test=0.134) roc_auc: (test=0.666) 11.91s
==get_scoring_result==
base_score: total=2625, TP=75, TN=1615, FP=885, FN=50; precision=0.078, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.644) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.090) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.623) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.138) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.676) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1615, 'FP': 885, 'FN': 50, 'precision': 0.078125, 'recall': 0.6, 'accuracy': 0.6438095238095238, 'average_precision': 0.08969056448791121, 'balanced_accuracy': 0.623, 'f1': 0.1382488479262673, 'roc_auc': 0.6764096}
==getted_scoring_result==
[fit 482/850] END C=512.0, gamma=0.0625, kernel=rbf; total=2625, TP=75, TN=1615, FP=885, FN=50; precision=0.078, recall=0.600
accuracy: (test=0.644) average_precision: (test=0.090) balanced_accuracy: (test=0.623) f1: (test=0.138) roc_auc: (test=0.676) 15.27s
==get_scoring_result==
base_score: total=2625, TP=79, TN=1659, FP=841, FN=46; precision=0.086, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.662) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.099) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.648) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.151) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.703) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 1659, 'FP': 841, 'FN': 46, 'precision': 0.08586956521739131, 'recall': 0.632, 'accuracy': 0.6620952380952381, 'average_precision': 0.09893854877276645, 'balanced_accuracy': 0.6477999999999999, 'f1': 0.15119617224880383, 'roc_auc': 0.7028544}
==getted_scoring_result==
[fit 483/850] END C=512.0, gamma=0.125, kernel=rbf; total=2625, TP=79, TN=1659, FP=841, FN=46; precision=0.086, recall=0.632
accuracy: (test=0.662) average_precision: (test=0.099) balanced_accuracy: (test=0.648) f1: (test=0.151) roc_auc: (test=0.703) 21.46s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=85, TN=1786, FP=714, FN=40; precision=0.106, recall=0.680

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.713) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.133) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.697) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.184) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.750) ===
score_result_dict: {'Total': 2625, 'TP': 85, 'TN': 1786, 'FP': 714, 'FN': 40, 'precision': 0.10638297872340426, 'recall': 0.68, 'accuracy': 0.7127619047619047, 'average_precision': 0.1334141737552002, 'balanced_accuracy': 0.6972, 'f1': 0.18398268398268397, 'roc_auc': 0.7499424}
==getted_scoring_result==
[fit 484/850] END C=512.0, gamma=0.25, kernel=rbf; total=2625, TP=85, TN=1786, FP=714, FN=40; precision=0.106, recall=0.680
accuracy: (test=0.713) average_precision: (test=0.133) balanced_accuracy: (test=0.697) f1: (test=0.184) roc_auc: (test=0.750) 34.53s
==get_scoring_result==
base_score: total=2625, TP=89, TN=1933, FP=567, FN=36; precision=0.136, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.770) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.175) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.743) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.228) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.806) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 1933, 'FP': 567, 'FN': 36, 'precision': 0.13567073170731708, 'recall': 0.712, 'accuracy': 0.7702857142857142, 'average_precision': 0.1751080912445048, 'balanced_accuracy': 0.7425999999999999, 'f1': 0.22791293213828426, 'roc_auc': 0.80556}
==getted_scoring_result==
[fit 485/850] END C=512.0, gamma=0.5, kernel=rbf; total=2625, TP=89, TN=1933, FP=567, FN=36; precision=0.136, recall=0.712
accuracy: (test=0.770) average_precision: (test=0.175) balanced_accuracy: (test=0.743) f1: (test=0.228) roc_auc: (test=0.806) 56.04s
==get_scoring_result==
base_score: total=2625, TP=94, TN=2071, FP=429, FN=31; precision=0.180, recall=0.752

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.825) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.267) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.790) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.290) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.858) ===
score_result_dict: {'Total': 2625, 'TP': 94, 'TN': 2071, 'FP': 429, 'FN': 31, 'precision': 0.17973231357552583, 'recall': 0.752, 'accuracy': 0.8247619047619048, 'average_precision': 0.267253061564245, 'balanced_accuracy': 0.7902, 'f1': 0.29012345679012347, 'roc_auc': 0.8578432}
==getted_scoring_result==
[fit 486/850] END C=512.0, gamma=1.0, kernel=rbf; total=2625, TP=94, TN=2071, FP=429, FN=31; precision=0.180, recall=0.752
accuracy: (test=0.825) average_precision: (test=0.267) balanced_accuracy: (test=0.790) f1: (test=0.290) roc_auc: (test=0.858) 1.76min
==get_scoring_result==
base_score: total=2625, TP=91, TN=2258, FP=242, FN=34; precision=0.273, recall=0.728

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.895) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.415) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.816) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.397) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.893) ===
score_result_dict: {'Total': 2625, 'TP': 91, 'TN': 2258, 'FP': 242, 'FN': 34, 'precision': 0.2732732732732733, 'recall': 0.728, 'accuracy': 0.8948571428571429, 'average_precision': 0.41486146109169286, 'balanced_accuracy': 0.8156, 'f1': 0.39737991266375544, 'roc_auc': 0.8930208}
==getted_scoring_result==
[fit 487/850] END C=512.0, gamma=2.0, kernel=rbf; total=2625, TP=91, TN=2258, FP=242, FN=34; precision=0.273, recall=0.728
accuracy: (test=0.895) average_precision: (test=0.415) balanced_accuracy: (test=0.816) f1: (test=0.397) roc_auc: (test=0.893) 4.68min
==get_scoring_result==
base_score: total=2625, TP=86, TN=2384, FP=116, FN=39; precision=0.426, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.941) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.554) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.821) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.526) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.904) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 2384, 'FP': 116, 'FN': 39, 'precision': 0.42574257425742573, 'recall': 0.688, 'accuracy': 0.940952380952381, 'average_precision': 0.5538277893449354, 'balanced_accuracy': 0.8208, 'f1': 0.5259938837920489, 'roc_auc': 0.9036416}
==getted_scoring_result==
[fit 488/850] END C=512.0, gamma=4.0, kernel=rbf; total=2625, TP=86, TN=2384, FP=116, FN=39; precision=0.426, recall=0.688
accuracy: (test=0.941) average_precision: (test=0.554) balanced_accuracy: (test=0.821) f1: (test=0.526) roc_auc: (test=0.904) 15.81min
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=82, TN=2435, FP=65, FN=43; precision=0.558, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.650) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.815) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.603) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.907) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 2435, 'FP': 65, 'FN': 43, 'precision': 0.5578231292517006, 'recall': 0.656, 'accuracy': 0.9588571428571429, 'average_precision': 0.6498976638746266, 'balanced_accuracy': 0.815, 'f1': 0.6029411764705883, 'roc_auc': 0.9070784}
==getted_scoring_result==
[fit 489/850] END C=512.0, gamma=8.0, kernel=rbf; total=2625, TP=82, TN=2435, FP=65, FN=43; precision=0.558, recall=0.656
accuracy: (test=0.959) average_precision: (test=0.650) balanced_accuracy: (test=0.815) f1: (test=0.603) roc_auc: (test=0.907) 15.82min
==get_scoring_result==
base_score: total=2625, TP=81, TN=2461, FP=39, FN=44; precision=0.675, recall=0.648

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.968) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.687) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.816) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.661) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.904) ===
score_result_dict: {'Total': 2625, 'TP': 81, 'TN': 2461, 'FP': 39, 'FN': 44, 'precision': 0.675, 'recall': 0.648, 'accuracy': 0.9683809523809523, 'average_precision': 0.6865099722644268, 'balanced_accuracy': 0.8162, 'f1': 0.6612244897959185, 'roc_auc': 0.9041152}
==getted_scoring_result==
[fit 490/850] END C=512.0, gamma=16.0, kernel=rbf; total=2625, TP=81, TN=2461, FP=39, FN=44; precision=0.675, recall=0.648
accuracy: (test=0.968) average_precision: (test=0.687) balanced_accuracy: (test=0.816) f1: (test=0.661) roc_auc: (test=0.904) 2.33min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2467, FP=33, FN=46; precision=0.705, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.696) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.809) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.667) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.906) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2467, 'FP': 33, 'FN': 46, 'precision': 0.7053571428571429, 'recall': 0.632, 'accuracy': 0.9699047619047619, 'average_precision': 0.6958134940264806, 'balanced_accuracy': 0.8094, 'f1': 0.6666666666666667, 'roc_auc': 0.9058592}
==getted_scoring_result==
[fit 491/850] END C=512.0, gamma=32.0, kernel=rbf; total=2625, TP=79, TN=2467, FP=33, FN=46; precision=0.705, recall=0.632
accuracy: (test=0.970) average_precision: (test=0.696) balanced_accuracy: (test=0.809) f1: (test=0.667) roc_auc: (test=0.906) 54.38s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.670) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2474, 'FP': 26, 'FN': 49, 'precision': 0.7450980392156863, 'recall': 0.608, 'accuracy': 0.9714285714285714, 'average_precision': 0.6967551398498117, 'balanced_accuracy': 0.7988, 'f1': 0.6696035242290749, 'roc_auc': 0.8993504}
==getted_scoring_result==
[fit 492/850] END C=512.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608
accuracy: (test=0.971) average_precision: (test=0.697) balanced_accuracy: (test=0.799) f1: (test=0.670) roc_auc: (test=0.899) 27.08s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.795) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2477, 'FP': 23, 'FN': 50, 'precision': 0.7653061224489796, 'recall': 0.6, 'accuracy': 0.9721904761904762, 'average_precision': 0.6970638985448205, 'balanced_accuracy': 0.7954, 'f1': 0.6726457399103138, 'roc_auc': 0.895408}
==getted_scoring_result==
[fit 493/850] END C=512.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600
accuracy: (test=0.972) average_precision: (test=0.697) balanced_accuracy: (test=0.795) f1: (test=0.673) roc_auc: (test=0.895) 19.06s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786539160578525, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 494/850] END C=512.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 18.39s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 495/850] END C=512.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 21.43s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 496/850] END C=512.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 25.52s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 497/850] END C=512.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 25.48s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 498/850] END C=512.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 21.61s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 499/850] END C=512.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 19.28s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 500/850] END C=512.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 15.49s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1560, FP=940, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.622) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.082) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.600) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.127) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.645) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1560, 'FP': 940, 'FN': 53, 'precision': 0.07114624505928854, 'recall': 0.576, 'accuracy': 0.6217142857142857, 'average_precision': 0.08247435779451581, 'balanced_accuracy': 0.6, 'f1': 0.12664907651715038, 'roc_auc': 0.6446176}
==getted_scoring_result==
[fit 501/850] END C=1024.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=72, TN=1560, FP=940, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.622) average_precision: (test=0.082) balanced_accuracy: (test=0.600) f1: (test=0.127) roc_auc: (test=0.645) 9.01s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1585, FP=915, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.631) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.605) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.129) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.653) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1585, 'FP': 915, 'FN': 53, 'precision': 0.0729483282674772, 'recall': 0.576, 'accuracy': 0.6312380952380953, 'average_precision': 0.08588057797583813, 'balanced_accuracy': 0.605, 'f1': 0.12949640287769784, 'roc_auc': 0.6533744}
==getted_scoring_result==
[fit 502/850] END C=1024.0, gamma=0.001953125, kernel=rbf; total=2625, TP=72, TN=1585, FP=915, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.631) average_precision: (test=0.086) balanced_accuracy: (test=0.605) f1: (test=0.129) roc_auc: (test=0.653) 9.29s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1586, FP=914, FN=54; precision=0.072, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.631) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.601) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.128) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.657) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1586, 'FP': 914, 'FN': 54, 'precision': 0.07208121827411168, 'recall': 0.568, 'accuracy': 0.6312380952380953, 'average_precision': 0.08577705453812481, 'balanced_accuracy': 0.6012, 'f1': 0.12792792792792793, 'roc_auc': 0.6573696}
==getted_scoring_result==
[fit 503/850] END C=1024.0, gamma=0.00390625, kernel=rbf; total=2625, TP=71, TN=1586, FP=914, FN=54; precision=0.072, recall=0.568
accuracy: (test=0.631) average_precision: (test=0.086) balanced_accuracy: (test=0.601) f1: (test=0.128) roc_auc: (test=0.657) 9.73s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1589, FP=911, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.633) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.660) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1589, 'FP': 911, 'FN': 53, 'precision': 0.07324516785350967, 'recall': 0.576, 'accuracy': 0.6327619047619047, 'average_precision': 0.08507061568080376, 'balanced_accuracy': 0.6058, 'f1': 0.12996389891696752, 'roc_auc': 0.6596928}
==getted_scoring_result==
[fit 504/850] END C=1024.0, gamma=0.0078125, kernel=rbf; total=2625, TP=72, TN=1589, FP=911, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.633) average_precision: (test=0.085) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.660) 10.35s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1595, FP=905, FN=51; precision=0.076, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.636) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.615) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.134) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.663) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1595, 'FP': 905, 'FN': 51, 'precision': 0.0755873340143003, 'recall': 0.592, 'accuracy': 0.6358095238095238, 'average_precision': 0.08593645780294881, 'balanced_accuracy': 0.615, 'f1': 0.13405797101449277, 'roc_auc': 0.6628096}
==getted_scoring_result==
[fit 505/850] END C=1024.0, gamma=0.015625, kernel=rbf; total=2625, TP=74, TN=1595, FP=905, FN=51; precision=0.076, recall=0.592
accuracy: (test=0.636) average_precision: (test=0.086) balanced_accuracy: (test=0.615) f1: (test=0.134) roc_auc: (test=0.663) 12.07s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1595, FP=905, FN=51; precision=0.076, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.636) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.088) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.615) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.134) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.669) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1595, 'FP': 905, 'FN': 51, 'precision': 0.0755873340143003, 'recall': 0.592, 'accuracy': 0.6358095238095238, 'average_precision': 0.08761086016231952, 'balanced_accuracy': 0.615, 'f1': 0.13405797101449277, 'roc_auc': 0.669336}
==getted_scoring_result==
[fit 506/850] END C=1024.0, gamma=0.03125, kernel=rbf; total=2625, TP=74, TN=1595, FP=905, FN=51; precision=0.076, recall=0.592
accuracy: (test=0.636) average_precision: (test=0.088) balanced_accuracy: (test=0.615) f1: (test=0.134) roc_auc: (test=0.669) 15.33s
==get_scoring_result==
base_score: total=2625, TP=75, TN=1631, FP=869, FN=50; precision=0.079, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.650) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.093) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.626) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.140) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.687) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1631, 'FP': 869, 'FN': 50, 'precision': 0.07944915254237288, 'recall': 0.6, 'accuracy': 0.6499047619047619, 'average_precision': 0.09311293397890873, 'balanced_accuracy': 0.6262, 'f1': 0.14031805425631433, 'roc_auc': 0.6874496}
==getted_scoring_result==
[fit 507/850] END C=1024.0, gamma=0.0625, kernel=rbf; total=2625, TP=75, TN=1631, FP=869, FN=50; precision=0.079, recall=0.600
accuracy: (test=0.650) average_precision: (test=0.093) balanced_accuracy: (test=0.626) f1: (test=0.140) roc_auc: (test=0.687) 21.72s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=83, TN=1737, FP=763, FN=42; precision=0.098, recall=0.664

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.693) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.111) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.679) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.171) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.726) ===
score_result_dict: {'Total': 2625, 'TP': 83, 'TN': 1737, 'FP': 763, 'FN': 42, 'precision': 0.09810874704491726, 'recall': 0.664, 'accuracy': 0.6933333333333334, 'average_precision': 0.11116997421357085, 'balanced_accuracy': 0.6794, 'f1': 0.1709577754891864, 'roc_auc': 0.7256096}
==getted_scoring_result==
[fit 508/850] END C=1024.0, gamma=0.125, kernel=rbf; total=2625, TP=83, TN=1737, FP=763, FN=42; precision=0.098, recall=0.664
accuracy: (test=0.693) average_precision: (test=0.111) balanced_accuracy: (test=0.679) f1: (test=0.171) roc_auc: (test=0.726) 34.60s
==get_scoring_result==
base_score: total=2625, TP=86, TN=1850, FP=650, FN=39; precision=0.117, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.738) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.151) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.714) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.200) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.773) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 1850, 'FP': 650, 'FN': 39, 'precision': 0.11684782608695653, 'recall': 0.688, 'accuracy': 0.7375238095238095, 'average_precision': 0.15099275549345098, 'balanced_accuracy': 0.714, 'f1': 0.1997677119628339, 'roc_auc': 0.773488}
==getted_scoring_result==
[fit 509/850] END C=1024.0, gamma=0.25, kernel=rbf; total=2625, TP=86, TN=1850, FP=650, FN=39; precision=0.117, recall=0.688
accuracy: (test=0.738) average_precision: (test=0.151) balanced_accuracy: (test=0.714) f1: (test=0.200) roc_auc: (test=0.773) 58.86s
==get_scoring_result==
base_score: total=2625, TP=91, TN=1989, FP=511, FN=34; precision=0.151, recall=0.728

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.792) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.204) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.762) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.250) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.830) ===
score_result_dict: {'Total': 2625, 'TP': 91, 'TN': 1989, 'FP': 511, 'FN': 34, 'precision': 0.1511627906976744, 'recall': 0.728, 'accuracy': 0.7923809523809524, 'average_precision': 0.20353604802960554, 'balanced_accuracy': 0.7618, 'f1': 0.2503438789546079, 'roc_auc': 0.8299408}
==getted_scoring_result==
[fit 510/850] END C=1024.0, gamma=0.5, kernel=rbf; total=2625, TP=91, TN=1989, FP=511, FN=34; precision=0.151, recall=0.728
accuracy: (test=0.792) average_precision: (test=0.204) balanced_accuracy: (test=0.762) f1: (test=0.250) roc_auc: (test=0.830) 1.73min
==get_scoring_result==
base_score: total=2625, TP=91, TN=2146, FP=354, FN=34; precision=0.204, recall=0.728

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.852) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.316) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.793) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.319) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.872) ===
score_result_dict: {'Total': 2625, 'TP': 91, 'TN': 2146, 'FP': 354, 'FN': 34, 'precision': 0.20449438202247192, 'recall': 0.728, 'accuracy': 0.8521904761904762, 'average_precision': 0.31647371546129943, 'balanced_accuracy': 0.7932, 'f1': 0.3192982456140351, 'roc_auc': 0.8720768}
==getted_scoring_result==
[fit 511/850] END C=1024.0, gamma=1.0, kernel=rbf; total=2625, TP=91, TN=2146, FP=354, FN=34; precision=0.204, recall=0.728
accuracy: (test=0.852) average_precision: (test=0.316) balanced_accuracy: (test=0.793) f1: (test=0.319) roc_auc: (test=0.872) 4.63min
==get_scoring_result==
base_score: total=2625, TP=91, TN=2255, FP=245, FN=34; precision=0.271, recall=0.728

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.894) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.422) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.815) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.395) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.890) ===
score_result_dict: {'Total': 2625, 'TP': 91, 'TN': 2255, 'FP': 245, 'FN': 34, 'precision': 0.2708333333333333, 'recall': 0.728, 'accuracy': 0.8937142857142857, 'average_precision': 0.4222358605073309, 'balanced_accuracy': 0.815, 'f1': 0.39479392624728854, 'roc_auc': 0.8903904}
==getted_scoring_result==
[fit 512/850] END C=1024.0, gamma=2.0, kernel=rbf; total=2625, TP=91, TN=2255, FP=245, FN=34; precision=0.271, recall=0.728
accuracy: (test=0.894) average_precision: (test=0.422) balanced_accuracy: (test=0.815) f1: (test=0.395) roc_auc: (test=0.890) 14.94min
==get_scoring_result==
base_score: total=2625, TP=87, TN=2367, FP=133, FN=38; precision=0.395, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.935) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.545) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.821) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.504) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 2367, 'FP': 133, 'FN': 38, 'precision': 0.39545454545454545, 'recall': 0.696, 'accuracy': 0.9348571428571428, 'average_precision': 0.5446143956678753, 'balanced_accuracy': 0.8213999999999999, 'f1': 0.5043478260869565, 'roc_auc': 0.8985856}
==getted_scoring_result==
[fit 513/850] END C=1024.0, gamma=4.0, kernel=rbf; total=2625, TP=87, TN=2367, FP=133, FN=38; precision=0.395, recall=0.696
accuracy: (test=0.935) average_precision: (test=0.545) balanced_accuracy: (test=0.821) f1: (test=0.504) roc_auc: (test=0.899) 10.00min
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=81, TN=2438, FP=62, FN=44; precision=0.566, recall=0.648

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.960) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.643) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.812) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.604) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.906) ===
score_result_dict: {'Total': 2625, 'TP': 81, 'TN': 2438, 'FP': 62, 'FN': 44, 'precision': 0.5664335664335665, 'recall': 0.648, 'accuracy': 0.9596190476190476, 'average_precision': 0.6427283477740303, 'balanced_accuracy': 0.8116, 'f1': 0.6044776119402986, 'roc_auc': 0.9056352}
==getted_scoring_result==
[fit 514/850] END C=1024.0, gamma=8.0, kernel=rbf; total=2625, TP=81, TN=2438, FP=62, FN=44; precision=0.566, recall=0.648
accuracy: (test=0.960) average_precision: (test=0.643) balanced_accuracy: (test=0.812) f1: (test=0.604) roc_auc: (test=0.906) 12.93min
==get_scoring_result==
base_score: total=2625, TP=80, TN=2462, FP=38, FN=45; precision=0.678, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.968) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.683) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.812) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.658) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.906) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2462, 'FP': 38, 'FN': 45, 'precision': 0.6779661016949152, 'recall': 0.64, 'accuracy': 0.9683809523809523, 'average_precision': 0.6833958314473422, 'balanced_accuracy': 0.8124, 'f1': 0.6584362139917694, 'roc_auc': 0.9056544}
==getted_scoring_result==
[fit 515/850] END C=1024.0, gamma=16.0, kernel=rbf; total=2625, TP=80, TN=2462, FP=38, FN=45; precision=0.678, recall=0.640
accuracy: (test=0.968) average_precision: (test=0.683) balanced_accuracy: (test=0.812) f1: (test=0.658) roc_auc: (test=0.906) 2.35min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2466, FP=34, FN=46; precision=0.699, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.695) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.809) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.664) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.905) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2466, 'FP': 34, 'FN': 46, 'precision': 0.6991150442477876, 'recall': 0.632, 'accuracy': 0.9695238095238096, 'average_precision': 0.6949966900062938, 'balanced_accuracy': 0.8092, 'f1': 0.6638655462184874, 'roc_auc': 0.9054016}
==getted_scoring_result==
[fit 516/850] END C=1024.0, gamma=32.0, kernel=rbf; total=2625, TP=79, TN=2466, FP=34, FN=46; precision=0.699, recall=0.632
accuracy: (test=0.970) average_precision: (test=0.695) balanced_accuracy: (test=0.809) f1: (test=0.664) roc_auc: (test=0.905) 54.69s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.670) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2474, 'FP': 26, 'FN': 49, 'precision': 0.7450980392156863, 'recall': 0.608, 'accuracy': 0.9714285714285714, 'average_precision': 0.6967551398498117, 'balanced_accuracy': 0.7988, 'f1': 0.6696035242290749, 'roc_auc': 0.8993504}
==getted_scoring_result==
[fit 517/850] END C=1024.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608
accuracy: (test=0.971) average_precision: (test=0.697) balanced_accuracy: (test=0.799) f1: (test=0.670) roc_auc: (test=0.899) 27.06s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.795) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2477, 'FP': 23, 'FN': 50, 'precision': 0.7653061224489796, 'recall': 0.6, 'accuracy': 0.9721904761904762, 'average_precision': 0.6970638985448205, 'balanced_accuracy': 0.7954, 'f1': 0.6726457399103138, 'roc_auc': 0.895408}
==getted_scoring_result==
[fit 518/850] END C=1024.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600
accuracy: (test=0.972) average_precision: (test=0.697) balanced_accuracy: (test=0.795) f1: (test=0.673) roc_auc: (test=0.895) 19.15s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786539160578525, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 519/850] END C=1024.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 18.45s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 520/850] END C=1024.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 21.54s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 521/850] END C=1024.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 25.59s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 522/850] END C=1024.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 25.62s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 523/850] END C=1024.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 21.68s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 524/850] END C=1024.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 19.39s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 525/850] END C=1024.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 16.17s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1580, FP=920, FN=52; precision=0.074, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.630) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.608) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.654) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1580, 'FP': 920, 'FN': 52, 'precision': 0.07351460221550855, 'recall': 0.584, 'accuracy': 0.6297142857142857, 'average_precision': 0.08585644031018153, 'balanced_accuracy': 0.608, 'f1': 0.13059033989266547, 'roc_auc': 0.6535328}
==getted_scoring_result==
[fit 526/850] END C=2048.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=73, TN=1580, FP=920, FN=52; precision=0.074, recall=0.584
accuracy: (test=0.630) average_precision: (test=0.086) balanced_accuracy: (test=0.608) f1: (test=0.131) roc_auc: (test=0.654) 10.04s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1588, FP=912, FN=54; precision=0.072, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.632) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.602) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.128) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.657) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1588, 'FP': 912, 'FN': 54, 'precision': 0.07222787385554426, 'recall': 0.568, 'accuracy': 0.632, 'average_precision': 0.08579941684807711, 'balanced_accuracy': 0.6015999999999999, 'f1': 0.12815884476534295, 'roc_auc': 0.6568768}
==getted_scoring_result==
[fit 527/850] END C=2048.0, gamma=0.001953125, kernel=rbf; total=2625, TP=71, TN=1588, FP=912, FN=54; precision=0.072, recall=0.568
accuracy: (test=0.632) average_precision: (test=0.086) balanced_accuracy: (test=0.602) f1: (test=0.128) roc_auc: (test=0.657) 10.09s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1591, FP=909, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.634) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.658) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1591, 'FP': 909, 'FN': 53, 'precision': 0.07339449541284404, 'recall': 0.576, 'accuracy': 0.6335238095238095, 'average_precision': 0.08480249523542815, 'balanced_accuracy': 0.6062, 'f1': 0.1301989150090416, 'roc_auc': 0.6581568}
==getted_scoring_result==
[fit 528/850] END C=2048.0, gamma=0.00390625, kernel=rbf; total=2625, TP=72, TN=1591, FP=909, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.634) average_precision: (test=0.085) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.658) 11.25s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1592, FP=908, FN=51; precision=0.075, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.635) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.614) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.134) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.662) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1592, 'FP': 908, 'FN': 51, 'precision': 0.07535641547861507, 'recall': 0.592, 'accuracy': 0.6346666666666667, 'average_precision': 0.08495373029454252, 'balanced_accuracy': 0.6144000000000001, 'f1': 0.13369467028003615, 'roc_auc': 0.6615168}
==getted_scoring_result==
[fit 529/850] END C=2048.0, gamma=0.0078125, kernel=rbf; total=2625, TP=74, TN=1592, FP=908, FN=51; precision=0.075, recall=0.592
accuracy: (test=0.635) average_precision: (test=0.085) balanced_accuracy: (test=0.614) f1: (test=0.134) roc_auc: (test=0.662) 13.04s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1590, FP=910, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.633) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.664) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1590, 'FP': 910, 'FN': 53, 'precision': 0.07331975560081466, 'recall': 0.576, 'accuracy': 0.6331428571428571, 'average_precision': 0.0861614608581219, 'balanced_accuracy': 0.606, 'f1': 0.13008130081300814, 'roc_auc': 0.6640896}
==getted_scoring_result==
[fit 530/850] END C=2048.0, gamma=0.015625, kernel=rbf; total=2625, TP=72, TN=1590, FP=910, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.633) average_precision: (test=0.086) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.664) 17.15s
==get_scoring_result==
base_score: total=2625, TP=75, TN=1610, FP=890, FN=50; precision=0.078, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.642) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.089) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.622) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.138) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.677) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1610, 'FP': 890, 'FN': 50, 'precision': 0.07772020725388601, 'recall': 0.6, 'accuracy': 0.6419047619047619, 'average_precision': 0.08921846799972931, 'balanced_accuracy': 0.622, 'f1': 0.13761467889908258, 'roc_auc': 0.6765376}
==getted_scoring_result==
[fit 531/850] END C=2048.0, gamma=0.03125, kernel=rbf; total=2625, TP=75, TN=1610, FP=890, FN=50; precision=0.078, recall=0.600
accuracy: (test=0.642) average_precision: (test=0.089) balanced_accuracy: (test=0.622) f1: (test=0.138) roc_auc: (test=0.677) 23.37s
==get_scoring_result==
base_score: total=2625, TP=79, TN=1658, FP=842, FN=46; precision=0.086, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.662) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.099) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.648) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.151) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.703) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 1658, 'FP': 842, 'FN': 46, 'precision': 0.08577633007600434, 'recall': 0.632, 'accuracy': 0.6617142857142857, 'average_precision': 0.09873644958635264, 'balanced_accuracy': 0.6476, 'f1': 0.15105162523900573, 'roc_auc': 0.7034624}
==getted_scoring_result==
[fit 532/850] END C=2048.0, gamma=0.0625, kernel=rbf; total=2625, TP=79, TN=1658, FP=842, FN=46; precision=0.086, recall=0.632
accuracy: (test=0.662) average_precision: (test=0.099) balanced_accuracy: (test=0.648) f1: (test=0.151) roc_auc: (test=0.703) 35.22s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=85, TN=1786, FP=714, FN=40; precision=0.106, recall=0.680

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.713) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.131) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.697) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.184) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.750) ===
score_result_dict: {'Total': 2625, 'TP': 85, 'TN': 1786, 'FP': 714, 'FN': 40, 'precision': 0.10638297872340426, 'recall': 0.68, 'accuracy': 0.7127619047619047, 'average_precision': 0.13132426661579766, 'balanced_accuracy': 0.6972, 'f1': 0.18398268398268397, 'roc_auc': 0.749504}
==getted_scoring_result==
[fit 533/850] END C=2048.0, gamma=0.125, kernel=rbf; total=2625, TP=85, TN=1786, FP=714, FN=40; precision=0.106, recall=0.680
accuracy: (test=0.713) average_precision: (test=0.131) balanced_accuracy: (test=0.697) f1: (test=0.184) roc_auc: (test=0.750) 1.02min
==get_scoring_result==
base_score: total=2625, TP=90, TN=1928, FP=572, FN=35; precision=0.136, recall=0.720

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.769) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.173) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.746) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.229) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.803) ===
score_result_dict: {'Total': 2625, 'TP': 90, 'TN': 1928, 'FP': 572, 'FN': 35, 'precision': 0.13595166163141995, 'recall': 0.72, 'accuracy': 0.7687619047619048, 'average_precision': 0.17316217063391495, 'balanced_accuracy': 0.7456, 'f1': 0.2287166454891995, 'roc_auc': 0.8028512}
==getted_scoring_result==
[fit 534/850] END C=2048.0, gamma=0.25, kernel=rbf; total=2625, TP=90, TN=1928, FP=572, FN=35; precision=0.136, recall=0.720
accuracy: (test=0.769) average_precision: (test=0.173) balanced_accuracy: (test=0.746) f1: (test=0.229) roc_auc: (test=0.803) 1.78min
==get_scoring_result==
base_score: total=2625, TP=95, TN=2047, FP=453, FN=30; precision=0.173, recall=0.760

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.816) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.247) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.789) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.282) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.850) ===
score_result_dict: {'Total': 2625, 'TP': 95, 'TN': 2047, 'FP': 453, 'FN': 30, 'precision': 0.17335766423357665, 'recall': 0.76, 'accuracy': 0.816, 'average_precision': 0.24747112424282522, 'balanced_accuracy': 0.7894, 'f1': 0.2823179791976226, 'roc_auc': 0.8501296}
==getted_scoring_result==
[fit 535/850] END C=2048.0, gamma=0.5, kernel=rbf; total=2625, TP=95, TN=2047, FP=453, FN=30; precision=0.173, recall=0.760
accuracy: (test=0.816) average_precision: (test=0.247) balanced_accuracy: (test=0.789) f1: (test=0.282) roc_auc: (test=0.850) 3.67min
==get_scoring_result==
base_score: total=2625, TP=88, TN=2131, FP=369, FN=37; precision=0.193, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.845) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.320) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.778) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.302) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.860) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 2131, 'FP': 369, 'FN': 37, 'precision': 0.1925601750547046, 'recall': 0.704, 'accuracy': 0.8453333333333334, 'average_precision': 0.3203979280839138, 'balanced_accuracy': 0.7782, 'f1': 0.302405498281787, 'roc_auc': 0.8599264}
==getted_scoring_result==
[fit 536/850] END C=2048.0, gamma=1.0, kernel=rbf; total=2625, TP=88, TN=2131, FP=369, FN=37; precision=0.193, recall=0.704
accuracy: (test=0.845) average_precision: (test=0.320) balanced_accuracy: (test=0.778) f1: (test=0.302) roc_auc: (test=0.860) 11.98min
==get_scoring_result==
base_score: total=2625, TP=94, TN=2191, FP=309, FN=31; precision=0.233, recall=0.752

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.870) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.382) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.814) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.356) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.878) ===
score_result_dict: {'Total': 2625, 'TP': 94, 'TN': 2191, 'FP': 309, 'FN': 31, 'precision': 0.23325062034739455, 'recall': 0.752, 'accuracy': 0.8704761904761905, 'average_precision': 0.38165756410186563, 'balanced_accuracy': 0.8142, 'f1': 0.3560606060606061, 'roc_auc': 0.8780848}
==getted_scoring_result==
[fit 537/850] END C=2048.0, gamma=2.0, kernel=rbf; total=2625, TP=94, TN=2191, FP=309, FN=31; precision=0.233, recall=0.752
accuracy: (test=0.870) average_precision: (test=0.382) balanced_accuracy: (test=0.814) f1: (test=0.356) roc_auc: (test=0.878) 9.73min
==get_scoring_result==
base_score: total=2625, TP=86, TN=2319, FP=181, FN=39; precision=0.322, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.916) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.505) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.808) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.439) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.897) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 2319, 'FP': 181, 'FN': 39, 'precision': 0.32209737827715357, 'recall': 0.688, 'accuracy': 0.9161904761904762, 'average_precision': 0.5049184431845877, 'balanced_accuracy': 0.8078, 'f1': 0.43877551020408156, 'roc_auc': 0.8966848}
==getted_scoring_result==
[fit 538/850] END C=2048.0, gamma=4.0, kernel=rbf; total=2625, TP=86, TN=2319, FP=181, FN=39; precision=0.322, recall=0.688
accuracy: (test=0.916) average_precision: (test=0.505) balanced_accuracy: (test=0.808) f1: (test=0.439) roc_auc: (test=0.897) 13.96min
==get_scoring_result==
base_score: total=2625, TP=80, TN=2438, FP=62, FN=45; precision=0.563, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.634) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.808) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.599) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.903) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2438, 'FP': 62, 'FN': 45, 'precision': 0.5633802816901409, 'recall': 0.64, 'accuracy': 0.9592380952380952, 'average_precision': 0.6336936185885252, 'balanced_accuracy': 0.8076, 'f1': 0.599250936329588, 'roc_auc': 0.902736}
==getted_scoring_result==
[fit 539/850] END C=2048.0, gamma=8.0, kernel=rbf; total=2625, TP=80, TN=2438, FP=62, FN=45; precision=0.563, recall=0.640
accuracy: (test=0.959) average_precision: (test=0.634) balanced_accuracy: (test=0.808) f1: (test=0.599) roc_auc: (test=0.903) 12.22min
==get_scoring_result==
base_score: total=2625, TP=80, TN=2460, FP=40, FN=45; precision=0.667, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.968) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.682) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.812) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.653) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.906) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2460, 'FP': 40, 'FN': 45, 'precision': 0.6666666666666666, 'recall': 0.64, 'accuracy': 0.9676190476190476, 'average_precision': 0.6822960182960814, 'balanced_accuracy': 0.812, 'f1': 0.6530612244897959, 'roc_auc': 0.9063936}
==getted_scoring_result==
[fit 540/850] END C=2048.0, gamma=16.0, kernel=rbf; total=2625, TP=80, TN=2460, FP=40, FN=45; precision=0.667, recall=0.640
accuracy: (test=0.968) average_precision: (test=0.682) balanced_accuracy: (test=0.812) f1: (test=0.653) roc_auc: (test=0.906) 2.40min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2466, FP=34, FN=46; precision=0.699, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.695) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.809) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.664) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.905) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2466, 'FP': 34, 'FN': 46, 'precision': 0.6991150442477876, 'recall': 0.632, 'accuracy': 0.9695238095238096, 'average_precision': 0.6949966900062938, 'balanced_accuracy': 0.8092, 'f1': 0.6638655462184874, 'roc_auc': 0.9054016}
==getted_scoring_result==
[fit 541/850] END C=2048.0, gamma=32.0, kernel=rbf; total=2625, TP=79, TN=2466, FP=34, FN=46; precision=0.699, recall=0.632
accuracy: (test=0.970) average_precision: (test=0.695) balanced_accuracy: (test=0.809) f1: (test=0.664) roc_auc: (test=0.905) 56.86s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.670) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2474, 'FP': 26, 'FN': 49, 'precision': 0.7450980392156863, 'recall': 0.608, 'accuracy': 0.9714285714285714, 'average_precision': 0.6967551398498117, 'balanced_accuracy': 0.7988, 'f1': 0.6696035242290749, 'roc_auc': 0.8993504}
==getted_scoring_result==
[fit 542/850] END C=2048.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608
accuracy: (test=0.971) average_precision: (test=0.697) balanced_accuracy: (test=0.799) f1: (test=0.670) roc_auc: (test=0.899) 28.70s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.795) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2477, 'FP': 23, 'FN': 50, 'precision': 0.7653061224489796, 'recall': 0.6, 'accuracy': 0.9721904761904762, 'average_precision': 0.6970638985448205, 'balanced_accuracy': 0.7954, 'f1': 0.6726457399103138, 'roc_auc': 0.895408}
==getted_scoring_result==
[fit 543/850] END C=2048.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600
accuracy: (test=0.972) average_precision: (test=0.697) balanced_accuracy: (test=0.795) f1: (test=0.673) roc_auc: (test=0.895) 20.60s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786539160578525, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 544/850] END C=2048.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 20.72s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 545/850] END C=2048.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 23.41s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 546/850] END C=2048.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 27.20s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 547/850] END C=2048.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 28.12s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 548/850] END C=2048.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 24.79s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 549/850] END C=2048.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 22.27s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 550/850] END C=2048.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 18.70s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1591, FP=909, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.634) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.658) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1591, 'FP': 909, 'FN': 53, 'precision': 0.07339449541284404, 'recall': 0.576, 'accuracy': 0.6335238095238095, 'average_precision': 0.08577270859618258, 'balanced_accuracy': 0.6062, 'f1': 0.1301989150090416, 'roc_auc': 0.6581872}
==getted_scoring_result==
[fit 551/850] END C=4096.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=72, TN=1591, FP=909, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.634) average_precision: (test=0.086) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.658) 12.62s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1588, FP=912, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.632) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.658) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1588, 'FP': 912, 'FN': 53, 'precision': 0.07317073170731707, 'recall': 0.576, 'accuracy': 0.6323809523809524, 'average_precision': 0.0845660265157828, 'balanced_accuracy': 0.6055999999999999, 'f1': 0.12984670874661858, 'roc_auc': 0.658096}
==getted_scoring_result==
[fit 552/850] END C=4096.0, gamma=0.001953125, kernel=rbf; total=2625, TP=72, TN=1588, FP=912, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.632) average_precision: (test=0.085) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.658) 12.85s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1590, FP=910, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.633) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.659) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1590, 'FP': 910, 'FN': 53, 'precision': 0.07331975560081466, 'recall': 0.576, 'accuracy': 0.6331428571428571, 'average_precision': 0.08468556768264116, 'balanced_accuracy': 0.606, 'f1': 0.13008130081300814, 'roc_auc': 0.6593168}
==getted_scoring_result==
[fit 553/850] END C=4096.0, gamma=0.00390625, kernel=rbf; total=2625, TP=72, TN=1590, FP=910, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.633) average_precision: (test=0.085) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.659) 14.54s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1595, FP=905, FN=51; precision=0.076, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.636) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.615) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.134) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.663) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1595, 'FP': 905, 'FN': 51, 'precision': 0.0755873340143003, 'recall': 0.592, 'accuracy': 0.6358095238095238, 'average_precision': 0.08521608539632122, 'balanced_accuracy': 0.615, 'f1': 0.13405797101449277, 'roc_auc': 0.663248}
==getted_scoring_result==
[fit 554/850] END C=4096.0, gamma=0.0078125, kernel=rbf; total=2625, TP=74, TN=1595, FP=905, FN=51; precision=0.076, recall=0.592
accuracy: (test=0.636) average_precision: (test=0.085) balanced_accuracy: (test=0.615) f1: (test=0.134) roc_auc: (test=0.663) 18.06s
==get_scoring_result==
base_score: total=2625, TP=75, TN=1596, FP=904, FN=50; precision=0.077, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.637) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.088) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.619) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.136) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.669) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1596, 'FP': 904, 'FN': 50, 'precision': 0.07660878447395301, 'recall': 0.6, 'accuracy': 0.6365714285714286, 'average_precision': 0.08785215358857898, 'balanced_accuracy': 0.6192, 'f1': 0.1358695652173913, 'roc_auc': 0.6687136}
==getted_scoring_result==
[fit 555/850] END C=4096.0, gamma=0.015625, kernel=rbf; total=2625, TP=75, TN=1596, FP=904, FN=50; precision=0.077, recall=0.600
accuracy: (test=0.637) average_precision: (test=0.088) balanced_accuracy: (test=0.619) f1: (test=0.136) roc_auc: (test=0.669) 24.91s
==get_scoring_result==
base_score: total=2625, TP=75, TN=1627, FP=873, FN=50; precision=0.079, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.648) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.093) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.625) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.140) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.689) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1627, 'FP': 873, 'FN': 50, 'precision': 0.07911392405063292, 'recall': 0.6, 'accuracy': 0.6483809523809524, 'average_precision': 0.09296883265376721, 'balanced_accuracy': 0.6254, 'f1': 0.1397949673811743, 'roc_auc': 0.6887488}
==getted_scoring_result==
[fit 556/850] END C=4096.0, gamma=0.03125, kernel=rbf; total=2625, TP=75, TN=1627, FP=873, FN=50; precision=0.079, recall=0.600
accuracy: (test=0.648) average_precision: (test=0.093) balanced_accuracy: (test=0.625) f1: (test=0.140) roc_auc: (test=0.689) 38.13s
==get_scoring_result==
base_score: total=2625, TP=82, TN=1733, FP=767, FN=43; precision=0.097, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.691) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.110) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.675) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.168) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.725) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 1733, 'FP': 767, 'FN': 43, 'precision': 0.09658421672555949, 'recall': 0.656, 'accuracy': 0.6914285714285714, 'average_precision': 0.11012832068439682, 'balanced_accuracy': 0.6746000000000001, 'f1': 0.16837782340862426, 'roc_auc': 0.7245536}
==getted_scoring_result==
[fit 557/850] END C=4096.0, gamma=0.0625, kernel=rbf; total=2625, TP=82, TN=1733, FP=767, FN=43; precision=0.097, recall=0.656
accuracy: (test=0.691) average_precision: (test=0.110) balanced_accuracy: (test=0.675) f1: (test=0.168) roc_auc: (test=0.725) 1.06min
==get_scoring_result==
base_score: total=2625, TP=84, TN=1848, FP=652, FN=41; precision=0.114, recall=0.672

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.736) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.148) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.706) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.195) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.771) ===
score_result_dict: {'Total': 2625, 'TP': 84, 'TN': 1848, 'FP': 652, 'FN': 41, 'precision': 0.11413043478260869, 'recall': 0.672, 'accuracy': 0.736, 'average_precision': 0.14771193557071835, 'balanced_accuracy': 0.7056, 'f1': 0.19512195121951217, 'roc_auc': 0.7712384}
==getted_scoring_result==
[fit 558/850] END C=4096.0, gamma=0.125, kernel=rbf; total=2625, TP=84, TN=1848, FP=652, FN=41; precision=0.114, recall=0.672
accuracy: (test=0.736) average_precision: (test=0.148) balanced_accuracy: (test=0.706) f1: (test=0.195) roc_auc: (test=0.771) 1.90min
==get_scoring_result==
base_score: total=2625, TP=91, TN=1986, FP=514, FN=34; precision=0.150, recall=0.728

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.791) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.196) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.761) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.249) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.823) ===
score_result_dict: {'Total': 2625, 'TP': 91, 'TN': 1986, 'FP': 514, 'FN': 34, 'precision': 0.15041322314049588, 'recall': 0.728, 'accuracy': 0.7912380952380952, 'average_precision': 0.19641999736006008, 'balanced_accuracy': 0.7612, 'f1': 0.2493150684931507, 'roc_auc': 0.8234272}
==getted_scoring_result==
[fit 559/850] END C=4096.0, gamma=0.25, kernel=rbf; total=2625, TP=91, TN=1986, FP=514, FN=34; precision=0.150, recall=0.728
accuracy: (test=0.791) average_precision: (test=0.196) balanced_accuracy: (test=0.761) f1: (test=0.249) roc_auc: (test=0.823) 3.70min
==get_scoring_result==
base_score: total=2625, TP=92, TN=2032, FP=468, FN=33; precision=0.164, recall=0.736

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.809) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.225) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.774) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.269) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 92, 'TN': 2032, 'FP': 468, 'FN': 33, 'precision': 0.16428571428571428, 'recall': 0.736, 'accuracy': 0.8091428571428572, 'average_precision': 0.22548669422849993, 'balanced_accuracy': 0.7744, 'f1': 0.2686131386861314, 'roc_auc': 0.8349024}
==getted_scoring_result==
[fit 560/850] END C=4096.0, gamma=0.5, kernel=rbf; total=2625, TP=92, TN=2032, FP=468, FN=33; precision=0.164, recall=0.736
accuracy: (test=0.809) average_precision: (test=0.225) balanced_accuracy: (test=0.774) f1: (test=0.269) roc_auc: (test=0.835) 9.58min
==get_scoring_result==
base_score: total=2625, TP=88, TN=2053, FP=447, FN=37; precision=0.164, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.816) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.266) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.763) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.267) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.842) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 2053, 'FP': 447, 'FN': 37, 'precision': 0.16448598130841122, 'recall': 0.704, 'accuracy': 0.8156190476190476, 'average_precision': 0.2655726407973694, 'balanced_accuracy': 0.7626, 'f1': 0.26666666666666666, 'roc_auc': 0.8421568}
==getted_scoring_result==
[fit 561/850] END C=4096.0, gamma=1.0, kernel=rbf; total=2625, TP=88, TN=2053, FP=447, FN=37; precision=0.164, recall=0.704
accuracy: (test=0.816) average_precision: (test=0.266) balanced_accuracy: (test=0.763) f1: (test=0.267) roc_auc: (test=0.842) 10.48min
==get_scoring_result==
base_score: total=2625, TP=82, TN=2169, FP=331, FN=43; precision=0.199, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.858) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.366) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.762) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.305) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.851) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 2169, 'FP': 331, 'FN': 43, 'precision': 0.19854721549636803, 'recall': 0.656, 'accuracy': 0.8575238095238096, 'average_precision': 0.3657690558322025, 'balanced_accuracy': 0.7618, 'f1': 0.3048327137546469, 'roc_auc': 0.8507744}
==getted_scoring_result==
[fit 562/850] END C=4096.0, gamma=2.0, kernel=rbf; total=2625, TP=82, TN=2169, FP=331, FN=43; precision=0.199, recall=0.656
accuracy: (test=0.858) average_precision: (test=0.366) balanced_accuracy: (test=0.762) f1: (test=0.305) roc_auc: (test=0.851) 17.34min
==get_scoring_result==
base_score: total=2625, TP=87, TN=2299, FP=201, FN=38; precision=0.302, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.909) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.480) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.808) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.421) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.893) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 2299, 'FP': 201, 'FN': 38, 'precision': 0.3020833333333333, 'recall': 0.696, 'accuracy': 0.908952380952381, 'average_precision': 0.48042901859565174, 'balanced_accuracy': 0.8078, 'f1': 0.4213075060532687, 'roc_auc': 0.8926528}
==getted_scoring_result==
[fit 563/850] END C=4096.0, gamma=4.0, kernel=rbf; total=2625, TP=87, TN=2299, FP=201, FN=38; precision=0.302, recall=0.696
accuracy: (test=0.909) average_precision: (test=0.480) balanced_accuracy: (test=0.808) f1: (test=0.421) roc_auc: (test=0.893) 32.12min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2436, FP=64, FN=46; precision=0.552, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.958) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.624) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.803) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.590) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.904) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2436, 'FP': 64, 'FN': 46, 'precision': 0.5524475524475524, 'recall': 0.632, 'accuracy': 0.9580952380952381, 'average_precision': 0.6241540934322709, 'balanced_accuracy': 0.8032, 'f1': 0.5895522388059701, 'roc_auc': 0.9040352}
==getted_scoring_result==
[fit 564/850] END C=4096.0, gamma=8.0, kernel=rbf; total=2625, TP=79, TN=2436, FP=64, FN=46; precision=0.552, recall=0.632
accuracy: (test=0.958) average_precision: (test=0.624) balanced_accuracy: (test=0.803) f1: (test=0.590) roc_auc: (test=0.904) 12.64min
==get_scoring_result==
base_score: total=2625, TP=80, TN=2458, FP=42, FN=45; precision=0.656, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.967) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.681) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.812) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.648) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.906) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2458, 'FP': 42, 'FN': 45, 'precision': 0.6557377049180327, 'recall': 0.64, 'accuracy': 0.9668571428571429, 'average_precision': 0.6813804265776009, 'balanced_accuracy': 0.8116, 'f1': 0.6477732793522267, 'roc_auc': 0.905872}
==getted_scoring_result==
[fit 565/850] END C=4096.0, gamma=16.0, kernel=rbf; total=2625, TP=80, TN=2458, FP=42, FN=45; precision=0.656, recall=0.640
accuracy: (test=0.967) average_precision: (test=0.681) balanced_accuracy: (test=0.812) f1: (test=0.648) roc_auc: (test=0.906) 2.38min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2466, FP=34, FN=46; precision=0.699, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.695) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.809) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.664) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.905) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2466, 'FP': 34, 'FN': 46, 'precision': 0.6991150442477876, 'recall': 0.632, 'accuracy': 0.9695238095238096, 'average_precision': 0.6949966900062938, 'balanced_accuracy': 0.8092, 'f1': 0.6638655462184874, 'roc_auc': 0.9054016}
==getted_scoring_result==
[fit 566/850] END C=4096.0, gamma=32.0, kernel=rbf; total=2625, TP=79, TN=2466, FP=34, FN=46; precision=0.699, recall=0.632
accuracy: (test=0.970) average_precision: (test=0.695) balanced_accuracy: (test=0.809) f1: (test=0.664) roc_auc: (test=0.905) 56.73s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.670) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2474, 'FP': 26, 'FN': 49, 'precision': 0.7450980392156863, 'recall': 0.608, 'accuracy': 0.9714285714285714, 'average_precision': 0.6967551398498117, 'balanced_accuracy': 0.7988, 'f1': 0.6696035242290749, 'roc_auc': 0.8993504}
==getted_scoring_result==
[fit 567/850] END C=4096.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608
accuracy: (test=0.971) average_precision: (test=0.697) balanced_accuracy: (test=0.799) f1: (test=0.670) roc_auc: (test=0.899) 28.68s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.795) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2477, 'FP': 23, 'FN': 50, 'precision': 0.7653061224489796, 'recall': 0.6, 'accuracy': 0.9721904761904762, 'average_precision': 0.6970638985448205, 'balanced_accuracy': 0.7954, 'f1': 0.6726457399103138, 'roc_auc': 0.895408}
==getted_scoring_result==
[fit 568/850] END C=4096.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600
accuracy: (test=0.972) average_precision: (test=0.697) balanced_accuracy: (test=0.795) f1: (test=0.673) roc_auc: (test=0.895) 20.40s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786539160578525, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 569/850] END C=4096.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 20.48s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 570/850] END C=4096.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 24.19s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 571/850] END C=4096.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 28.25s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 572/850] END C=4096.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 27.79s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 573/850] END C=4096.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 23.74s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 574/850] END C=4096.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 21.61s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 575/850] END C=4096.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 17.46s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1584, FP=916, FN=52; precision=0.074, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.631) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.609) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.660) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1584, 'FP': 916, 'FN': 52, 'precision': 0.07381193124368049, 'recall': 0.584, 'accuracy': 0.6312380952380953, 'average_precision': 0.08435980583936566, 'balanced_accuracy': 0.6088, 'f1': 0.13105924596050272, 'roc_auc': 0.6600784}
==getted_scoring_result==
[fit 576/850] END C=8192.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=73, TN=1584, FP=916, FN=52; precision=0.074, recall=0.584
accuracy: (test=0.631) average_precision: (test=0.084) balanced_accuracy: (test=0.609) f1: (test=0.131) roc_auc: (test=0.660) 12.73s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1578, FP=922, FN=53; precision=0.072, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.629) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.604) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.129) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.659) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1578, 'FP': 922, 'FN': 53, 'precision': 0.07243460764587525, 'recall': 0.576, 'accuracy': 0.6285714285714286, 'average_precision': 0.08361090998347245, 'balanced_accuracy': 0.6035999999999999, 'f1': 0.128686327077748, 'roc_auc': 0.6587744}
==getted_scoring_result==
[fit 577/850] END C=8192.0, gamma=0.001953125, kernel=rbf; total=2625, TP=72, TN=1578, FP=922, FN=53; precision=0.072, recall=0.576
accuracy: (test=0.629) average_precision: (test=0.084) balanced_accuracy: (test=0.604) f1: (test=0.129) roc_auc: (test=0.659) 14.45s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1583, FP=917, FN=52; precision=0.074, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.631) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.609) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.659) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1583, 'FP': 917, 'FN': 52, 'precision': 0.07373737373737374, 'recall': 0.584, 'accuracy': 0.6308571428571429, 'average_precision': 0.08385355580352374, 'balanced_accuracy': 0.6086, 'f1': 0.13094170403587443, 'roc_auc': 0.6593952}
==getted_scoring_result==
[fit 578/850] END C=8192.0, gamma=0.00390625, kernel=rbf; total=2625, TP=73, TN=1583, FP=917, FN=52; precision=0.074, recall=0.584
accuracy: (test=0.631) average_precision: (test=0.084) balanced_accuracy: (test=0.609) f1: (test=0.131) roc_auc: (test=0.659) 18.39s
==get_scoring_result==
base_score: total=2625, TP=75, TN=1596, FP=904, FN=50; precision=0.077, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.637) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.619) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.136) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.667) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1596, 'FP': 904, 'FN': 50, 'precision': 0.07660878447395301, 'recall': 0.6, 'accuracy': 0.6365714285714286, 'average_precision': 0.08583362759612338, 'balanced_accuracy': 0.6192, 'f1': 0.1358695652173913, 'roc_auc': 0.6668576}
==getted_scoring_result==
[fit 579/850] END C=8192.0, gamma=0.0078125, kernel=rbf; total=2625, TP=75, TN=1596, FP=904, FN=50; precision=0.077, recall=0.600
accuracy: (test=0.637) average_precision: (test=0.086) balanced_accuracy: (test=0.619) f1: (test=0.136) roc_auc: (test=0.667) 26.79s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1614, FP=886, FN=51; precision=0.077, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.643) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.090) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.619) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.136) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.675) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1614, 'FP': 886, 'FN': 51, 'precision': 0.07708333333333334, 'recall': 0.592, 'accuracy': 0.6430476190476191, 'average_precision': 0.090198490367887, 'balanced_accuracy': 0.6188, 'f1': 0.13640552995391705, 'roc_auc': 0.6746752}
==getted_scoring_result==
[fit 580/850] END C=8192.0, gamma=0.015625, kernel=rbf; total=2625, TP=74, TN=1614, FP=886, FN=51; precision=0.077, recall=0.592
accuracy: (test=0.643) average_precision: (test=0.090) balanced_accuracy: (test=0.619) f1: (test=0.136) roc_auc: (test=0.675) 40.73s
==get_scoring_result==
base_score: total=2625, TP=80, TN=1668, FP=832, FN=45; precision=0.088, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.666) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.098) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.654) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.154) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.704) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 1668, 'FP': 832, 'FN': 45, 'precision': 0.08771929824561403, 'recall': 0.64, 'accuracy': 0.6659047619047619, 'average_precision': 0.09811441045551467, 'balanced_accuracy': 0.6536, 'f1': 0.15429122468659595, 'roc_auc': 0.7042064}
==getted_scoring_result==
[fit 581/850] END C=8192.0, gamma=0.03125, kernel=rbf; total=2625, TP=80, TN=1668, FP=832, FN=45; precision=0.088, recall=0.640
accuracy: (test=0.666) average_precision: (test=0.098) balanced_accuracy: (test=0.654) f1: (test=0.154) roc_auc: (test=0.704) 1.11min
==get_scoring_result==
base_score: total=2625, TP=83, TN=1779, FP=721, FN=42; precision=0.103, recall=0.664

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.709) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.128) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.688) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.179) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.746) ===
score_result_dict: {'Total': 2625, 'TP': 83, 'TN': 1779, 'FP': 721, 'FN': 42, 'precision': 0.10323383084577115, 'recall': 0.664, 'accuracy': 0.7093333333333334, 'average_precision': 0.12806549078766233, 'balanced_accuracy': 0.6878, 'f1': 0.17868675995694297, 'roc_auc': 0.7464816}
==getted_scoring_result==
[fit 582/850] END C=8192.0, gamma=0.0625, kernel=rbf; total=2625, TP=83, TN=1779, FP=721, FN=42; precision=0.103, recall=0.664
accuracy: (test=0.709) average_precision: (test=0.128) balanced_accuracy: (test=0.688) f1: (test=0.179) roc_auc: (test=0.746) 2.02min
==get_scoring_result==
base_score: total=2625, TP=88, TN=1901, FP=599, FN=37; precision=0.128, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.758) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.166) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.732) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.217) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.797) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 1901, 'FP': 599, 'FN': 37, 'precision': 0.12809315866084425, 'recall': 0.704, 'accuracy': 0.7577142857142857, 'average_precision': 0.16566086986289844, 'balanced_accuracy': 0.7322, 'f1': 0.2167487684729064, 'roc_auc': 0.7970864}
==getted_scoring_result==
[fit 583/850] END C=8192.0, gamma=0.125, kernel=rbf; total=2625, TP=88, TN=1901, FP=599, FN=37; precision=0.128, recall=0.704
accuracy: (test=0.758) average_precision: (test=0.166) balanced_accuracy: (test=0.732) f1: (test=0.217) roc_auc: (test=0.797) 3.86min
==get_scoring_result==
base_score: total=2625, TP=88, TN=1956, FP=544, FN=37; precision=0.139, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.779) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.184) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.743) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.232) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.808) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 1956, 'FP': 544, 'FN': 37, 'precision': 0.13924050632911392, 'recall': 0.704, 'accuracy': 0.7786666666666666, 'average_precision': 0.18382308535671738, 'balanced_accuracy': 0.7432, 'f1': 0.23249669749009247, 'roc_auc': 0.8081664}
==getted_scoring_result==
[fit 584/850] END C=8192.0, gamma=0.25, kernel=rbf; total=2625, TP=88, TN=1956, FP=544, FN=37; precision=0.139, recall=0.704
accuracy: (test=0.779) average_precision: (test=0.184) balanced_accuracy: (test=0.743) f1: (test=0.232) roc_auc: (test=0.808) 11.59min
==get_scoring_result==
base_score: total=2625, TP=89, TN=1914, FP=586, FN=36; precision=0.132, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.763) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.202) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.739) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.222) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.808) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 1914, 'FP': 586, 'FN': 36, 'precision': 0.13185185185185186, 'recall': 0.712, 'accuracy': 0.7630476190476191, 'average_precision': 0.20242183844850986, 'balanced_accuracy': 0.7387999999999999, 'f1': 0.22249999999999998, 'roc_auc': 0.8081344}
==getted_scoring_result==
[fit 585/850] END C=8192.0, gamma=0.5, kernel=rbf; total=2625, TP=89, TN=1914, FP=586, FN=36; precision=0.132, recall=0.712
accuracy: (test=0.763) average_precision: (test=0.202) balanced_accuracy: (test=0.739) f1: (test=0.222) roc_auc: (test=0.808) 7.73min
==get_scoring_result==
base_score: total=2625, TP=87, TN=1981, FP=519, FN=38; precision=0.144, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.788) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.252) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.744) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.238) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.830) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 1981, 'FP': 519, 'FN': 38, 'precision': 0.14356435643564355, 'recall': 0.696, 'accuracy': 0.7878095238095238, 'average_precision': 0.2519041125385647, 'balanced_accuracy': 0.7442, 'f1': 0.23803009575923392, 'roc_auc': 0.8295232}
==getted_scoring_result==
[fit 586/850] END C=8192.0, gamma=1.0, kernel=rbf; total=2625, TP=87, TN=1981, FP=519, FN=38; precision=0.144, recall=0.696
accuracy: (test=0.788) average_precision: (test=0.252) balanced_accuracy: (test=0.744) f1: (test=0.238) roc_auc: (test=0.830) 15.72min
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=93, TN=2100, FP=400, FN=32; precision=0.189, recall=0.744

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.835) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.338) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.301) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.860) ===
score_result_dict: {'Total': 2625, 'TP': 93, 'TN': 2100, 'FP': 400, 'FN': 32, 'precision': 0.18864097363083165, 'recall': 0.744, 'accuracy': 0.8354285714285714, 'average_precision': 0.33847760755794515, 'balanced_accuracy': 0.792, 'f1': 0.30097087378640774, 'roc_auc': 0.8601888}
==getted_scoring_result==
[fit 587/850] END C=8192.0, gamma=2.0, kernel=rbf; total=2625, TP=93, TN=2100, FP=400, FN=32; precision=0.189, recall=0.744
accuracy: (test=0.835) average_precision: (test=0.338) balanced_accuracy: (test=0.792) f1: (test=0.301) roc_auc: (test=0.860) 32.11min
==get_scoring_result==
base_score: total=2625, TP=87, TN=2263, FP=237, FN=38; precision=0.269, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.895) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.455) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.801) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.388) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.890) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 2263, 'FP': 237, 'FN': 38, 'precision': 0.26851851851851855, 'recall': 0.696, 'accuracy': 0.8952380952380953, 'average_precision': 0.4552986750059111, 'balanced_accuracy': 0.8006, 'f1': 0.38752783964365256, 'roc_auc': 0.8904448}
==getted_scoring_result==
[fit 588/850] END C=8192.0, gamma=4.0, kernel=rbf; total=2625, TP=87, TN=2263, FP=237, FN=38; precision=0.269, recall=0.696
accuracy: (test=0.895) average_precision: (test=0.455) balanced_accuracy: (test=0.801) f1: (test=0.388) roc_auc: (test=0.890) 52.98min
==get_scoring_result==
base_score: total=2625, TP=80, TN=2434, FP=66, FN=45; precision=0.548, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.958) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.624) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.807) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.590) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.906) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2434, 'FP': 66, 'FN': 45, 'precision': 0.547945205479452, 'recall': 0.64, 'accuracy': 0.9577142857142857, 'average_precision': 0.6237787757258153, 'balanced_accuracy': 0.8068, 'f1': 0.5904059040590406, 'roc_auc': 0.9059616}
==getted_scoring_result==
[fit 589/850] END C=8192.0, gamma=8.0, kernel=rbf; total=2625, TP=80, TN=2434, FP=66, FN=45; precision=0.548, recall=0.640
accuracy: (test=0.958) average_precision: (test=0.624) balanced_accuracy: (test=0.807) f1: (test=0.590) roc_auc: (test=0.906) 13.01min
==get_scoring_result==
base_score: total=2625, TP=80, TN=2458, FP=42, FN=45; precision=0.656, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.967) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.681) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.812) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.648) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.906) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2458, 'FP': 42, 'FN': 45, 'precision': 0.6557377049180327, 'recall': 0.64, 'accuracy': 0.9668571428571429, 'average_precision': 0.6813804265776009, 'balanced_accuracy': 0.8116, 'f1': 0.6477732793522267, 'roc_auc': 0.905872}
==getted_scoring_result==
[fit 590/850] END C=8192.0, gamma=16.0, kernel=rbf; total=2625, TP=80, TN=2458, FP=42, FN=45; precision=0.656, recall=0.640
accuracy: (test=0.967) average_precision: (test=0.681) balanced_accuracy: (test=0.812) f1: (test=0.648) roc_auc: (test=0.906) 2.37min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2466, FP=34, FN=46; precision=0.699, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.695) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.809) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.664) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.905) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2466, 'FP': 34, 'FN': 46, 'precision': 0.6991150442477876, 'recall': 0.632, 'accuracy': 0.9695238095238096, 'average_precision': 0.6949966900062938, 'balanced_accuracy': 0.8092, 'f1': 0.6638655462184874, 'roc_auc': 0.9054016}
==getted_scoring_result==
[fit 591/850] END C=8192.0, gamma=32.0, kernel=rbf; total=2625, TP=79, TN=2466, FP=34, FN=46; precision=0.699, recall=0.632
accuracy: (test=0.970) average_precision: (test=0.695) balanced_accuracy: (test=0.809) f1: (test=0.664) roc_auc: (test=0.905) 56.45s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.670) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2474, 'FP': 26, 'FN': 49, 'precision': 0.7450980392156863, 'recall': 0.608, 'accuracy': 0.9714285714285714, 'average_precision': 0.6967551398498117, 'balanced_accuracy': 0.7988, 'f1': 0.6696035242290749, 'roc_auc': 0.8993504}
==getted_scoring_result==
[fit 592/850] END C=8192.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608
accuracy: (test=0.971) average_precision: (test=0.697) balanced_accuracy: (test=0.799) f1: (test=0.670) roc_auc: (test=0.899) 28.56s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.795) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2477, 'FP': 23, 'FN': 50, 'precision': 0.7653061224489796, 'recall': 0.6, 'accuracy': 0.9721904761904762, 'average_precision': 0.6970638985448205, 'balanced_accuracy': 0.7954, 'f1': 0.6726457399103138, 'roc_auc': 0.895408}
==getted_scoring_result==
[fit 593/850] END C=8192.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600
accuracy: (test=0.972) average_precision: (test=0.697) balanced_accuracy: (test=0.795) f1: (test=0.673) roc_auc: (test=0.895) 20.54s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786539160578525, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 594/850] END C=8192.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 20.87s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 595/850] END C=8192.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 23.87s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 596/850] END C=8192.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 27.45s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 597/850] END C=8192.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 27.52s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 598/850] END C=8192.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 23.68s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 599/850] END C=8192.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 21.09s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 600/850] END C=8192.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 17.21s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1581, FP=919, FN=51; precision=0.075, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.630) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.083) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.132) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.661) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1581, 'FP': 919, 'FN': 51, 'precision': 0.07452165156092648, 'recall': 0.592, 'accuracy': 0.6304761904761905, 'average_precision': 0.08334152188152051, 'balanced_accuracy': 0.6122, 'f1': 0.1323792486583184, 'roc_auc': 0.661056}
==getted_scoring_result==
[fit 601/850] END C=16384.0, gamma=0.0009765625, kernel=rbf; total=2625, TP=74, TN=1581, FP=919, FN=51; precision=0.075, recall=0.592
accuracy: (test=0.630) average_precision: (test=0.083) balanced_accuracy: (test=0.612) f1: (test=0.132) roc_auc: (test=0.661) 15.17s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1575, FP=925, FN=53; precision=0.072, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.627) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.083) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.603) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.128) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.659) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1575, 'FP': 925, 'FN': 53, 'precision': 0.07221664994984955, 'recall': 0.576, 'accuracy': 0.6274285714285714, 'average_precision': 0.08255310796298007, 'balanced_accuracy': 0.603, 'f1': 0.12834224598930483, 'roc_auc': 0.659312}
==getted_scoring_result==
[fit 602/850] END C=16384.0, gamma=0.001953125, kernel=rbf; total=2625, TP=72, TN=1575, FP=925, FN=53; precision=0.072, recall=0.576
accuracy: (test=0.627) average_precision: (test=0.083) balanced_accuracy: (test=0.603) f1: (test=0.128) roc_auc: (test=0.659) 19.46s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1576, FP=924, FN=51; precision=0.074, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.629) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.083) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.611) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.132) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.658) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1576, 'FP': 924, 'FN': 51, 'precision': 0.07414829659318638, 'recall': 0.592, 'accuracy': 0.6285714285714286, 'average_precision': 0.08347368876764275, 'balanced_accuracy': 0.6112, 'f1': 0.13178984861976847, 'roc_auc': 0.6583616}
==getted_scoring_result==
[fit 603/850] END C=16384.0, gamma=0.00390625, kernel=rbf; total=2625, TP=74, TN=1576, FP=924, FN=51; precision=0.074, recall=0.592
accuracy: (test=0.629) average_precision: (test=0.083) balanced_accuracy: (test=0.611) f1: (test=0.132) roc_auc: (test=0.658) 28.80s
==get_scoring_result==
base_score: total=2625, TP=76, TN=1604, FP=896, FN=49; precision=0.078, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.640) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.087) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.625) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.139) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.672) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 1604, 'FP': 896, 'FN': 49, 'precision': 0.07818930041152264, 'recall': 0.608, 'accuracy': 0.64, 'average_precision': 0.08663581261429866, 'balanced_accuracy': 0.6248, 'f1': 0.13855970829535097, 'roc_auc': 0.6718928}
==getted_scoring_result==
[fit 604/850] END C=16384.0, gamma=0.0078125, kernel=rbf; total=2625, TP=76, TN=1604, FP=896, FN=49; precision=0.078, recall=0.608
accuracy: (test=0.640) average_precision: (test=0.087) balanced_accuracy: (test=0.625) f1: (test=0.139) roc_auc: (test=0.672) 46.01s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1634, FP=866, FN=51; precision=0.079, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.651) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.094) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.623) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.139) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.684) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1634, 'FP': 866, 'FN': 51, 'precision': 0.07872340425531915, 'recall': 0.592, 'accuracy': 0.6506666666666666, 'average_precision': 0.09399564274402727, 'balanced_accuracy': 0.6228, 'f1': 0.13896713615023473, 'roc_auc': 0.6838464}
==getted_scoring_result==
[fit 605/850] END C=16384.0, gamma=0.015625, kernel=rbf; total=2625, TP=74, TN=1634, FP=866, FN=51; precision=0.079, recall=0.592
accuracy: (test=0.651) average_precision: (test=0.094) balanced_accuracy: (test=0.623) f1: (test=0.139) roc_auc: (test=0.684) 1.25min
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=84, TN=1724, FP=776, FN=41; precision=0.098, recall=0.672

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.689) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.109) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.681) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.171) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.725) ===
score_result_dict: {'Total': 2625, 'TP': 84, 'TN': 1724, 'FP': 776, 'FN': 41, 'precision': 0.09767441860465116, 'recall': 0.672, 'accuracy': 0.6887619047619048, 'average_precision': 0.10867051050825169, 'balanced_accuracy': 0.6808000000000001, 'f1': 0.17055837563451776, 'roc_auc': 0.724704}
==getted_scoring_result==
[fit 606/850] END C=16384.0, gamma=0.03125, kernel=rbf; total=2625, TP=84, TN=1724, FP=776, FN=41; precision=0.098, recall=0.672
accuracy: (test=0.689) average_precision: (test=0.109) balanced_accuracy: (test=0.681) f1: (test=0.171) roc_auc: (test=0.725) 2.37min
==get_scoring_result==
base_score: total=2625, TP=85, TN=1822, FP=678, FN=40; precision=0.111, recall=0.680

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.726) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.142) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.704) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.191) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.766) ===
score_result_dict: {'Total': 2625, 'TP': 85, 'TN': 1822, 'FP': 678, 'FN': 40, 'precision': 0.11140235910878113, 'recall': 0.68, 'accuracy': 0.7264761904761905, 'average_precision': 0.14172902797033493, 'balanced_accuracy': 0.7044, 'f1': 0.19144144144144146, 'roc_auc': 0.7657248}
==getted_scoring_result==
[fit 607/850] END C=16384.0, gamma=0.0625, kernel=rbf; total=2625, TP=85, TN=1822, FP=678, FN=40; precision=0.111, recall=0.680
accuracy: (test=0.726) average_precision: (test=0.142) balanced_accuracy: (test=0.704) f1: (test=0.191) roc_auc: (test=0.766) 4.73min
==get_scoring_result==
base_score: total=2625, TP=78, TN=1863, FP=637, FN=47; precision=0.109, recall=0.624

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.739) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.170) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.685) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.186) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.770) ===
score_result_dict: {'Total': 2625, 'TP': 78, 'TN': 1863, 'FP': 637, 'FN': 47, 'precision': 0.10909090909090909, 'recall': 0.624, 'accuracy': 0.7394285714285714, 'average_precision': 0.17048113986247865, 'balanced_accuracy': 0.6846, 'f1': 0.1857142857142857, 'roc_auc': 0.7704832}
==getted_scoring_result==
[fit 608/850] END C=16384.0, gamma=0.125, kernel=rbf; total=2625, TP=78, TN=1863, FP=637, FN=47; precision=0.109, recall=0.624
accuracy: (test=0.739) average_precision: (test=0.170) balanced_accuracy: (test=0.685) f1: (test=0.186) roc_auc: (test=0.770) 20.05min
==get_scoring_result==
base_score: total=2625, TP=82, TN=1809, FP=691, FN=43; precision=0.106, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.720) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.168) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.690) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.183) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.773) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 1809, 'FP': 691, 'FN': 43, 'precision': 0.10608020698576973, 'recall': 0.656, 'accuracy': 0.7203809523809523, 'average_precision': 0.16753999305759634, 'balanced_accuracy': 0.6898, 'f1': 0.18262806236080179, 'roc_auc': 0.7730208}
==getted_scoring_result==
[fit 609/850] END C=16384.0, gamma=0.25, kernel=rbf; total=2625, TP=82, TN=1809, FP=691, FN=43; precision=0.106, recall=0.656
accuracy: (test=0.720) average_precision: (test=0.168) balanced_accuracy: (test=0.690) f1: (test=0.183) roc_auc: (test=0.773) 7.77min
==get_scoring_result==
base_score: total=2625, TP=86, TN=1854, FP=646, FN=39; precision=0.117, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.739) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.191) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.715) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.201) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.792) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 1854, 'FP': 646, 'FN': 39, 'precision': 0.11748633879781421, 'recall': 0.688, 'accuracy': 0.7390476190476191, 'average_precision': 0.1913333174964019, 'balanced_accuracy': 0.7148, 'f1': 0.20070011668611437, 'roc_auc': 0.7919552}
==getted_scoring_result==
[fit 610/850] END C=16384.0, gamma=0.5, kernel=rbf; total=2625, TP=86, TN=1854, FP=646, FN=39; precision=0.117, recall=0.688
accuracy: (test=0.739) average_precision: (test=0.191) balanced_accuracy: (test=0.715) f1: (test=0.201) roc_auc: (test=0.792) 9.13min
==get_scoring_result==
base_score: total=2625, TP=84, TN=1953, FP=547, FN=41; precision=0.133, recall=0.672

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.776) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.251) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.727) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.222) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.803) ===
score_result_dict: {'Total': 2625, 'TP': 84, 'TN': 1953, 'FP': 547, 'FN': 41, 'precision': 0.13312202852614896, 'recall': 0.672, 'accuracy': 0.776, 'average_precision': 0.2511583611173076, 'balanced_accuracy': 0.7266, 'f1': 0.22222222222222218, 'roc_auc': 0.802624}
==getted_scoring_result==
[fit 611/850] END C=16384.0, gamma=1.0, kernel=rbf; total=2625, TP=84, TN=1953, FP=547, FN=41; precision=0.133, recall=0.672
accuracy: (test=0.776) average_precision: (test=0.251) balanced_accuracy: (test=0.727) f1: (test=0.222) roc_auc: (test=0.803) 22.20min
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=91, TN=2075, FP=425, FN=34; precision=0.176, recall=0.728

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.825) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.323) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.779) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.284) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.853) ===
score_result_dict: {'Total': 2625, 'TP': 91, 'TN': 2075, 'FP': 425, 'FN': 34, 'precision': 0.17635658914728683, 'recall': 0.728, 'accuracy': 0.8251428571428572, 'average_precision': 0.32256875633627674, 'balanced_accuracy': 0.7789999999999999, 'f1': 0.28393135725429014, 'roc_auc': 0.8530704}
==getted_scoring_result==
[fit 612/850] END C=16384.0, gamma=2.0, kernel=rbf; total=2625, TP=91, TN=2075, FP=425, FN=34; precision=0.176, recall=0.728
accuracy: (test=0.825) average_precision: (test=0.323) balanced_accuracy: (test=0.779) f1: (test=0.284) roc_auc: (test=0.853) 1h 8m 51s
==get_scoring_result==
base_score: total=2625, TP=88, TN=2232, FP=268, FN=37; precision=0.247, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.884) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.450) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.798) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.890) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 2232, 'FP': 268, 'FN': 37, 'precision': 0.24719101123595505, 'recall': 0.704, 'accuracy': 0.8838095238095238, 'average_precision': 0.4503902610356515, 'balanced_accuracy': 0.7984, 'f1': 0.3659043659043659, 'roc_auc': 0.8899616}
==getted_scoring_result==
[fit 613/850] END C=16384.0, gamma=4.0, kernel=rbf; total=2625, TP=88, TN=2232, FP=268, FN=37; precision=0.247, recall=0.704
accuracy: (test=0.884) average_precision: (test=0.450) balanced_accuracy: (test=0.798) f1: (test=0.366) roc_auc: (test=0.890) 1h 20m 15s
==get_scoring_result==
base_score: total=2625, TP=81, TN=2434, FP=66, FN=44; precision=0.551, recall=0.648

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.958) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.623) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.811) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.596) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.905) ===
score_result_dict: {'Total': 2625, 'TP': 81, 'TN': 2434, 'FP': 66, 'FN': 44, 'precision': 0.5510204081632653, 'recall': 0.648, 'accuracy': 0.9580952380952381, 'average_precision': 0.6229976790330248, 'balanced_accuracy': 0.8108, 'f1': 0.5955882352941175, 'roc_auc': 0.9052048}
==getted_scoring_result==
[fit 614/850] END C=16384.0, gamma=8.0, kernel=rbf; total=2625, TP=81, TN=2434, FP=66, FN=44; precision=0.551, recall=0.648
accuracy: (test=0.958) average_precision: (test=0.623) balanced_accuracy: (test=0.811) f1: (test=0.596) roc_auc: (test=0.905) 13.81min
==get_scoring_result==
base_score: total=2625, TP=80, TN=2458, FP=42, FN=45; precision=0.656, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.967) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.681) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.812) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.648) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.906) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 2458, 'FP': 42, 'FN': 45, 'precision': 0.6557377049180327, 'recall': 0.64, 'accuracy': 0.9668571428571429, 'average_precision': 0.6813804265776009, 'balanced_accuracy': 0.8116, 'f1': 0.6477732793522267, 'roc_auc': 0.905872}
==getted_scoring_result==
[fit 615/850] END C=16384.0, gamma=16.0, kernel=rbf; total=2625, TP=80, TN=2458, FP=42, FN=45; precision=0.656, recall=0.640
accuracy: (test=0.967) average_precision: (test=0.681) balanced_accuracy: (test=0.812) f1: (test=0.648) roc_auc: (test=0.906) 2.39min
==get_scoring_result==
base_score: total=2625, TP=79, TN=2466, FP=34, FN=46; precision=0.699, recall=0.632

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.695) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.809) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.664) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.905) ===
score_result_dict: {'Total': 2625, 'TP': 79, 'TN': 2466, 'FP': 34, 'FN': 46, 'precision': 0.6991150442477876, 'recall': 0.632, 'accuracy': 0.9695238095238096, 'average_precision': 0.6949966900062938, 'balanced_accuracy': 0.8092, 'f1': 0.6638655462184874, 'roc_auc': 0.9054016}
==getted_scoring_result==
[fit 616/850] END C=16384.0, gamma=32.0, kernel=rbf; total=2625, TP=79, TN=2466, FP=34, FN=46; precision=0.699, recall=0.632
accuracy: (test=0.970) average_precision: (test=0.695) balanced_accuracy: (test=0.809) f1: (test=0.664) roc_auc: (test=0.905) 59.06s
==get_scoring_result==
base_score: total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.971) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.799) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.670) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.899) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 2474, 'FP': 26, 'FN': 49, 'precision': 0.7450980392156863, 'recall': 0.608, 'accuracy': 0.9714285714285714, 'average_precision': 0.6967551398498117, 'balanced_accuracy': 0.7988, 'f1': 0.6696035242290749, 'roc_auc': 0.8993504}
==getted_scoring_result==
[fit 617/850] END C=16384.0, gamma=64.0, kernel=rbf; total=2625, TP=76, TN=2474, FP=26, FN=49; precision=0.745, recall=0.608
accuracy: (test=0.971) average_precision: (test=0.697) balanced_accuracy: (test=0.799) f1: (test=0.670) roc_auc: (test=0.899) 29.89s
==get_scoring_result==
base_score: total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.697) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.795) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.673) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.895) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 2477, 'FP': 23, 'FN': 50, 'precision': 0.7653061224489796, 'recall': 0.6, 'accuracy': 0.9721904761904762, 'average_precision': 0.6970638985448205, 'balanced_accuracy': 0.7954, 'f1': 0.6726457399103138, 'roc_auc': 0.895408}
==getted_scoring_result==
[fit 618/850] END C=16384.0, gamma=128.0, kernel=rbf; total=2625, TP=75, TN=2477, FP=23, FN=50; precision=0.765, recall=0.600
accuracy: (test=0.972) average_precision: (test=0.697) balanced_accuracy: (test=0.795) f1: (test=0.673) roc_auc: (test=0.895) 21.82s
==get_scoring_result==
base_score: total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.679) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.792) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.682) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.889) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 2482, 'FP': 18, 'FN': 51, 'precision': 0.8043478260869565, 'recall': 0.592, 'accuracy': 0.9737142857142858, 'average_precision': 0.6786539160578525, 'balanced_accuracy': 0.7924, 'f1': 0.6820276497695852, 'roc_auc': 0.888752}
==getted_scoring_result==
[fit 619/850] END C=16384.0, gamma=256.0, kernel=rbf; total=2625, TP=74, TN=2482, FP=18, FN=51; precision=0.804, recall=0.592
accuracy: (test=0.974) average_precision: (test=0.679) balanced_accuracy: (test=0.792) f1: (test=0.682) roc_auc: (test=0.889) 20.44s
==get_scoring_result==
base_score: total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.972) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.658) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.780) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.660) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.867) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 2481, 'FP': 19, 'FN': 54, 'precision': 0.7888888888888889, 'recall': 0.568, 'accuracy': 0.9721904761904762, 'average_precision': 0.6583158311375298, 'balanced_accuracy': 0.7802, 'f1': 0.6604651162790697, 'roc_auc': 0.8666592}
==getted_scoring_result==
[fit 620/850] END C=16384.0, gamma=512.0, kernel=rbf; total=2625, TP=71, TN=2481, FP=19, FN=54; precision=0.789, recall=0.568
accuracy: (test=0.972) average_precision: (test=0.658) balanced_accuracy: (test=0.780) f1: (test=0.660) roc_auc: (test=0.867) 24.18s
==get_scoring_result==
base_score: total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.974) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.655) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.740) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.642) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.847) ===
score_result_dict: {'Total': 2625, 'TP': 60, 'TN': 2498, 'FP': 2, 'FN': 65, 'precision': 0.967741935483871, 'recall': 0.48, 'accuracy': 0.9744761904761905, 'average_precision': 0.6550924967154181, 'balanced_accuracy': 0.7396, 'f1': 0.6417112299465241, 'roc_auc': 0.8474336}
==getted_scoring_result==
[fit 621/850] END C=16384.0, gamma=1024.0, kernel=rbf; total=2625, TP=60, TN=2498, FP=2, FN=65; precision=0.968, recall=0.480
accuracy: (test=0.974) average_precision: (test=0.655) balanced_accuracy: (test=0.740) f1: (test=0.642) roc_auc: (test=0.847) 27.64s
==get_scoring_result==
base_score: total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.970) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.649) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.680) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.529) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.835) ===
score_result_dict: {'Total': 2625, 'TP': 45, 'TN': 2500, 'FP': 0, 'FN': 80, 'precision': 1.0, 'recall': 0.36, 'accuracy': 0.9695238095238096, 'average_precision': 0.6486015492302862, 'balanced_accuracy': 0.6799999999999999, 'f1': 0.5294117647058824, 'roc_auc': 0.8347728}
==getted_scoring_result==
[fit 622/850] END C=16384.0, gamma=2048.0, kernel=rbf; total=2625, TP=45, TN=2500, FP=0, FN=80; precision=1.000, recall=0.360
accuracy: (test=0.970) average_precision: (test=0.649) balanced_accuracy: (test=0.680) f1: (test=0.529) roc_auc: (test=0.835) 27.26s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.963) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.609) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.366) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.819) ===
score_result_dict: {'Total': 2625, 'TP': 28, 'TN': 2500, 'FP': 0, 'FN': 97, 'precision': 1.0, 'recall': 0.224, 'accuracy': 0.963047619047619, 'average_precision': 0.6088865612687244, 'balanced_accuracy': 0.612, 'f1': 0.36601307189542487, 'roc_auc': 0.8191168}
==getted_scoring_result==
[fit 623/850] END C=16384.0, gamma=4096.0, kernel=rbf; total=2625, TP=28, TN=2500, FP=0, FN=97; precision=1.000, recall=0.224
accuracy: (test=0.963) average_precision: (test=0.609) balanced_accuracy: (test=0.612) f1: (test=0.366) roc_auc: (test=0.819) 23.47s
==get_scoring_result==
base_score: total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.959) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.506) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.239) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.748) ===
score_result_dict: {'Total': 2625, 'TP': 17, 'TN': 2500, 'FP': 0, 'FN': 108, 'precision': 1.0, 'recall': 0.136, 'accuracy': 0.9588571428571429, 'average_precision': 0.5060093071113337, 'balanced_accuracy': 0.5680000000000001, 'f1': 0.23943661971830985, 'roc_auc': 0.747528}
==getted_scoring_result==
[fit 624/850] END C=16384.0, gamma=8192.0, kernel=rbf; total=2625, TP=17, TN=2500, FP=0, FN=108; precision=1.000, recall=0.136
accuracy: (test=0.959) average_precision: (test=0.506) balanced_accuracy: (test=0.568) f1: (test=0.239) roc_auc: (test=0.748) 21.14s
==get_scoring_result==
base_score: total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.956) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.369) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.540) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.148) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.680) ===
score_result_dict: {'Total': 2625, 'TP': 10, 'TN': 2500, 'FP': 0, 'FN': 115, 'precision': 1.0, 'recall': 0.08, 'accuracy': 0.9561904761904761, 'average_precision': 0.3687545382794002, 'balanced_accuracy': 0.54, 'f1': 0.14814814814814814, 'roc_auc': 0.6800848}
==getted_scoring_result==
[fit 625/850] END C=16384.0, gamma=16384.0, kernel=rbf; total=2625, TP=10, TN=2500, FP=0, FN=115; precision=1.000, recall=0.080
accuracy: (test=0.956) average_precision: (test=0.369) balanced_accuracy: (test=0.540) f1: (test=0.148) roc_auc: (test=0.680) 17.20s
==get_scoring_result==
base_score: total=2625, TP=89, TN=834, FP=1666, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.352) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.523) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 834, 'FP': 1666, 'FN': 36, 'precision': 0.05071225071225071, 'recall': 0.712, 'accuracy': 0.3516190476190476, 'average_precision': 0.04622315477324723, 'balanced_accuracy': 0.5227999999999999, 'f1': 0.09468085106382977, 'roc_auc': 0.506752}
==getted_scoring_result==
[fit 626/850] END C=0.0009765625, kernel=linear; total=2625, TP=89, TN=834, FP=1666, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.352) average_precision: (test=0.046) balanced_accuracy: (test=0.523) f1: (test=0.095) roc_auc: (test=0.507) 9.89s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=114, TN=312, FP=2188, FN=11; precision=0.050, recall=0.912

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.162) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.502) ===
score_result_dict: {'Total': 2625, 'TP': 114, 'TN': 312, 'FP': 2188, 'FN': 11, 'precision': 0.04952215464813206, 'recall': 0.912, 'accuracy': 0.16228571428571428, 'average_precision': 0.04626151764841775, 'balanced_accuracy': 0.5184, 'f1': 0.09394313967861558, 'roc_auc': 0.502224}
==getted_scoring_result==
[fit 627/850] END C=0.0009765625, kernel=polynomial; total=2625, TP=114, TN=312, FP=2188, FN=11; precision=0.050, recall=0.912
accuracy: (test=0.162) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.094) roc_auc: (test=0.502) 9.48s
==get_scoring_result==
base_score: total=2625, TP=90, TN=809, FP=1691, FN=35; precision=0.051, recall=0.720

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.342) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 90, 'TN': 809, 'FP': 1691, 'FN': 35, 'precision': 0.05053340819764177, 'recall': 0.72, 'accuracy': 0.3424761904761905, 'average_precision': 0.0461817077761503, 'balanced_accuracy': 0.5218, 'f1': 0.09443861490031479, 'roc_auc': 0.5068288}
==getted_scoring_result==
[fit 628/850] END C=0.0009765625, kernel=sigmoid; total=2625, TP=90, TN=809, FP=1691, FN=35; precision=0.051, recall=0.720
accuracy: (test=0.342) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.507) 9.93s
==get_scoring_result==
base_score: total=2625, TP=88, TN=852, FP=1648, FN=37; precision=0.051, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.358) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 852, 'FP': 1648, 'FN': 37, 'precision': 0.05069124423963134, 'recall': 0.704, 'accuracy': 0.3580952380952381, 'average_precision': 0.04622583163636353, 'balanced_accuracy': 0.5224, 'f1': 0.09457281031703385, 'roc_auc': 0.5067056}
==getted_scoring_result==
[fit 629/850] END C=0.0009765625, kernel=precomputed; total=2625, TP=88, TN=852, FP=1648, FN=37; precision=0.051, recall=0.704
accuracy: (test=0.358) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.095) roc_auc: (test=0.507) 9.98s
==get_scoring_result==
base_score: total=2625, TP=88, TN=837, FP=1663, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.352) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 837, 'FP': 1663, 'FN': 37, 'precision': 0.05025699600228441, 'recall': 0.704, 'accuracy': 0.3523809523809524, 'average_precision': 0.04620061099213935, 'balanced_accuracy': 0.5194, 'f1': 0.09381663113006397, 'roc_auc': 0.5066576}
==getted_scoring_result==
[fit 630/850] END C=0.001953125, kernel=linear; total=2625, TP=88, TN=837, FP=1663, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.352) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 10.93s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 631/850] END C=0.001953125, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.75s
==get_scoring_result==
base_score: total=2625, TP=90, TN=809, FP=1691, FN=35; precision=0.051, recall=0.720

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.342) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 90, 'TN': 809, 'FP': 1691, 'FN': 35, 'precision': 0.05053340819764177, 'recall': 0.72, 'accuracy': 0.3424761904761905, 'average_precision': 0.0461817077761503, 'balanced_accuracy': 0.5218, 'f1': 0.09443861490031479, 'roc_auc': 0.5068288}
==getted_scoring_result==
[fit 632/850] END C=0.001953125, kernel=sigmoid; total=2625, TP=90, TN=809, FP=1691, FN=35; precision=0.051, recall=0.720
accuracy: (test=0.342) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.507) 9.27s
==get_scoring_result==
base_score: total=2625, TP=87, TN=864, FP=1636, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.362) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 864, 'FP': 1636, 'FN': 38, 'precision': 0.05049332559489263, 'recall': 0.696, 'accuracy': 0.36228571428571427, 'average_precision': 0.046221671805758924, 'balanced_accuracy': 0.5207999999999999, 'f1': 0.09415584415584416, 'roc_auc': 0.5067792}
==getted_scoring_result==
[fit 633/850] END C=0.001953125, kernel=precomputed; total=2625, TP=87, TN=864, FP=1636, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.362) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 9.82s
==get_scoring_result==
base_score: total=2625, TP=88, TN=837, FP=1663, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.352) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 837, 'FP': 1663, 'FN': 37, 'precision': 0.05025699600228441, 'recall': 0.704, 'accuracy': 0.3523809523809524, 'average_precision': 0.046200610992139346, 'balanced_accuracy': 0.5194, 'f1': 0.09381663113006397, 'roc_auc': 0.5066576}
==getted_scoring_result==
[fit 634/850] END C=0.00390625, kernel=linear; total=2625, TP=88, TN=837, FP=1663, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.352) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 11.01s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=95, TN=692, FP=1808, FN=30; precision=0.050, recall=0.760

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.300) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 95, 'TN': 692, 'FP': 1808, 'FN': 30, 'precision': 0.049921177088807146, 'recall': 0.76, 'accuracy': 0.2998095238095238, 'average_precision': 0.046417731780375046, 'balanced_accuracy': 0.5184, 'f1': 0.09368836291913214, 'roc_auc': 0.507424}
==getted_scoring_result==
[fit 635/850] END C=0.00390625, kernel=polynomial; total=2625, TP=95, TN=692, FP=1808, FN=30; precision=0.050, recall=0.760
accuracy: (test=0.300) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.094) roc_auc: (test=0.507) 10.13s
==get_scoring_result==
base_score: total=2625, TP=89, TN=814, FP=1686, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.344) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 814, 'FP': 1686, 'FN': 36, 'precision': 0.05014084507042253, 'recall': 0.712, 'accuracy': 0.344, 'average_precision': 0.04615559203448831, 'balanced_accuracy': 0.5187999999999999, 'f1': 0.09368421052631579, 'roc_auc': 0.5065312}
==getted_scoring_result==
[fit 636/850] END C=0.00390625, kernel=sigmoid; total=2625, TP=89, TN=814, FP=1686, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.344) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 10.06s
==get_scoring_result==
base_score: total=2625, TP=89, TN=827, FP=1673, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.349) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 827, 'FP': 1673, 'FN': 36, 'precision': 0.05051078320090806, 'recall': 0.712, 'accuracy': 0.34895238095238096, 'average_precision': 0.04617820992261874, 'balanced_accuracy': 0.5214, 'f1': 0.09432962374138845, 'roc_auc': 0.506616}
==getted_scoring_result==
[fit 637/850] END C=0.00390625, kernel=precomputed; total=2625, TP=89, TN=827, FP=1673, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.349) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 10.20s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1087, FP=1413, FN=51; precision=0.050, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.442) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.513) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.509) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1087, 'FP': 1413, 'FN': 51, 'precision': 0.04976462676529926, 'recall': 0.592, 'accuracy': 0.4422857142857143, 'average_precision': 0.04644098708146655, 'balanced_accuracy': 0.5134, 'f1': 0.09181141439205955, 'roc_auc': 0.5085584}
==getted_scoring_result==
[fit 638/850] END C=0.0078125, kernel=linear; total=2625, TP=74, TN=1087, FP=1413, FN=51; precision=0.050, recall=0.592
accuracy: (test=0.442) average_precision: (test=0.046) balanced_accuracy: (test=0.513) f1: (test=0.092) roc_auc: (test=0.509) 10.96s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 639/850] END C=0.0078125, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 10.00s
==get_scoring_result==
base_score: total=2625, TP=90, TN=796, FP=1704, FN=35; precision=0.050, recall=0.720

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.338) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 90, 'TN': 796, 'FP': 1704, 'FN': 35, 'precision': 0.05016722408026756, 'recall': 0.72, 'accuracy': 0.3375238095238095, 'average_precision': 0.04615220655164312, 'balanced_accuracy': 0.5192, 'f1': 0.09379885356956749, 'roc_auc': 0.5066016}
==getted_scoring_result==
[fit 640/850] END C=0.0078125, kernel=sigmoid; total=2625, TP=90, TN=796, FP=1704, FN=35; precision=0.050, recall=0.720
accuracy: (test=0.338) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.83s
==get_scoring_result==
base_score: total=2625, TP=88, TN=847, FP=1653, FN=37; precision=0.051, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 847, 'FP': 1653, 'FN': 37, 'precision': 0.05054566341183228, 'recall': 0.704, 'accuracy': 0.35619047619047617, 'average_precision': 0.04620255736912171, 'balanced_accuracy': 0.5214, 'f1': 0.09431939978563772, 'roc_auc': 0.5066464}
==getted_scoring_result==
[fit 641/850] END C=0.0078125, kernel=precomputed; total=2625, TP=88, TN=847, FP=1653, FN=37; precision=0.051, recall=0.704
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 9.91s
==get_scoring_result==
base_score: total=2625, TP=82, TN=930, FP=1570, FN=43; precision=0.050, recall=0.656

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.386) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.514) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.515) ===
score_result_dict: {'Total': 2625, 'TP': 82, 'TN': 930, 'FP': 1570, 'FN': 43, 'precision': 0.04963680387409201, 'recall': 0.656, 'accuracy': 0.38552380952380955, 'average_precision': 0.04705552563186315, 'balanced_accuracy': 0.514, 'f1': 0.09229037703995499, 'roc_auc': 0.5148784}
==getted_scoring_result==
[fit 642/850] END C=0.015625, kernel=linear; total=2625, TP=82, TN=930, FP=1570, FN=43; precision=0.050, recall=0.656
accuracy: (test=0.386) average_precision: (test=0.047) balanced_accuracy: (test=0.514) f1: (test=0.092) roc_auc: (test=0.515) 10.10s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 643/850] END C=0.015625, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.56s
==get_scoring_result==
base_score: total=2625, TP=89, TN=829, FP=1671, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.350) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 829, 'FP': 1671, 'FN': 36, 'precision': 0.05056818181818182, 'recall': 0.712, 'accuracy': 0.3497142857142857, 'average_precision': 0.046187051640494095, 'balanced_accuracy': 0.5218, 'f1': 0.09442970822281169, 'roc_auc': 0.5067216}
==getted_scoring_result==
[fit 644/850] END C=0.015625, kernel=sigmoid; total=2625, TP=89, TN=829, FP=1671, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.350) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.507) 10.04s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.04622350669208025, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.5065104}
==getted_scoring_result==
[fit 645/850] END C=0.015625, kernel=precomputed; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 10.09s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.520) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.523) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1298, 'FP': 1202, 'FN': 59, 'precision': 0.052050473186119876, 'recall': 0.528, 'accuracy': 0.5196190476190476, 'average_precision': 0.04818166270753325, 'balanced_accuracy': 0.5236000000000001, 'f1': 0.09475951184493898, 'roc_auc': 0.5230608}
==getted_scoring_result==
[fit 646/850] END C=0.03125, kernel=linear; total=2625, TP=66, TN=1298, FP=1202, FN=59; precision=0.052, recall=0.528
accuracy: (test=0.520) average_precision: (test=0.048) balanced_accuracy: (test=0.524) f1: (test=0.095) roc_auc: (test=0.523) 10.81s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 647/850] END C=0.03125, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.68s
==get_scoring_result==
base_score: total=2625, TP=88, TN=837, FP=1663, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.352) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 837, 'FP': 1663, 'FN': 37, 'precision': 0.05025699600228441, 'recall': 0.704, 'accuracy': 0.3523809523809524, 'average_precision': 0.04619370153696594, 'balanced_accuracy': 0.5194, 'f1': 0.09381663113006397, 'roc_auc': 0.5066272}
==getted_scoring_result==
[fit 648/850] END C=0.03125, kernel=sigmoid; total=2625, TP=88, TN=837, FP=1663, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.352) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 8.83s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.04622732745094625, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.5064944}
==getted_scoring_result==
[fit 649/850] END C=0.03125, kernel=precomputed; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 8.70s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1325, FP=1175, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.530) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.050) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.533) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.538) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1325, 'FP': 1175, 'FN': 58, 'precision': 0.05394524959742351, 'recall': 0.536, 'accuracy': 0.5302857142857142, 'average_precision': 0.050189063889327215, 'balanced_accuracy': 0.533, 'f1': 0.09802487198244329, 'roc_auc': 0.5376944}
==getted_scoring_result==
[fit 650/850] END C=0.0625, kernel=linear; total=2625, TP=67, TN=1325, FP=1175, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.530) average_precision: (test=0.050) balanced_accuracy: (test=0.533) f1: (test=0.098) roc_auc: (test=0.538) 9.98s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 651/850] END C=0.0625, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.39s
==get_scoring_result==
base_score: total=2625, TP=88, TN=835, FP=1665, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.352) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 835, 'FP': 1665, 'FN': 37, 'precision': 0.05019965772960639, 'recall': 0.704, 'accuracy': 0.3516190476190476, 'average_precision': 0.04619555344359161, 'balanced_accuracy': 0.519, 'f1': 0.09371671991480299, 'roc_auc': 0.5065968}
==getted_scoring_result==
[fit 652/850] END C=0.0625, kernel=sigmoid; total=2625, TP=88, TN=835, FP=1665, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.352) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.59s
==get_scoring_result==
base_score: total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 855, 'FP': 1645, 'FN': 38, 'precision': 0.05023094688221709, 'recall': 0.696, 'accuracy': 0.3588571428571429, 'average_precision': 0.04621569964076963, 'balanced_accuracy': 0.519, 'f1': 0.09369951534733441, 'roc_auc': 0.5066656}
==getted_scoring_result==
[fit 653/850] END C=0.0625, kernel=precomputed; total=2625, TP=87, TN=855, FP=1645, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.56s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1354, FP=1146, FN=56; precision=0.057, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.542) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.053) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.547) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.556) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1354, 'FP': 1146, 'FN': 56, 'precision': 0.056790123456790124, 'recall': 0.552, 'accuracy': 0.5420952380952381, 'average_precision': 0.05333294683797827, 'balanced_accuracy': 0.5468, 'f1': 0.10298507462686568, 'roc_auc': 0.556376}
==getted_scoring_result==
[fit 654/850] END C=0.125, kernel=linear; total=2625, TP=69, TN=1354, FP=1146, FN=56; precision=0.057, recall=0.552
accuracy: (test=0.542) average_precision: (test=0.053) balanced_accuracy: (test=0.547) f1: (test=0.103) roc_auc: (test=0.556) 10.27s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 655/850] END C=0.125, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.46s
==get_scoring_result==
base_score: total=2625, TP=89, TN=835, FP=1665, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.352) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.523) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 835, 'FP': 1665, 'FN': 36, 'precision': 0.05074116305587229, 'recall': 0.712, 'accuracy': 0.352, 'average_precision': 0.046225005163239005, 'balanced_accuracy': 0.523, 'f1': 0.09473124002128792, 'roc_auc': 0.5067648}
==getted_scoring_result==
[fit 656/850] END C=0.125, kernel=sigmoid; total=2625, TP=89, TN=835, FP=1665, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.352) average_precision: (test=0.046) balanced_accuracy: (test=0.523) f1: (test=0.095) roc_auc: (test=0.507) 9.29s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.04623426444169992, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.5065968}
==getted_scoring_result==
[fit 657/850] END C=0.125, kernel=precomputed; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.51s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1399, FP=1101, FN=58; precision=0.057, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.558) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.058) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.548) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.104) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.580) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1399, 'FP': 1101, 'FN': 58, 'precision': 0.05736301369863014, 'recall': 0.536, 'accuracy': 0.5584761904761905, 'average_precision': 0.05821131193049507, 'balanced_accuracy': 0.5478000000000001, 'f1': 0.10363495746326372, 'roc_auc': 0.5797248}
==getted_scoring_result==
[fit 658/850] END C=0.25, kernel=linear; total=2625, TP=67, TN=1399, FP=1101, FN=58; precision=0.057, recall=0.536
accuracy: (test=0.558) average_precision: (test=0.058) balanced_accuracy: (test=0.548) f1: (test=0.104) roc_auc: (test=0.580) 10.46s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 659/850] END C=0.25, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.23s
==get_scoring_result==
base_score: total=2625, TP=89, TN=835, FP=1665, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.352) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.523) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 835, 'FP': 1665, 'FN': 36, 'precision': 0.05074116305587229, 'recall': 0.712, 'accuracy': 0.352, 'average_precision': 0.046225005163239005, 'balanced_accuracy': 0.523, 'f1': 0.09473124002128792, 'roc_auc': 0.5067648}
==getted_scoring_result==
[fit 660/850] END C=0.25, kernel=sigmoid; total=2625, TP=89, TN=835, FP=1665, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.352) average_precision: (test=0.046) balanced_accuracy: (test=0.523) f1: (test=0.095) roc_auc: (test=0.507) 9.49s
==get_scoring_result==
base_score: total=2625, TP=87, TN=860, FP=1640, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.361) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 860, 'FP': 1640, 'FN': 38, 'precision': 0.05037637521713955, 'recall': 0.696, 'accuracy': 0.3607619047619048, 'average_precision': 0.04623881795956241, 'balanced_accuracy': 0.52, 'f1': 0.09395248380129591, 'roc_auc': 0.5066704}
==getted_scoring_result==
[fit 661/850] END C=0.25, kernel=precomputed; total=2625, TP=87, TN=860, FP=1640, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.361) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.36s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1478, FP=1022, FN=57; precision=0.062, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.589) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.065) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.568) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.112) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.605) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1478, 'FP': 1022, 'FN': 57, 'precision': 0.062385321100917435, 'recall': 0.544, 'accuracy': 0.588952380952381, 'average_precision': 0.06546174364987073, 'balanced_accuracy': 0.5676, 'f1': 0.11193415637860084, 'roc_auc': 0.6046528}
==getted_scoring_result==
[fit 662/850] END C=0.5, kernel=linear; total=2625, TP=68, TN=1478, FP=1022, FN=57; precision=0.062, recall=0.544
accuracy: (test=0.589) average_precision: (test=0.065) balanced_accuracy: (test=0.568) f1: (test=0.112) roc_auc: (test=0.605) 10.47s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 663/850] END C=0.5, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.29s
==get_scoring_result==
base_score: total=2625, TP=88, TN=837, FP=1663, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.352) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 837, 'FP': 1663, 'FN': 37, 'precision': 0.05025699600228441, 'recall': 0.704, 'accuracy': 0.3523809523809524, 'average_precision': 0.046200610992139346, 'balanced_accuracy': 0.5194, 'f1': 0.09381663113006397, 'roc_auc': 0.5066576}
==getted_scoring_result==
[fit 664/850] END C=0.5, kernel=sigmoid; total=2625, TP=88, TN=837, FP=1663, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.352) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.14s
==get_scoring_result==
base_score: total=2625, TP=86, TN=883, FP=1617, FN=39; precision=0.050, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.369) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 883, 'FP': 1617, 'FN': 39, 'precision': 0.05049911920140928, 'recall': 0.688, 'accuracy': 0.36914285714285716, 'average_precision': 0.0462581861663853, 'balanced_accuracy': 0.5206, 'f1': 0.09409190371991248, 'roc_auc': 0.5072736}
==getted_scoring_result==
[fit 665/850] END C=0.5, kernel=precomputed; total=2625, TP=86, TN=883, FP=1617, FN=39; precision=0.050, recall=0.688
accuracy: (test=0.369) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 9.28s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1501, FP=999, FN=56; precision=0.065, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.598) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.075) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.576) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.116) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.627) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1501, 'FP': 999, 'FN': 56, 'precision': 0.06460674157303371, 'recall': 0.552, 'accuracy': 0.5980952380952381, 'average_precision': 0.07483736546478818, 'balanced_accuracy': 0.5762, 'f1': 0.115674769488684, 'roc_auc': 0.6271456}
==getted_scoring_result==
[fit 666/850] END C=1.0, kernel=linear; total=2625, TP=69, TN=1501, FP=999, FN=56; precision=0.065, recall=0.552
accuracy: (test=0.598) average_precision: (test=0.075) balanced_accuracy: (test=0.576) f1: (test=0.116) roc_auc: (test=0.627) 10.93s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 667/850] END C=1.0, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 10.01s
==get_scoring_result==
base_score: total=2625, TP=88, TN=840, FP=1660, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.354) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 840, 'FP': 1660, 'FN': 37, 'precision': 0.05034324942791762, 'recall': 0.704, 'accuracy': 0.3535238095238095, 'average_precision': 0.04621279709739961, 'balanced_accuracy': 0.52, 'f1': 0.09396689802455954, 'roc_auc': 0.506904}
==getted_scoring_result==
[fit 668/850] END C=1.0, kernel=sigmoid; total=2625, TP=88, TN=840, FP=1660, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.354) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.06s
==get_scoring_result==
base_score: total=2625, TP=65, TN=1228, FP=1272, FN=60; precision=0.049, recall=0.520

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.493) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.506) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.089) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.511) ===
score_result_dict: {'Total': 2625, 'TP': 65, 'TN': 1228, 'FP': 1272, 'FN': 60, 'precision': 0.048616305160807775, 'recall': 0.52, 'accuracy': 0.49257142857142855, 'average_precision': 0.04661942773534907, 'balanced_accuracy': 0.5056, 'f1': 0.08891928864569083, 'roc_auc': 0.5107248}
==getted_scoring_result==
[fit 669/850] END C=1.0, kernel=precomputed; total=2625, TP=65, TN=1228, FP=1272, FN=60; precision=0.049, recall=0.520
accuracy: (test=0.493) average_precision: (test=0.047) balanced_accuracy: (test=0.506) f1: (test=0.089) roc_auc: (test=0.511) 10.16s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1562, FP=938, FN=53; precision=0.071, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.622) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.082) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.600) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.127) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.644) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1562, 'FP': 938, 'FN': 53, 'precision': 0.07128712871287128, 'recall': 0.576, 'accuracy': 0.6224761904761905, 'average_precision': 0.08228254219050124, 'balanced_accuracy': 0.6004, 'f1': 0.12687224669603525, 'roc_auc': 0.6443264}
==getted_scoring_result==
[fit 670/850] END C=2.0, kernel=linear; total=2625, TP=72, TN=1562, FP=938, FN=53; precision=0.071, recall=0.576
accuracy: (test=0.622) average_precision: (test=0.082) balanced_accuracy: (test=0.600) f1: (test=0.127) roc_auc: (test=0.644) 12.14s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 671/850] END C=2.0, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 10.02s
==get_scoring_result==
base_score: total=2625, TP=76, TN=1050, FP=1450, FN=49; precision=0.050, recall=0.608

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.429) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.514) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.092) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.511) ===
score_result_dict: {'Total': 2625, 'TP': 76, 'TN': 1050, 'FP': 1450, 'FN': 49, 'precision': 0.04980340760157274, 'recall': 0.608, 'accuracy': 0.428952380952381, 'average_precision': 0.046656811776103174, 'balanced_accuracy': 0.514, 'f1': 0.09206541490006055, 'roc_auc': 0.5108192}
==getted_scoring_result==
[fit 672/850] END C=2.0, kernel=sigmoid; total=2625, TP=76, TN=1050, FP=1450, FN=49; precision=0.050, recall=0.608
accuracy: (test=0.429) average_precision: (test=0.047) balanced_accuracy: (test=0.514) f1: (test=0.092) roc_auc: (test=0.511) 10.00s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1298, FP=1202, FN=58; precision=0.053, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.520) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.528) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.518) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1298, 'FP': 1202, 'FN': 58, 'precision': 0.05279747832939322, 'recall': 0.536, 'accuracy': 0.52, 'average_precision': 0.04752862888750878, 'balanced_accuracy': 0.5276000000000001, 'f1': 0.09612625538020086, 'roc_auc': 0.5181024}
==getted_scoring_result==
[fit 673/850] END C=2.0, kernel=precomputed; total=2625, TP=67, TN=1298, FP=1202, FN=58; precision=0.053, recall=0.536
accuracy: (test=0.520) average_precision: (test=0.048) balanced_accuracy: (test=0.528) f1: (test=0.096) roc_auc: (test=0.518) 10.34s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1580, FP=920, FN=52; precision=0.074, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.630) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.608) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.653) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1580, 'FP': 920, 'FN': 52, 'precision': 0.07351460221550855, 'recall': 0.584, 'accuracy': 0.6297142857142857, 'average_precision': 0.08603424148934918, 'balanced_accuracy': 0.608, 'f1': 0.13059033989266547, 'roc_auc': 0.653264}
==getted_scoring_result==
[fit 674/850] END C=4.0, kernel=linear; total=2625, TP=73, TN=1580, FP=920, FN=52; precision=0.074, recall=0.584
accuracy: (test=0.630) average_precision: (test=0.086) balanced_accuracy: (test=0.608) f1: (test=0.131) roc_auc: (test=0.653) 12.48s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 675/850] END C=4.0, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.15s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1298, FP=1202, FN=58; precision=0.053, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.520) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.528) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.518) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1298, 'FP': 1202, 'FN': 58, 'precision': 0.05279747832939322, 'recall': 0.536, 'accuracy': 0.52, 'average_precision': 0.04753349149181778, 'balanced_accuracy': 0.5276000000000001, 'f1': 0.09612625538020086, 'roc_auc': 0.5181376}
==getted_scoring_result==
[fit 676/850] END C=4.0, kernel=sigmoid; total=2625, TP=67, TN=1298, FP=1202, FN=58; precision=0.053, recall=0.536
accuracy: (test=0.520) average_precision: (test=0.048) balanced_accuracy: (test=0.528) f1: (test=0.096) roc_auc: (test=0.518) 8.49s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1304, FP=1196, FN=59; precision=0.052, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.522) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.049) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.525) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.528) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1304, 'FP': 1196, 'FN': 59, 'precision': 0.05229793977812995, 'recall': 0.528, 'accuracy': 0.5219047619047619, 'average_precision': 0.04880116302137495, 'balanced_accuracy': 0.5247999999999999, 'f1': 0.09516943042537851, 'roc_auc': 0.5283456}
==getted_scoring_result==
[fit 677/850] END C=4.0, kernel=precomputed; total=2625, TP=66, TN=1304, FP=1196, FN=59; precision=0.052, recall=0.528
accuracy: (test=0.522) average_precision: (test=0.049) balanced_accuracy: (test=0.525) f1: (test=0.095) roc_auc: (test=0.528) 8.39s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1588, FP=912, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.632) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.656) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1588, 'FP': 912, 'FN': 53, 'precision': 0.07317073170731707, 'recall': 0.576, 'accuracy': 0.6323809523809524, 'average_precision': 0.0857760632649918, 'balanced_accuracy': 0.6055999999999999, 'f1': 0.12984670874661858, 'roc_auc': 0.65644}
==getted_scoring_result==
[fit 678/850] END C=8.0, kernel=linear; total=2625, TP=72, TN=1588, FP=912, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.632) average_precision: (test=0.086) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.656) 11.66s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 679/850] END C=8.0, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.34s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1303, FP=1197, FN=59; precision=0.052, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.522) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.049) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.525) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.528) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1303, 'FP': 1197, 'FN': 59, 'precision': 0.052256532066508314, 'recall': 0.528, 'accuracy': 0.5215238095238095, 'average_precision': 0.04880536131867004, 'balanced_accuracy': 0.5246, 'f1': 0.09510086455331412, 'roc_auc': 0.5283584}
==getted_scoring_result==
[fit 680/850] END C=8.0, kernel=sigmoid; total=2625, TP=66, TN=1303, FP=1197, FN=59; precision=0.052, recall=0.528
accuracy: (test=0.522) average_precision: (test=0.049) balanced_accuracy: (test=0.525) f1: (test=0.095) roc_auc: (test=0.528) 9.78s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1334, FP=1166, FN=59; precision=0.054, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.533) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.051) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.531) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.097) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.545) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1334, 'FP': 1166, 'FN': 59, 'precision': 0.05357142857142857, 'recall': 0.528, 'accuracy': 0.5333333333333333, 'average_precision': 0.051343961172059464, 'balanced_accuracy': 0.5307999999999999, 'f1': 0.09727339719970522, 'roc_auc': 0.5447104}
==getted_scoring_result==
[fit 681/850] END C=8.0, kernel=precomputed; total=2625, TP=66, TN=1334, FP=1166, FN=59; precision=0.054, recall=0.528
accuracy: (test=0.533) average_precision: (test=0.051) balanced_accuracy: (test=0.531) f1: (test=0.097) roc_auc: (test=0.545) 9.70s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1601, FP=899, FN=53; precision=0.074, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.637) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.608) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.657) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1601, 'FP': 899, 'FN': 53, 'precision': 0.07415036045314109, 'recall': 0.576, 'accuracy': 0.6373333333333333, 'average_precision': 0.08457208270551148, 'balanced_accuracy': 0.6082, 'f1': 0.13138686131386862, 'roc_auc': 0.65736}
==getted_scoring_result==
[fit 682/850] END C=16.0, kernel=linear; total=2625, TP=72, TN=1601, FP=899, FN=53; precision=0.074, recall=0.576
accuracy: (test=0.637) average_precision: (test=0.085) balanced_accuracy: (test=0.608) f1: (test=0.131) roc_auc: (test=0.657) 13.34s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 683/850] END C=16.0, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.38s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1332, FP=1168, FN=59; precision=0.053, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.533) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.051) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.530) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.097) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.545) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1332, 'FP': 1168, 'FN': 59, 'precision': 0.05348460291734198, 'recall': 0.528, 'accuracy': 0.5325714285714286, 'average_precision': 0.05134506132600473, 'balanced_accuracy': 0.5304, 'f1': 0.09713024282560706, 'roc_auc': 0.5445856}
==getted_scoring_result==
[fit 684/850] END C=16.0, kernel=sigmoid; total=2625, TP=66, TN=1332, FP=1168, FN=59; precision=0.053, recall=0.528
accuracy: (test=0.533) average_precision: (test=0.051) balanced_accuracy: (test=0.530) f1: (test=0.097) roc_auc: (test=0.545) 9.44s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1373, FP=1127, FN=57; precision=0.057, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.549) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.055) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.547) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.566) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1373, 'FP': 1127, 'FN': 57, 'precision': 0.05690376569037657, 'recall': 0.544, 'accuracy': 0.548952380952381, 'average_precision': 0.055066627141419036, 'balanced_accuracy': 0.5466, 'f1': 0.10303030303030303, 'roc_auc': 0.5656}
==getted_scoring_result==
[fit 685/850] END C=16.0, kernel=precomputed; total=2625, TP=68, TN=1373, FP=1127, FN=57; precision=0.057, recall=0.544
accuracy: (test=0.549) average_precision: (test=0.055) balanced_accuracy: (test=0.547) f1: (test=0.103) roc_auc: (test=0.566) 9.41s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1598, FP=902, FN=54; precision=0.073, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.636) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.604) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.129) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.659) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1598, 'FP': 902, 'FN': 54, 'precision': 0.07297019527235354, 'recall': 0.568, 'accuracy': 0.6358095238095238, 'average_precision': 0.08461685389220772, 'balanced_accuracy': 0.6035999999999999, 'f1': 0.12932604735883424, 'roc_auc': 0.658816}
==getted_scoring_result==
[fit 686/850] END C=32.0, kernel=linear; total=2625, TP=71, TN=1598, FP=902, FN=54; precision=0.073, recall=0.568
accuracy: (test=0.636) average_precision: (test=0.085) balanced_accuracy: (test=0.604) f1: (test=0.129) roc_auc: (test=0.659) 14.53s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 687/850] END C=32.0, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.10s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1373, FP=1127, FN=57; precision=0.057, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.549) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.055) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.547) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.103) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.566) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1373, 'FP': 1127, 'FN': 57, 'precision': 0.05690376569037657, 'recall': 0.544, 'accuracy': 0.548952380952381, 'average_precision': 0.05510517430188956, 'balanced_accuracy': 0.5466, 'f1': 0.10303030303030303, 'roc_auc': 0.5658528}
==getted_scoring_result==
[fit 688/850] END C=32.0, kernel=sigmoid; total=2625, TP=68, TN=1373, FP=1127, FN=57; precision=0.057, recall=0.544
accuracy: (test=0.549) average_precision: (test=0.055) balanced_accuracy: (test=0.547) f1: (test=0.103) roc_auc: (test=0.566) 9.44s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=67, TN=1442, FP=1058, FN=58; precision=0.060, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.575) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.061) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.556) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.107) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.590) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1442, 'FP': 1058, 'FN': 58, 'precision': 0.059555555555555556, 'recall': 0.536, 'accuracy': 0.5748571428571428, 'average_precision': 0.0607584675171514, 'balanced_accuracy': 0.5564, 'f1': 0.10719999999999999, 'roc_auc': 0.5898976}
==getted_scoring_result==
[fit 689/850] END C=32.0, kernel=precomputed; total=2625, TP=67, TN=1442, FP=1058, FN=58; precision=0.060, recall=0.536
accuracy: (test=0.575) average_precision: (test=0.061) balanced_accuracy: (test=0.556) f1: (test=0.107) roc_auc: (test=0.590) 9.56s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1600, FP=900, FN=53; precision=0.074, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.637) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.608) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.659) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1600, 'FP': 900, 'FN': 53, 'precision': 0.07407407407407407, 'recall': 0.576, 'accuracy': 0.6369523809523809, 'average_precision': 0.0842664650240908, 'balanced_accuracy': 0.608, 'f1': 0.13126709206927983, 'roc_auc': 0.6594544}
==getted_scoring_result==
[fit 690/850] END C=64.0, kernel=linear; total=2625, TP=72, TN=1600, FP=900, FN=53; precision=0.074, recall=0.576
accuracy: (test=0.637) average_precision: (test=0.084) balanced_accuracy: (test=0.608) f1: (test=0.131) roc_auc: (test=0.659) 18.97s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.046425033045774264, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.5063968}
==getted_scoring_result==
[fit 691/850] END C=64.0, kernel=polynomial; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.506) 9.01s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=67, TN=1443, FP=1057, FN=58; precision=0.060, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.575) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.061) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.557) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.107) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.590) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1443, 'FP': 1057, 'FN': 58, 'precision': 0.059608540925266906, 'recall': 0.536, 'accuracy': 0.5752380952380952, 'average_precision': 0.06078378061237623, 'balanced_accuracy': 0.5566, 'f1': 0.10728582866293035, 'roc_auc': 0.5899488}
==getted_scoring_result==
[fit 692/850] END C=64.0, kernel=sigmoid; total=2625, TP=67, TN=1443, FP=1057, FN=58; precision=0.060, recall=0.536
accuracy: (test=0.575) average_precision: (test=0.061) balanced_accuracy: (test=0.557) f1: (test=0.107) roc_auc: (test=0.590) 9.47s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=68, TN=1485, FP=1015, FN=57; precision=0.063, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.592) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.069) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.569) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.113) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.615) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1485, 'FP': 1015, 'FN': 57, 'precision': 0.06278855032317636, 'recall': 0.544, 'accuracy': 0.5916190476190476, 'average_precision': 0.069375655785094, 'balanced_accuracy': 0.569, 'f1': 0.11258278145695365, 'roc_auc': 0.614776}
==getted_scoring_result==
[fit 693/850] END C=64.0, kernel=precomputed; total=2625, TP=68, TN=1485, FP=1015, FN=57; precision=0.063, recall=0.544
accuracy: (test=0.592) average_precision: (test=0.069) balanced_accuracy: (test=0.569) f1: (test=0.113) roc_auc: (test=0.615) 10.01s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1593, FP=907, FN=53; precision=0.074, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.634) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.607) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.660) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1593, 'FP': 907, 'FN': 53, 'precision': 0.0735444330949949, 'recall': 0.576, 'accuracy': 0.6342857142857142, 'average_precision': 0.08417028944477797, 'balanced_accuracy': 0.6066, 'f1': 0.13043478260869565, 'roc_auc': 0.6599648}
==getted_scoring_result==
[fit 694/850] END C=128.0, kernel=linear; total=2625, TP=72, TN=1593, FP=907, FN=53; precision=0.074, recall=0.576
accuracy: (test=0.634) average_precision: (test=0.084) balanced_accuracy: (test=0.607) f1: (test=0.130) roc_auc: (test=0.660) 29.65s
==get_scoring_result==
base_score: total=2625, TP=92, TN=754, FP=1746, FN=33; precision=0.050, recall=0.736

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.322) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 92, 'TN': 754, 'FP': 1746, 'FN': 33, 'precision': 0.05005440696409141, 'recall': 0.736, 'accuracy': 0.3222857142857143, 'average_precision': 0.046391736280686005, 'balanced_accuracy': 0.5187999999999999, 'f1': 0.0937340804890474, 'roc_auc': 0.5066128}
==getted_scoring_result==
[fit 695/850] END C=128.0, kernel=polynomial; total=2625, TP=92, TN=754, FP=1746, FN=33; precision=0.050, recall=0.736
accuracy: (test=0.322) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 10.42s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1485, FP=1015, FN=57; precision=0.063, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.592) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.069) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.569) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.113) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.615) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1485, 'FP': 1015, 'FN': 57, 'precision': 0.06278855032317636, 'recall': 0.544, 'accuracy': 0.5916190476190476, 'average_precision': 0.06939744092520311, 'balanced_accuracy': 0.569, 'f1': 0.11258278145695365, 'roc_auc': 0.614752}
==getted_scoring_result==
[fit 696/850] END C=128.0, kernel=sigmoid; total=2625, TP=68, TN=1485, FP=1015, FN=57; precision=0.063, recall=0.544
accuracy: (test=0.592) average_precision: (test=0.069) balanced_accuracy: (test=0.569) f1: (test=0.113) roc_auc: (test=0.615) 11.00s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1536, FP=964, FN=54; precision=0.069, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.612) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.078) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.591) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.122) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.635) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1536, 'FP': 964, 'FN': 54, 'precision': 0.06859903381642513, 'recall': 0.568, 'accuracy': 0.6121904761904762, 'average_precision': 0.07810578164728504, 'balanced_accuracy': 0.5912, 'f1': 0.12241379310344828, 'roc_auc': 0.6348032}
==getted_scoring_result==
[fit 697/850] END C=128.0, kernel=precomputed; total=2625, TP=71, TN=1536, FP=964, FN=54; precision=0.069, recall=0.568
accuracy: (test=0.612) average_precision: (test=0.078) balanced_accuracy: (test=0.591) f1: (test=0.122) roc_auc: (test=0.635) 11.48s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1595, FP=905, FN=52; precision=0.075, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.635) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.611) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.132) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.661) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1595, 'FP': 905, 'FN': 52, 'precision': 0.07464212678936605, 'recall': 0.584, 'accuracy': 0.6354285714285715, 'average_precision': 0.08443850464630359, 'balanced_accuracy': 0.611, 'f1': 0.13236627379873073, 'roc_auc': 0.661376}
==getted_scoring_result==
[fit 698/850] END C=256.0, kernel=linear; total=2625, TP=73, TN=1595, FP=905, FN=52; precision=0.075, recall=0.584
accuracy: (test=0.635) average_precision: (test=0.084) balanced_accuracy: (test=0.611) f1: (test=0.132) roc_auc: (test=0.661) 47.84s
==get_scoring_result==
base_score: total=2625, TP=90, TN=791, FP=1709, FN=35; precision=0.050, recall=0.720

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.336) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 90, 'TN': 791, 'FP': 1709, 'FN': 35, 'precision': 0.0500277932184547, 'recall': 0.72, 'accuracy': 0.3356190476190476, 'average_precision': 0.04638878949525821, 'balanced_accuracy': 0.5182, 'f1': 0.09355509355509356, 'roc_auc': 0.506576}
==getted_scoring_result==
[fit 699/850] END C=256.0, kernel=polynomial; total=2625, TP=90, TN=791, FP=1709, FN=35; precision=0.050, recall=0.720
accuracy: (test=0.336) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.094) roc_auc: (test=0.507) 9.41s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1535, FP=965, FN=54; precision=0.069, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.612) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.078) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.591) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.122) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.634) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1535, 'FP': 965, 'FN': 54, 'precision': 0.06853281853281853, 'recall': 0.568, 'accuracy': 0.6118095238095238, 'average_precision': 0.07797680219210423, 'balanced_accuracy': 0.591, 'f1': 0.1223083548664944, 'roc_auc': 0.6344224}
==getted_scoring_result==
[fit 700/850] END C=256.0, kernel=sigmoid; total=2625, TP=71, TN=1535, FP=965, FN=54; precision=0.069, recall=0.568
accuracy: (test=0.612) average_precision: (test=0.078) balanced_accuracy: (test=0.591) f1: (test=0.122) roc_auc: (test=0.634) 10.43s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1560, FP=940, FN=56; precision=0.068, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.621) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.588) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.122) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.649) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1560, 'FP': 940, 'FN': 56, 'precision': 0.06838453914767097, 'recall': 0.552, 'accuracy': 0.6205714285714286, 'average_precision': 0.08467908406327823, 'balanced_accuracy': 0.5880000000000001, 'f1': 0.12169312169312171, 'roc_auc': 0.6489792}
==getted_scoring_result==
[fit 701/850] END C=256.0, kernel=precomputed; total=2625, TP=69, TN=1560, FP=940, FN=56; precision=0.068, recall=0.552
accuracy: (test=0.621) average_precision: (test=0.085) balanced_accuracy: (test=0.588) f1: (test=0.122) roc_auc: (test=0.649) 10.91s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1595, FP=905, FN=52; precision=0.075, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.635) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.611) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.132) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.662) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1595, 'FP': 905, 'FN': 52, 'precision': 0.07464212678936605, 'recall': 0.584, 'accuracy': 0.6354285714285715, 'average_precision': 0.08490473932360315, 'balanced_accuracy': 0.611, 'f1': 0.13236627379873073, 'roc_auc': 0.662376}
==getted_scoring_result==
[fit 702/850] END C=512.0, kernel=linear; total=2625, TP=73, TN=1595, FP=905, FN=52; precision=0.075, recall=0.584
accuracy: (test=0.635) average_precision: (test=0.085) balanced_accuracy: (test=0.611) f1: (test=0.132) roc_auc: (test=0.662) 1.50min
==get_scoring_result==
base_score: total=2625, TP=89, TN=819, FP=1681, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 819, 'FP': 1681, 'FN': 36, 'precision': 0.05028248587570622, 'recall': 0.712, 'accuracy': 0.3459047619047619, 'average_precision': 0.04638322808236753, 'balanced_accuracy': 0.5198, 'f1': 0.09393139841688654, 'roc_auc': 0.506432}
==getted_scoring_result==
[fit 703/850] END C=512.0, kernel=polynomial; total=2625, TP=89, TN=819, FP=1681, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.506) 9.97s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1564, FP=936, FN=56; precision=0.069, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.622) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.589) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.122) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.649) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1564, 'FP': 936, 'FN': 56, 'precision': 0.06865671641791045, 'recall': 0.552, 'accuracy': 0.6220952380952381, 'average_precision': 0.08461298748951543, 'balanced_accuracy': 0.5888, 'f1': 0.12212389380530972, 'roc_auc': 0.6488336}
==getted_scoring_result==
[fit 704/850] END C=512.0, kernel=sigmoid; total=2625, TP=69, TN=1564, FP=936, FN=56; precision=0.069, recall=0.552
accuracy: (test=0.622) average_precision: (test=0.085) balanced_accuracy: (test=0.589) f1: (test=0.122) roc_auc: (test=0.649) 11.04s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1581, FP=919, FN=51; precision=0.075, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.630) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.612) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.132) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.656) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1581, 'FP': 919, 'FN': 51, 'precision': 0.07452165156092648, 'recall': 0.592, 'accuracy': 0.6304761904761905, 'average_precision': 0.08622180713058793, 'balanced_accuracy': 0.6122, 'f1': 0.1323792486583184, 'roc_auc': 0.6555776}
==getted_scoring_result==
[fit 705/850] END C=512.0, kernel=precomputed; total=2625, TP=74, TN=1581, FP=919, FN=51; precision=0.075, recall=0.592
accuracy: (test=0.630) average_precision: (test=0.086) balanced_accuracy: (test=0.612) f1: (test=0.132) roc_auc: (test=0.656) 10.86s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1588, FP=912, FN=51; precision=0.075, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.633) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.614) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.133) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.662) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1588, 'FP': 912, 'FN': 51, 'precision': 0.07505070993914807, 'recall': 0.592, 'accuracy': 0.6331428571428571, 'average_precision': 0.0844631327586399, 'balanced_accuracy': 0.6135999999999999, 'f1': 0.1332133213321332, 'roc_auc': 0.6615312}
==getted_scoring_result==
[fit 706/850] END C=1024.0, kernel=linear; total=2625, TP=74, TN=1588, FP=912, FN=51; precision=0.075, recall=0.592
accuracy: (test=0.633) average_precision: (test=0.084) balanced_accuracy: (test=0.614) f1: (test=0.133) roc_auc: (test=0.662) 2.66min
==get_scoring_result==
base_score: total=2625, TP=89, TN=815, FP=1685, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.344) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 815, 'FP': 1685, 'FN': 36, 'precision': 0.050169109357384445, 'recall': 0.712, 'accuracy': 0.3443809523809524, 'average_precision': 0.04636249691959317, 'balanced_accuracy': 0.519, 'f1': 0.0937335439705108, 'roc_auc': 0.5064704}
==getted_scoring_result==
[fit 707/850] END C=1024.0, kernel=polynomial; total=2625, TP=89, TN=815, FP=1685, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.344) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 11.80s
==get_scoring_result==
base_score: total=2625, TP=73, TN=1586, FP=914, FN=52; precision=0.074, recall=0.584

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.632) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.086) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.609) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.655) ===
score_result_dict: {'Total': 2625, 'TP': 73, 'TN': 1586, 'FP': 914, 'FN': 52, 'precision': 0.07396149949341439, 'recall': 0.584, 'accuracy': 0.632, 'average_precision': 0.08612110785459566, 'balanced_accuracy': 0.6092, 'f1': 0.131294964028777, 'roc_auc': 0.6551392}
==getted_scoring_result==
[fit 708/850] END C=1024.0, kernel=sigmoid; total=2625, TP=73, TN=1586, FP=914, FN=52; precision=0.074, recall=0.584
accuracy: (test=0.632) average_precision: (test=0.086) balanced_accuracy: (test=0.609) f1: (test=0.131) roc_auc: (test=0.655) 12.73s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1594, FP=906, FN=54; precision=0.073, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.634) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.603) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.129) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.658) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1594, 'FP': 906, 'FN': 54, 'precision': 0.07267144319344933, 'recall': 0.568, 'accuracy': 0.6342857142857142, 'average_precision': 0.08549983874219877, 'balanced_accuracy': 0.6028, 'f1': 0.12885662431941924, 'roc_auc': 0.6584384}
==getted_scoring_result==
[fit 709/850] END C=1024.0, kernel=precomputed; total=2625, TP=71, TN=1594, FP=906, FN=54; precision=0.073, recall=0.568
accuracy: (test=0.634) average_precision: (test=0.085) balanced_accuracy: (test=0.603) f1: (test=0.129) roc_auc: (test=0.658) 13.19s
==get_scoring_result==
base_score: total=2625, TP=74, TN=1588, FP=912, FN=51; precision=0.075, recall=0.592

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.633) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.614) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.133) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.660) ===
score_result_dict: {'Total': 2625, 'TP': 74, 'TN': 1588, 'FP': 912, 'FN': 51, 'precision': 0.07505070993914807, 'recall': 0.592, 'accuracy': 0.6331428571428571, 'average_precision': 0.0842461157099198, 'balanced_accuracy': 0.6135999999999999, 'f1': 0.1332133213321332, 'roc_auc': 0.6595936}
==getted_scoring_result==
[fit 710/850] END C=2048.0, kernel=linear; total=2625, TP=74, TN=1588, FP=912, FN=51; precision=0.075, recall=0.592
accuracy: (test=0.633) average_precision: (test=0.084) balanced_accuracy: (test=0.614) f1: (test=0.133) roc_auc: (test=0.660) 5.51min
==get_scoring_result==
base_score: total=2625, TP=89, TN=824, FP=1676, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.348) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 824, 'FP': 1676, 'FN': 36, 'precision': 0.05042492917847025, 'recall': 0.712, 'accuracy': 0.3478095238095238, 'average_precision': 0.04637805841107421, 'balanced_accuracy': 0.5207999999999999, 'f1': 0.09417989417989417, 'roc_auc': 0.5064928}
==getted_scoring_result==
[fit 711/850] END C=2048.0, kernel=polynomial; total=2625, TP=89, TN=824, FP=1676, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.348) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.506) 9.37s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1591, FP=909, FN=54; precision=0.072, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.633) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.602) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.129) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.657) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1591, 'FP': 909, 'FN': 54, 'precision': 0.07244897959183673, 'recall': 0.568, 'accuracy': 0.6331428571428571, 'average_precision': 0.08549700663908555, 'balanced_accuracy': 0.6022, 'f1': 0.12850678733031673, 'roc_auc': 0.6574336}
==getted_scoring_result==
[fit 712/850] END C=2048.0, kernel=sigmoid; total=2625, TP=71, TN=1591, FP=909, FN=54; precision=0.072, recall=0.568
accuracy: (test=0.633) average_precision: (test=0.085) balanced_accuracy: (test=0.602) f1: (test=0.129) roc_auc: (test=0.657) 11.37s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1589, FP=911, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.633) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.606) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.659) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1589, 'FP': 911, 'FN': 53, 'precision': 0.07324516785350967, 'recall': 0.576, 'accuracy': 0.6327619047619047, 'average_precision': 0.08480785709987113, 'balanced_accuracy': 0.6058, 'f1': 0.12996389891696752, 'roc_auc': 0.6592}
==getted_scoring_result==
[fit 713/850] END C=2048.0, kernel=precomputed; total=2625, TP=72, TN=1589, FP=911, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.633) average_precision: (test=0.085) balanced_accuracy: (test=0.606) f1: (test=0.130) roc_auc: (test=0.659) 12.52s
==get_scoring_result==
base_score: total=2625, TP=80, TN=1543, FP=957, FN=45; precision=0.077, recall=0.640

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.618) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.082) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.629) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.138) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.650) ===
score_result_dict: {'Total': 2625, 'TP': 80, 'TN': 1543, 'FP': 957, 'FN': 45, 'precision': 0.07714561234329798, 'recall': 0.64, 'accuracy': 0.6182857142857143, 'average_precision': 0.08225035838874414, 'balanced_accuracy': 0.6286, 'f1': 0.1376936316695353, 'roc_auc': 0.650256}
==getted_scoring_result==
[fit 714/850] END C=4096.0, kernel=linear; total=2625, TP=80, TN=1543, FP=957, FN=45; precision=0.077, recall=0.640
accuracy: (test=0.618) average_precision: (test=0.082) balanced_accuracy: (test=0.629) f1: (test=0.138) roc_auc: (test=0.650) 11.40min
==get_scoring_result==
base_score: total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.348) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 825, 'FP': 1675, 'FN': 36, 'precision': 0.05045351473922902, 'recall': 0.712, 'accuracy': 0.3481904761904762, 'average_precision': 0.046369893258362674, 'balanced_accuracy': 0.521, 'f1': 0.09422975119110641, 'roc_auc': 0.5064736}
==getted_scoring_result==
[fit 715/850] END C=4096.0, kernel=polynomial; total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.348) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.506) 9.62s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1601, FP=899, FN=53; precision=0.074, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.637) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.608) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.658) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1601, 'FP': 899, 'FN': 53, 'precision': 0.07415036045314109, 'recall': 0.576, 'accuracy': 0.6373333333333333, 'average_precision': 0.08447247479424959, 'balanced_accuracy': 0.6082, 'f1': 0.13138686131386862, 'roc_auc': 0.658032}
==getted_scoring_result==
[fit 716/850] END C=4096.0, kernel=sigmoid; total=2625, TP=72, TN=1601, FP=899, FN=53; precision=0.074, recall=0.576
accuracy: (test=0.637) average_precision: (test=0.084) balanced_accuracy: (test=0.608) f1: (test=0.131) roc_auc: (test=0.658) 13.34s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1587, FP=913, FN=53; precision=0.073, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.632) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.605) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.661) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1587, 'FP': 913, 'FN': 53, 'precision': 0.07309644670050762, 'recall': 0.576, 'accuracy': 0.632, 'average_precision': 0.08440505124893932, 'balanced_accuracy': 0.6053999999999999, 'f1': 0.12972972972972974, 'roc_auc': 0.6612576}
==getted_scoring_result==
[fit 717/850] END C=4096.0, kernel=precomputed; total=2625, TP=72, TN=1587, FP=913, FN=53; precision=0.073, recall=0.576
accuracy: (test=0.632) average_precision: (test=0.084) balanced_accuracy: (test=0.605) f1: (test=0.130) roc_auc: (test=0.661) 15.30s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=77, TN=1456, FP=1044, FN=48; precision=0.069, recall=0.616

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.584) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.078) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.599) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.124) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.625) ===
score_result_dict: {'Total': 2625, 'TP': 77, 'TN': 1456, 'FP': 1044, 'FN': 48, 'precision': 0.06868867082961641, 'recall': 0.616, 'accuracy': 0.584, 'average_precision': 0.07835299065941786, 'balanced_accuracy': 0.5992, 'f1': 0.12359550561797752, 'roc_auc': 0.6245408}
==getted_scoring_result==
[fit 718/850] END C=8192.0, kernel=linear; total=2625, TP=77, TN=1456, FP=1044, FN=48; precision=0.069, recall=0.616
accuracy: (test=0.584) average_precision: (test=0.078) balanced_accuracy: (test=0.599) f1: (test=0.124) roc_auc: (test=0.625) 25.87min
==get_scoring_result==
base_score: total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.348) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 825, 'FP': 1675, 'FN': 36, 'precision': 0.05045351473922902, 'recall': 0.712, 'accuracy': 0.3481904761904762, 'average_precision': 0.046366720205698785, 'balanced_accuracy': 0.521, 'f1': 0.09422975119110641, 'roc_auc': 0.5064448}
==getted_scoring_result==
[fit 719/850] END C=8192.0, kernel=polynomial; total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.348) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.506) 10.31s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1600, FP=900, FN=54; precision=0.073, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.637) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.604) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.130) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.659) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1600, 'FP': 900, 'FN': 54, 'precision': 0.07312049433573635, 'recall': 0.568, 'accuracy': 0.6365714285714286, 'average_precision': 0.08447321800908009, 'balanced_accuracy': 0.604, 'f1': 0.12956204379562045, 'roc_auc': 0.6592448}
==getted_scoring_result==
[fit 720/850] END C=8192.0, kernel=sigmoid; total=2625, TP=71, TN=1600, FP=900, FN=54; precision=0.073, recall=0.568
accuracy: (test=0.637) average_precision: (test=0.084) balanced_accuracy: (test=0.604) f1: (test=0.130) roc_auc: (test=0.659) 16.50s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1594, FP=906, FN=53; precision=0.074, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.635) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.607) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.662) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1594, 'FP': 906, 'FN': 53, 'precision': 0.0736196319018405, 'recall': 0.576, 'accuracy': 0.6346666666666667, 'average_precision': 0.08403439563946986, 'balanced_accuracy': 0.6068, 'f1': 0.13055303717135086, 'roc_auc': 0.6617856}
==getted_scoring_result==
[fit 721/850] END C=8192.0, kernel=precomputed; total=2625, TP=72, TN=1594, FP=906, FN=53; precision=0.074, recall=0.576
accuracy: (test=0.635) average_precision: (test=0.084) balanced_accuracy: (test=0.607) f1: (test=0.131) roc_auc: (test=0.662) 21.14s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=75, TN=1352, FP=1148, FN=50; precision=0.061, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.544) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.070) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.570) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.111) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.592) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1352, 'FP': 1148, 'FN': 50, 'precision': 0.06132461161079313, 'recall': 0.6, 'accuracy': 0.5436190476190477, 'average_precision': 0.06961658237329851, 'balanced_accuracy': 0.5704, 'f1': 0.11127596439169139, 'roc_auc': 0.5915968}
==getted_scoring_result==
[fit 722/850] END C=16384.0, kernel=linear; total=2625, TP=75, TN=1352, FP=1148, FN=50; precision=0.061, recall=0.600
accuracy: (test=0.544) average_precision: (test=0.070) balanced_accuracy: (test=0.570) f1: (test=0.111) roc_auc: (test=0.592) 1h 10m 2s
==get_scoring_result==
base_score: total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.348) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 825, 'FP': 1675, 'FN': 36, 'precision': 0.05045351473922902, 'recall': 0.712, 'accuracy': 0.3481904761904762, 'average_precision': 0.046355276924464325, 'balanced_accuracy': 0.521, 'f1': 0.09422975119110641, 'roc_auc': 0.5064224}
==getted_scoring_result==
[fit 723/850] END C=16384.0, kernel=polynomial; total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.348) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.506) 8.37s
==get_scoring_result==
base_score: total=2625, TP=72, TN=1595, FP=905, FN=53; precision=0.074, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.635) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.084) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.607) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.131) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.660) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1595, 'FP': 905, 'FN': 53, 'precision': 0.0736949846468782, 'recall': 0.576, 'accuracy': 0.6350476190476191, 'average_precision': 0.08419417991357872, 'balanced_accuracy': 0.607, 'f1': 0.1306715063520871, 'roc_auc': 0.6596608}
==getted_scoring_result==
[fit 724/850] END C=16384.0, kernel=sigmoid; total=2625, TP=72, TN=1595, FP=905, FN=53; precision=0.074, recall=0.576
accuracy: (test=0.635) average_precision: (test=0.084) balanced_accuracy: (test=0.607) f1: (test=0.131) roc_auc: (test=0.660) 21.80s
==get_scoring_result==
base_score: total=2625, TP=71, TN=1585, FP=915, FN=54; precision=0.072, recall=0.568

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.631) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.085) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.601) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.128) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.666) ===
score_result_dict: {'Total': 2625, 'TP': 71, 'TN': 1585, 'FP': 915, 'FN': 54, 'precision': 0.0720081135902637, 'recall': 0.568, 'accuracy': 0.6308571428571429, 'average_precision': 0.08498165735450619, 'balanced_accuracy': 0.601, 'f1': 0.1278127812781278, 'roc_auc': 0.6655552}
==getted_scoring_result==
[fit 725/850] END C=16384.0, kernel=precomputed; total=2625, TP=71, TN=1585, FP=915, FN=54; precision=0.072, recall=0.568
accuracy: (test=0.631) average_precision: (test=0.085) balanced_accuracy: (test=0.601) f1: (test=0.128) roc_auc: (test=0.666) 32.35s
==get_scoring_result==
base_score: total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 856, 'FP': 1644, 'FN': 38, 'precision': 0.05025996533795494, 'recall': 0.696, 'accuracy': 0.35923809523809525, 'average_precision': 0.04629013084650639, 'balanced_accuracy': 0.5192, 'f1': 0.09374999999999999, 'roc_auc': 0.5063424}
==getted_scoring_result==
[fit 726/850] END C=0.0009765625, degree=2, kernel=polynomial; total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 9.15s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=114, TN=312, FP=2188, FN=11; precision=0.050, recall=0.912

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.162) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.502) ===
score_result_dict: {'Total': 2625, 'TP': 114, 'TN': 312, 'FP': 2188, 'FN': 11, 'precision': 0.04952215464813206, 'recall': 0.912, 'accuracy': 0.16228571428571428, 'average_precision': 0.04626151764841775, 'balanced_accuracy': 0.5184, 'f1': 0.09394313967861558, 'roc_auc': 0.502224}
==getted_scoring_result==
[fit 727/850] END C=0.0009765625, degree=3, kernel=polynomial; total=2625, TP=114, TN=312, FP=2188, FN=11; precision=0.050, recall=0.912
accuracy: (test=0.162) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.094) roc_auc: (test=0.502) 9.28s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 728/850] END C=0.0009765625, degree=4, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.04s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 729/850] END C=0.0009765625, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.53s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 730/850] END C=0.0009765625, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.40s
==get_scoring_result==
base_score: total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 856, 'FP': 1644, 'FN': 38, 'precision': 0.05025996533795494, 'recall': 0.696, 'accuracy': 0.35923809523809525, 'average_precision': 0.04629013084650639, 'balanced_accuracy': 0.5192, 'f1': 0.09374999999999999, 'roc_auc': 0.5063424}
==getted_scoring_result==
[fit 731/850] END C=0.001953125, degree=2, kernel=polynomial; total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 10.35s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 732/850] END C=0.001953125, degree=3, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.49s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 733/850] END C=0.001953125, degree=4, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.07s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 734/850] END C=0.001953125, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.66s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 735/850] END C=0.001953125, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.31s
==get_scoring_result==
base_score: total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 856, 'FP': 1644, 'FN': 38, 'precision': 0.05025996533795494, 'recall': 0.696, 'accuracy': 0.35923809523809525, 'average_precision': 0.04629013084650639, 'balanced_accuracy': 0.5192, 'f1': 0.09374999999999999, 'roc_auc': 0.5063424}
==getted_scoring_result==
[fit 736/850] END C=0.00390625, degree=2, kernel=polynomial; total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 9.16s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=95, TN=692, FP=1808, FN=30; precision=0.050, recall=0.760

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.300) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 95, 'TN': 692, 'FP': 1808, 'FN': 30, 'precision': 0.049921177088807146, 'recall': 0.76, 'accuracy': 0.2998095238095238, 'average_precision': 0.046417731780375046, 'balanced_accuracy': 0.5184, 'f1': 0.09368836291913214, 'roc_auc': 0.507424}
==getted_scoring_result==
[fit 737/850] END C=0.00390625, degree=3, kernel=polynomial; total=2625, TP=95, TN=692, FP=1808, FN=30; precision=0.050, recall=0.760
accuracy: (test=0.300) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.094) roc_auc: (test=0.507) 9.34s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 738/850] END C=0.00390625, degree=4, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.07s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 739/850] END C=0.00390625, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.53s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 740/850] END C=0.00390625, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.83s
==get_scoring_result==
base_score: total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 856, 'FP': 1644, 'FN': 38, 'precision': 0.05025996533795494, 'recall': 0.696, 'accuracy': 0.35923809523809525, 'average_precision': 0.04629013084650639, 'balanced_accuracy': 0.5192, 'f1': 0.09374999999999999, 'roc_auc': 0.5063424}
==getted_scoring_result==
[fit 741/850] END C=0.0078125, degree=2, kernel=polynomial; total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 9.53s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 742/850] END C=0.0078125, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.40s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 743/850] END C=0.0078125, degree=4, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.02s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 744/850] END C=0.0078125, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.22s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 745/850] END C=0.0078125, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.40s
==get_scoring_result==
base_score: total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 856, 'FP': 1644, 'FN': 38, 'precision': 0.05025996533795494, 'recall': 0.696, 'accuracy': 0.35923809523809525, 'average_precision': 0.04629013084650639, 'balanced_accuracy': 0.5192, 'f1': 0.09374999999999999, 'roc_auc': 0.5063424}
==getted_scoring_result==
[fit 746/850] END C=0.015625, degree=2, kernel=polynomial; total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 9.76s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 747/850] END C=0.015625, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.62s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 748/850] END C=0.015625, degree=4, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.55s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 749/850] END C=0.015625, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.87s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 750/850] END C=0.015625, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.99s
==get_scoring_result==
base_score: total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 856, 'FP': 1644, 'FN': 38, 'precision': 0.05025996533795494, 'recall': 0.696, 'accuracy': 0.35923809523809525, 'average_precision': 0.04629013084650639, 'balanced_accuracy': 0.5192, 'f1': 0.09374999999999999, 'roc_auc': 0.5063424}
==getted_scoring_result==
[fit 751/850] END C=0.03125, degree=2, kernel=polynomial; total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 10.82s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 752/850] END C=0.03125, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 11.26s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 753/850] END C=0.03125, degree=4, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 11.76s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 754/850] END C=0.03125, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 11.74s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 755/850] END C=0.03125, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 11.13s
==get_scoring_result==
base_score: total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 856, 'FP': 1644, 'FN': 38, 'precision': 0.05025996533795494, 'recall': 0.696, 'accuracy': 0.35923809523809525, 'average_precision': 0.04629013084650639, 'balanced_accuracy': 0.5192, 'f1': 0.09374999999999999, 'roc_auc': 0.5063424}
==getted_scoring_result==
[fit 756/850] END C=0.0625, degree=2, kernel=polynomial; total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 10.59s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 757/850] END C=0.0625, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.72s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 758/850] END C=0.0625, degree=4, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 8.85s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 759/850] END C=0.0625, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.49s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 760/850] END C=0.0625, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.64s
==get_scoring_result==
base_score: total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 856, 'FP': 1644, 'FN': 38, 'precision': 0.05025996533795494, 'recall': 0.696, 'accuracy': 0.35923809523809525, 'average_precision': 0.04629013084650639, 'balanced_accuracy': 0.5192, 'f1': 0.09374999999999999, 'roc_auc': 0.5063424}
==getted_scoring_result==
[fit 761/850] END C=0.125, degree=2, kernel=polynomial; total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 10.11s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 762/850] END C=0.125, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 10.00s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 763/850] END C=0.125, degree=4, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.58s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 764/850] END C=0.125, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.29s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 765/850] END C=0.125, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.52s
==get_scoring_result==
base_score: total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.359) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 856, 'FP': 1644, 'FN': 38, 'precision': 0.05025996533795494, 'recall': 0.696, 'accuracy': 0.35923809523809525, 'average_precision': 0.04629013084650639, 'balanced_accuracy': 0.5192, 'f1': 0.09374999999999999, 'roc_auc': 0.5063424}
==getted_scoring_result==
[fit 766/850] END C=0.25, degree=2, kernel=polynomial; total=2625, TP=87, TN=856, FP=1644, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.359) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 9.33s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 767/850] END C=0.25, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.28s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.497) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.4966}
==getted_scoring_result==
[fit 768/850] END C=0.25, degree=4, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.497) 9.50s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 769/850] END C=0.25, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.52s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 770/850] END C=0.25, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 8.95s
==get_scoring_result==
base_score: total=2625, TP=90, TN=796, FP=1704, FN=35; precision=0.050, recall=0.720

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.338) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 90, 'TN': 796, 'FP': 1704, 'FN': 35, 'precision': 0.05016722408026756, 'recall': 0.72, 'accuracy': 0.3375238095238095, 'average_precision': 0.04622686507080892, 'balanced_accuracy': 0.5192, 'f1': 0.09379885356956749, 'roc_auc': 0.50664}
==getted_scoring_result==
[fit 771/850] END C=0.5, degree=2, kernel=polynomial; total=2625, TP=90, TN=796, FP=1704, FN=35; precision=0.050, recall=0.720
accuracy: (test=0.338) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 8.42s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 772/850] END C=0.5, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 8.25s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 773/850] END C=0.5, degree=4, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 8.86s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 774/850] END C=0.5, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 8.92s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 775/850] END C=0.5, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.15s
==get_scoring_result==
base_score: total=2625, TP=89, TN=802, FP=1698, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.339) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.516) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 802, 'FP': 1698, 'FN': 36, 'precision': 0.049804141018466704, 'recall': 0.712, 'accuracy': 0.3394285714285714, 'average_precision': 0.04626270692520898, 'balanced_accuracy': 0.5164, 'f1': 0.09309623430962342, 'roc_auc': 0.50672}
==getted_scoring_result==
[fit 776/850] END C=1.0, degree=2, kernel=polynomial; total=2625, TP=89, TN=802, FP=1698, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.339) average_precision: (test=0.046) balanced_accuracy: (test=0.516) f1: (test=0.093) roc_auc: (test=0.507) 9.12s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 777/850] END C=1.0, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.38s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=88, TN=828, FP=1672, FN=37; precision=0.050, recall=0.704

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.349) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 88, 'TN': 828, 'FP': 1672, 'FN': 37, 'precision': 0.05, 'recall': 0.704, 'accuracy': 0.34895238095238096, 'average_precision': 0.04656572867543665, 'balanced_accuracy': 0.5176, 'f1': 0.093368700265252, 'roc_auc': 0.5064608}
==getted_scoring_result==
[fit 778/850] END C=1.0, degree=4, kernel=polynomial; total=2625, TP=88, TN=828, FP=1672, FN=37; precision=0.050, recall=0.704
accuracy: (test=0.349) average_precision: (test=0.047) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.40s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 779/850] END C=1.0, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.42s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 780/850] END C=1.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.61s
==get_scoring_result==
base_score: total=2625, TP=89, TN=830, FP=1670, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.350) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 830, 'FP': 1670, 'FN': 36, 'precision': 0.05059693007390563, 'recall': 0.712, 'accuracy': 0.35009523809523807, 'average_precision': 0.04628254436091389, 'balanced_accuracy': 0.522, 'f1': 0.09447983014861995, 'roc_auc': 0.5065712}
==getted_scoring_result==
[fit 781/850] END C=2.0, degree=2, kernel=polynomial; total=2625, TP=89, TN=830, FP=1670, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.350) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.507) 9.43s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 782/850] END C=2.0, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.03s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 783/850] END C=2.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.19s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 784/850] END C=2.0, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.27s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 785/850] END C=2.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.35s
==get_scoring_result==
base_score: total=2625, TP=89, TN=824, FP=1676, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.348) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 824, 'FP': 1676, 'FN': 36, 'precision': 0.05042492917847025, 'recall': 0.712, 'accuracy': 0.3478095238095238, 'average_precision': 0.04627216340243284, 'balanced_accuracy': 0.5207999999999999, 'f1': 0.09417989417989417, 'roc_auc': 0.5066464}
==getted_scoring_result==
[fit 786/850] END C=4.0, degree=2, kernel=polynomial; total=2625, TP=89, TN=824, FP=1676, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.348) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.507) 9.25s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 787/850] END C=4.0, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.19s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 788/850] END C=4.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.27s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 789/850] END C=4.0, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.36s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 790/850] END C=4.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 8.97s
==get_scoring_result==
base_score: total=2625, TP=89, TN=830, FP=1670, FN=36; precision=0.051, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.350) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.522) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 830, 'FP': 1670, 'FN': 36, 'precision': 0.05059693007390563, 'recall': 0.712, 'accuracy': 0.35009523809523807, 'average_precision': 0.046290629543481385, 'balanced_accuracy': 0.522, 'f1': 0.09447983014861995, 'roc_auc': 0.5066064}
==getted_scoring_result==
[fit 791/850] END C=8.0, degree=2, kernel=polynomial; total=2625, TP=89, TN=830, FP=1670, FN=36; precision=0.051, recall=0.712
accuracy: (test=0.350) average_precision: (test=0.046) balanced_accuracy: (test=0.522) f1: (test=0.094) roc_auc: (test=0.507) 8.85s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 792/850] END C=8.0, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.39s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 793/850] END C=8.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.48s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 794/850] END C=8.0, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.65s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 795/850] END C=8.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.65s
==get_scoring_result==
base_score: total=2625, TP=89, TN=822, FP=1678, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.347) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 822, 'FP': 1678, 'FN': 36, 'precision': 0.05036785512167515, 'recall': 0.712, 'accuracy': 0.34704761904761905, 'average_precision': 0.046276771158448374, 'balanced_accuracy': 0.5204, 'f1': 0.09408033826638476, 'roc_auc': 0.5066496}
==getted_scoring_result==
[fit 796/850] END C=16.0, degree=2, kernel=polynomial; total=2625, TP=89, TN=822, FP=1678, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.347) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.38s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 797/850] END C=16.0, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 10.13s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 798/850] END C=16.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.78s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 799/850] END C=16.0, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.99s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 800/850] END C=16.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.80s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.04627647406503391, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066432}
==getted_scoring_result==
[fit 801/850] END C=32.0, degree=2, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.37s
==get_scoring_result==
base_score: total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.356) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 848, 'FP': 1652, 'FN': 38, 'precision': 0.050028752156411734, 'recall': 0.696, 'accuracy': 0.35619047619047617, 'average_precision': 0.04641424274248261, 'balanced_accuracy': 0.5176, 'f1': 0.09334763948497854, 'roc_auc': 0.5061568}
==getted_scoring_result==
[fit 802/850] END C=32.0, degree=3, kernel=polynomial; total=2625, TP=87, TN=848, FP=1652, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.356) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.506) 9.81s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 803/850] END C=32.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.73s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 804/850] END C=32.0, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.63s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 805/850] END C=32.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.39s
==get_scoring_result==
base_score: total=2625, TP=89, TN=821, FP=1679, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.347) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 821, 'FP': 1679, 'FN': 36, 'precision': 0.050339366515837106, 'recall': 0.712, 'accuracy': 0.3466666666666667, 'average_precision': 0.04627381921080176, 'balanced_accuracy': 0.5202, 'f1': 0.09403063919704174, 'roc_auc': 0.5066336}
==getted_scoring_result==
[fit 806/850] END C=64.0, degree=2, kernel=polynomial; total=2625, TP=89, TN=821, FP=1679, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.347) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.62s
==get_scoring_result==
base_score: total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.360) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 87, 'TN': 858, 'FP': 1642, 'FN': 38, 'precision': 0.0503181029496819, 'recall': 0.696, 'accuracy': 0.36, 'average_precision': 0.046425033045774264, 'balanced_accuracy': 0.5196, 'f1': 0.09385113268608414, 'roc_auc': 0.5063968}
==getted_scoring_result==
[fit 807/850] END C=64.0, degree=3, kernel=polynomial; total=2625, TP=87, TN=858, FP=1642, FN=38; precision=0.050, recall=0.696
accuracy: (test=0.360) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.506) 10.03s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 808/850] END C=64.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.73s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=99, TN=655, FP=1845, FN=26; precision=0.051, recall=0.792

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.287) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.527) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.508) ===
score_result_dict: {'Total': 2625, 'TP': 99, 'TN': 655, 'FP': 1845, 'FN': 26, 'precision': 0.05092592592592592, 'recall': 0.792, 'accuracy': 0.28723809523809524, 'average_precision': 0.04689034327231989, 'balanced_accuracy': 0.527, 'f1': 0.09569840502658289, 'roc_auc': 0.5075392}
==getted_scoring_result==
[fit 809/850] END C=64.0, degree=5, kernel=polynomial; total=2625, TP=99, TN=655, FP=1845, FN=26; precision=0.051, recall=0.792
accuracy: (test=0.287) average_precision: (test=0.047) balanced_accuracy: (test=0.527) f1: (test=0.096) roc_auc: (test=0.508) 9.61s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 810/850] END C=64.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.61s
==get_scoring_result==
base_score: total=2625, TP=86, TN=863, FP=1637, FN=39; precision=0.050, recall=0.688

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.362) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.517) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 86, 'TN': 863, 'FP': 1637, 'FN': 39, 'precision': 0.04991294254207777, 'recall': 0.688, 'accuracy': 0.3615238095238095, 'average_precision': 0.04630070444386748, 'balanced_accuracy': 0.5166, 'f1': 0.09307359307359309, 'roc_auc': 0.5065888}
==getted_scoring_result==
[fit 811/850] END C=128.0, degree=2, kernel=polynomial; total=2625, TP=86, TN=863, FP=1637, FN=39; precision=0.050, recall=0.688
accuracy: (test=0.362) average_precision: (test=0.046) balanced_accuracy: (test=0.517) f1: (test=0.093) roc_auc: (test=0.507) 9.81s
==get_scoring_result==
base_score: total=2625, TP=92, TN=754, FP=1746, FN=33; precision=0.050, recall=0.736

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.322) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 92, 'TN': 754, 'FP': 1746, 'FN': 33, 'precision': 0.05005440696409141, 'recall': 0.736, 'accuracy': 0.3222857142857143, 'average_precision': 0.046391736280686005, 'balanced_accuracy': 0.5187999999999999, 'f1': 0.0937340804890474, 'roc_auc': 0.5066128}
==getted_scoring_result==
[fit 812/850] END C=128.0, degree=3, kernel=polynomial; total=2625, TP=92, TN=754, FP=1746, FN=33; precision=0.050, recall=0.736
accuracy: (test=0.322) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.507) 9.70s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 813/850] END C=128.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.68s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 814/850] END C=128.0, degree=5, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.09s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 815/850] END C=128.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.42s
==get_scoring_result==
base_score: total=2625, TP=75, TN=1086, FP=1414, FN=50; precision=0.050, recall=0.600

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.442) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.517) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.511) ===
score_result_dict: {'Total': 2625, 'TP': 75, 'TN': 1086, 'FP': 1414, 'FN': 50, 'precision': 0.050369375419744795, 'recall': 0.6, 'accuracy': 0.4422857142857143, 'average_precision': 0.04677600332919167, 'balanced_accuracy': 0.5172, 'f1': 0.09293680297397769, 'roc_auc': 0.5113232}
==getted_scoring_result==
[fit 816/850] END C=256.0, degree=2, kernel=polynomial; total=2625, TP=75, TN=1086, FP=1414, FN=50; precision=0.050, recall=0.600
accuracy: (test=0.442) average_precision: (test=0.047) balanced_accuracy: (test=0.517) f1: (test=0.093) roc_auc: (test=0.511) 10.62s
==get_scoring_result==
base_score: total=2625, TP=90, TN=791, FP=1709, FN=35; precision=0.050, recall=0.720

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.336) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 90, 'TN': 791, 'FP': 1709, 'FN': 35, 'precision': 0.0500277932184547, 'recall': 0.72, 'accuracy': 0.3356190476190476, 'average_precision': 0.04638878949525821, 'balanced_accuracy': 0.5182, 'f1': 0.09355509355509356, 'roc_auc': 0.506576}
==getted_scoring_result==
[fit 817/850] END C=256.0, degree=3, kernel=polynomial; total=2625, TP=90, TN=791, FP=1709, FN=35; precision=0.050, recall=0.720
accuracy: (test=0.336) average_precision: (test=0.046) balanced_accuracy: (test=0.518) f1: (test=0.094) roc_auc: (test=0.507) 9.98s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 818/850] END C=256.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.81s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=103, TN=562, FP=1938, FN=22; precision=0.050, recall=0.824

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.253) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.524) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.508) ===
score_result_dict: {'Total': 2625, 'TP': 103, 'TN': 562, 'FP': 1938, 'FN': 22, 'precision': 0.05046545810877021, 'recall': 0.824, 'accuracy': 0.25333333333333335, 'average_precision': 0.04677751957181582, 'balanced_accuracy': 0.5244, 'f1': 0.0951061865189289, 'roc_auc': 0.5079712}
==getted_scoring_result==
[fit 819/850] END C=256.0, degree=5, kernel=polynomial; total=2625, TP=103, TN=562, FP=1938, FN=22; precision=0.050, recall=0.824
accuracy: (test=0.253) average_precision: (test=0.047) balanced_accuracy: (test=0.524) f1: (test=0.095) roc_auc: (test=0.508) 9.69s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 820/850] END C=256.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.65s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1295, FP=1205, FN=58; precision=0.053, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.519) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.527) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.096) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.519) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1295, 'FP': 1205, 'FN': 58, 'precision': 0.05267295597484277, 'recall': 0.536, 'accuracy': 0.5188571428571429, 'average_precision': 0.04752379991810593, 'balanced_accuracy': 0.527, 'f1': 0.09591982820329277, 'roc_auc': 0.5186224}
==getted_scoring_result==
[fit 821/850] END C=512.0, degree=2, kernel=polynomial; total=2625, TP=67, TN=1295, FP=1205, FN=58; precision=0.053, recall=0.536
accuracy: (test=0.519) average_precision: (test=0.048) balanced_accuracy: (test=0.527) f1: (test=0.096) roc_auc: (test=0.519) 9.74s
==get_scoring_result==
base_score: total=2625, TP=89, TN=819, FP=1681, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 819, 'FP': 1681, 'FN': 36, 'precision': 0.05028248587570622, 'recall': 0.712, 'accuracy': 0.3459047619047619, 'average_precision': 0.04638322808236753, 'balanced_accuracy': 0.5198, 'f1': 0.09393139841688654, 'roc_auc': 0.506432}
==getted_scoring_result==
[fit 822/850] END C=512.0, degree=3, kernel=polynomial; total=2625, TP=89, TN=819, FP=1681, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.046) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.506) 9.87s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 823/850] END C=512.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.72s
==get_scoring_result==
base_score: total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.342) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 810, 'FP': 1690, 'FN': 36, 'precision': 0.05002810567734682, 'recall': 0.712, 'accuracy': 0.3424761904761905, 'average_precision': 0.046718274571943615, 'balanced_accuracy': 0.518, 'f1': 0.09348739495798318, 'roc_auc': 0.5066912}
==getted_scoring_result==
[fit 824/850] END C=512.0, degree=5, kernel=polynomial; total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.342) average_precision: (test=0.047) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 11.27s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 825/850] END C=512.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 11.72s
==get_scoring_result==
base_score: total=2625, TP=66, TN=1295, FP=1205, FN=59; precision=0.052, recall=0.528

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.518) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.049) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.523) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.095) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.530) ===
score_result_dict: {'Total': 2625, 'TP': 66, 'TN': 1295, 'FP': 1205, 'FN': 59, 'precision': 0.05192761605035405, 'recall': 0.528, 'accuracy': 0.5184761904761904, 'average_precision': 0.04890748722637056, 'balanced_accuracy': 0.523, 'f1': 0.09455587392550144, 'roc_auc': 0.5297872}
==getted_scoring_result==
[fit 826/850] END C=1024.0, degree=2, kernel=polynomial; total=2625, TP=66, TN=1295, FP=1205, FN=59; precision=0.052, recall=0.528
accuracy: (test=0.518) average_precision: (test=0.049) balanced_accuracy: (test=0.523) f1: (test=0.095) roc_auc: (test=0.530) 12.79s
==get_scoring_result==
base_score: total=2625, TP=89, TN=815, FP=1685, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.344) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.519) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 815, 'FP': 1685, 'FN': 36, 'precision': 0.050169109357384445, 'recall': 0.712, 'accuracy': 0.3443809523809524, 'average_precision': 0.04636249691959317, 'balanced_accuracy': 0.519, 'f1': 0.0937335439705108, 'roc_auc': 0.5064704}
==getted_scoring_result==
[fit 827/850] END C=1024.0, degree=3, kernel=polynomial; total=2625, TP=89, TN=815, FP=1685, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.344) average_precision: (test=0.046) balanced_accuracy: (test=0.519) f1: (test=0.094) roc_auc: (test=0.506) 12.80s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 828/850] END C=1024.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 12.56s
==get_scoring_result==
base_score: total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.342) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 810, 'FP': 1690, 'FN': 36, 'precision': 0.05002810567734682, 'recall': 0.712, 'accuracy': 0.3424761904761905, 'average_precision': 0.046718274571943615, 'balanced_accuracy': 0.518, 'f1': 0.09348739495798318, 'roc_auc': 0.5066912}
==getted_scoring_result==
[fit 829/850] END C=1024.0, degree=5, kernel=polynomial; total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.342) average_precision: (test=0.047) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 10.89s
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 830/850] END C=1024.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 10.09s
==get_scoring_result==
base_score: total=2625, TP=67, TN=1331, FP=1169, FN=58; precision=0.054, recall=0.536

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.533) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.051) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.534) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.098) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.546) ===
score_result_dict: {'Total': 2625, 'TP': 67, 'TN': 1331, 'FP': 1169, 'FN': 58, 'precision': 0.054207119741100325, 'recall': 0.536, 'accuracy': 0.5325714285714286, 'average_precision': 0.051374862269791766, 'balanced_accuracy': 0.5342, 'f1': 0.09845701689933872, 'roc_auc': 0.5462}
==getted_scoring_result==
[fit 831/850] END C=2048.0, degree=2, kernel=polynomial; total=2625, TP=67, TN=1331, FP=1169, FN=58; precision=0.054, recall=0.536
accuracy: (test=0.533) average_precision: (test=0.051) balanced_accuracy: (test=0.534) f1: (test=0.098) roc_auc: (test=0.546) 9.78s
==get_scoring_result==
base_score: total=2625, TP=89, TN=824, FP=1676, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.348) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 824, 'FP': 1676, 'FN': 36, 'precision': 0.05042492917847025, 'recall': 0.712, 'accuracy': 0.3478095238095238, 'average_precision': 0.04637805841107421, 'balanced_accuracy': 0.5207999999999999, 'f1': 0.09417989417989417, 'roc_auc': 0.5064928}
==getted_scoring_result==
[fit 832/850] END C=2048.0, degree=3, kernel=polynomial; total=2625, TP=89, TN=824, FP=1676, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.348) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.506) 9.89s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 833/850] END C=2048.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 9.80s
==get_scoring_result==
base_score: total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.342) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 810, 'FP': 1690, 'FN': 36, 'precision': 0.05002810567734682, 'recall': 0.712, 'accuracy': 0.3424761904761905, 'average_precision': 0.046718274571943615, 'balanced_accuracy': 0.518, 'f1': 0.09348739495798318, 'roc_auc': 0.5066912}
==getted_scoring_result==
[fit 834/850] END C=2048.0, degree=5, kernel=polynomial; total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.342) average_precision: (test=0.047) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.71s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 835/850] END C=2048.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.81s
==get_scoring_result==
base_score: total=2625, TP=69, TN=1371, FP=1129, FN=56; precision=0.058, recall=0.552

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.549) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.055) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.550) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.104) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.567) ===
score_result_dict: {'Total': 2625, 'TP': 69, 'TN': 1371, 'FP': 1129, 'FN': 56, 'precision': 0.05759599332220367, 'recall': 0.552, 'accuracy': 0.5485714285714286, 'average_precision': 0.05521480620733164, 'balanced_accuracy': 0.5502, 'f1': 0.10430839002267574, 'roc_auc': 0.5671456}
==getted_scoring_result==
[fit 836/850] END C=4096.0, degree=2, kernel=polynomial; total=2625, TP=69, TN=1371, FP=1129, FN=56; precision=0.058, recall=0.552
accuracy: (test=0.549) average_precision: (test=0.055) balanced_accuracy: (test=0.550) f1: (test=0.104) roc_auc: (test=0.567) 9.93s
==get_scoring_result==
base_score: total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.348) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 825, 'FP': 1675, 'FN': 36, 'precision': 0.05045351473922902, 'recall': 0.712, 'accuracy': 0.3481904761904762, 'average_precision': 0.046369893258362674, 'balanced_accuracy': 0.521, 'f1': 0.09422975119110641, 'roc_auc': 0.5064736}
==getted_scoring_result==
[fit 837/850] END C=4096.0, degree=3, kernel=polynomial; total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.348) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.506) 9.84s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 838/850] END C=4096.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 10.01s
==get_scoring_result==
base_score: total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.342) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 810, 'FP': 1690, 'FN': 36, 'precision': 0.05002810567734682, 'recall': 0.712, 'accuracy': 0.3424761904761905, 'average_precision': 0.046718274571943615, 'balanced_accuracy': 0.518, 'f1': 0.09348739495798318, 'roc_auc': 0.5066912}
==getted_scoring_result==
[fit 839/850] END C=4096.0, degree=5, kernel=polynomial; total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.342) average_precision: (test=0.047) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 11.05s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 840/850] END C=4096.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 11.74s
==get_scoring_result==
base_score: total=2625, TP=68, TN=1447, FP=1053, FN=57; precision=0.061, recall=0.544

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.577) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.062) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.561) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.109) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.594) ===
score_result_dict: {'Total': 2625, 'TP': 68, 'TN': 1447, 'FP': 1053, 'FN': 57, 'precision': 0.060660124888492414, 'recall': 0.544, 'accuracy': 0.5771428571428572, 'average_precision': 0.06158746670099385, 'balanced_accuracy': 0.5614, 'f1': 0.10914927768860354, 'roc_auc': 0.5939296}
==getted_scoring_result==
[fit 841/850] END C=8192.0, degree=2, kernel=polynomial; total=2625, TP=68, TN=1447, FP=1053, FN=57; precision=0.061, recall=0.544
accuracy: (test=0.577) average_precision: (test=0.062) balanced_accuracy: (test=0.561) f1: (test=0.109) roc_auc: (test=0.594) 11.74s
==get_scoring_result==
base_score: total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.348) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 825, 'FP': 1675, 'FN': 36, 'precision': 0.05045351473922902, 'recall': 0.712, 'accuracy': 0.3481904761904762, 'average_precision': 0.046366720205698785, 'balanced_accuracy': 0.521, 'f1': 0.09422975119110641, 'roc_auc': 0.5064448}
==getted_scoring_result==
[fit 842/850] END C=8192.0, degree=3, kernel=polynomial; total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.348) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.506) 10.90s
==get_scoring_result==
base_score: total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.346) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.520) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 820, 'FP': 1680, 'FN': 36, 'precision': 0.05031091011871114, 'recall': 0.712, 'accuracy': 0.3462857142857143, 'average_precision': 0.046576633786179086, 'balanced_accuracy': 0.52, 'f1': 0.09398099260823653, 'roc_auc': 0.5066752}
==getted_scoring_result==
[fit 843/850] END C=8192.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=820, FP=1680, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.346) average_precision: (test=0.047) balanced_accuracy: (test=0.520) f1: (test=0.094) roc_auc: (test=0.507) 8.81s
==get_scoring_result==
base_score: total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.342) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 810, 'FP': 1690, 'FN': 36, 'precision': 0.05002810567734682, 'recall': 0.712, 'accuracy': 0.3424761904761905, 'average_precision': 0.046718274571943615, 'balanced_accuracy': 0.518, 'f1': 0.09348739495798318, 'roc_auc': 0.5066912}
==getted_scoring_result==
[fit 844/850] END C=8192.0, degree=5, kernel=polynomial; total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.342) average_precision: (test=0.047) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 8.88s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 845/850] END C=8192.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.45s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=72, TN=1491, FP=1009, FN=53; precision=0.067, recall=0.576

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.595) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.070) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.586) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.119) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.620) ===
score_result_dict: {'Total': 2625, 'TP': 72, 'TN': 1491, 'FP': 1009, 'FN': 53, 'precision': 0.0666049953746531, 'recall': 0.576, 'accuracy': 0.5954285714285714, 'average_precision': 0.07045336819723022, 'balanced_accuracy': 0.5862, 'f1': 0.11940298507462685, 'roc_auc': 0.6203984}
==getted_scoring_result==
[fit 846/850] END C=16384.0, degree=2, kernel=polynomial; total=2625, TP=72, TN=1491, FP=1009, FN=53; precision=0.067, recall=0.576
accuracy: (test=0.595) average_precision: (test=0.070) balanced_accuracy: (test=0.586) f1: (test=0.119) roc_auc: (test=0.620) 10.36s
==get_scoring_result==
base_score: total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.348) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.046) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.521) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 825, 'FP': 1675, 'FN': 36, 'precision': 0.05045351473922902, 'recall': 0.712, 'accuracy': 0.3481904761904762, 'average_precision': 0.046355276924464325, 'balanced_accuracy': 0.521, 'f1': 0.09422975119110641, 'roc_auc': 0.5064224}
==getted_scoring_result==
[fit 847/850] END C=16384.0, degree=3, kernel=polynomial; total=2625, TP=89, TN=825, FP=1675, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.348) average_precision: (test=0.046) balanced_accuracy: (test=0.521) f1: (test=0.094) roc_auc: (test=0.506) 9.54s
==get_scoring_result==
base_score: total=2625, TP=89, TN=811, FP=1689, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.343) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.094) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.506) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 811, 'FP': 1689, 'FN': 36, 'precision': 0.050056242969628795, 'recall': 0.712, 'accuracy': 0.34285714285714286, 'average_precision': 0.046544405025534225, 'balanced_accuracy': 0.5182, 'f1': 0.09353652128218604, 'roc_auc': 0.5064448}
==getted_scoring_result==
[fit 848/850] END C=16384.0, degree=4, kernel=polynomial; total=2625, TP=89, TN=811, FP=1689, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.343) average_precision: (test=0.047) balanced_accuracy: (test=0.518) f1: (test=0.094) roc_auc: (test=0.506) 9.48s
==get_scoring_result==
base_score: total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.342) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.047) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.518) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.093) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.507) ===
score_result_dict: {'Total': 2625, 'TP': 89, 'TN': 810, 'FP': 1690, 'FN': 36, 'precision': 0.05002810567734682, 'recall': 0.712, 'accuracy': 0.3424761904761905, 'average_precision': 0.046718274571943615, 'balanced_accuracy': 0.518, 'f1': 0.09348739495798318, 'roc_auc': 0.5066912}
==getted_scoring_result==
[fit 849/850] END C=16384.0, degree=5, kernel=polynomial; total=2625, TP=89, TN=810, FP=1690, FN=36; precision=0.050, recall=0.712
accuracy: (test=0.342) average_precision: (test=0.047) balanced_accuracy: (test=0.518) f1: (test=0.093) roc_auc: (test=0.507) 9.39s
Line search fails in two-class probability estimates
==get_scoring_result==
base_score: total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000

=== accuracy_score
(y_true, y_pred, *, normalize=True, sample_weight=None)
y_pred
accuracy_score over
accuracy: (test=0.048) ===
=== average_precision_score
(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)
y_score
average_precision_score over
average_precision: (test=0.048) ===
=== balanced_accuracy_score
(y_true, y_pred, *, sample_weight=None, adjusted=False)
y_pred
balanced_accuracy_score over
balanced_accuracy: (test=0.500) ===
=== f1_score
(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')
y_pred
f1_score over
f1: (test=0.091) ===
=== roc_auc_score
(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)
y_score
roc_auc_score over
roc_auc: (test=0.500) ===
score_result_dict: {'Total': 2625, 'TP': 125, 'TN': 0, 'FP': 2500, 'FN': 0, 'precision': 0.047619047619047616, 'recall': 1.0, 'accuracy': 0.047619047619047616, 'average_precision': 0.047619047619047616, 'balanced_accuracy': 0.5, 'f1': 0.0909090909090909, 'roc_auc': 0.5}
==getted_scoring_result==
[fit 850/850] END C=16384.0, degree=6, kernel=polynomial; total=2625, TP=125, TN=0, FP=2500, FN=0; precision=0.048, recall=1.000
accuracy: (test=0.048) average_precision: (test=0.048) balanced_accuracy: (test=0.500) f1: (test=0.091) roc_auc: (test=0.500) 9.66s
write rank test to csv!!!
write over!!!
clf.best_estimator_params: {'C': 16.0, 'gamma': 16.0, 'kernel': 'rbf'}
best params found in line [366] for metric [roc_auc] in rank file
best params found in fit [365] for metric [roc_auc] in run_and_score file
clf.best_scoring_result: [Total: (test=2625) TP: (test=83.000) TN: (test=2411.000) FP: (test=89.000) FN: (test=42.000) precision: (test=0.483) recall: (test=0.664) accuracy: (test=0.950) average_precision: (test=0.657) balanced_accuracy: (test=0.814) f1: (test=0.559) roc_auc: (test=0.914) ]
total time spending: 15h 37m 8s
